Log for Subject Pair 5-6 from H9
========================================


========================= PROCESSING SUBJECT PAIR: 5-6 from H9 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 236 clean Target and 945 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 806

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 53

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 67.92%

--- Training cWGAN-GP for Subject 5-6, Run 1 ---
Epoch 0/1000: D Loss=72.8686, G Loss (Comb)=2.9177
Epoch 50/1000: D Loss=-0.3101, G Loss (Comb)=-2.8823
Epoch 100/1000: D Loss=-0.2484, G Loss (Comb)=-2.3042
Epoch 150/1000: D Loss=-0.2423, G Loss (Comb)=-1.1550
Epoch 200/1000: D Loss=-0.1834, G Loss (Comb)=-0.4045
Epoch 250/1000: D Loss=-0.3698, G Loss (Comb)=0.6983
Epoch 300/1000: D Loss=-0.3721, G Loss (Comb)=1.7026
Epoch 350/1000: D Loss=-0.2325, G Loss (Comb)=2.0457
Epoch 400/1000: D Loss=-0.4445, G Loss (Comb)=1.7563
Epoch 450/1000: D Loss=-0.4350, G Loss (Comb)=1.4122
Epoch 500/1000: D Loss=-0.5477, G Loss (Comb)=0.5251
Epoch 550/1000: D Loss=-0.2926, G Loss (Comb)=-0.3455
Epoch 600/1000: D Loss=-0.5397, G Loss (Comb)=-1.1157
Epoch 650/1000: D Loss=-0.5307, G Loss (Comb)=-1.1232
Epoch 700/1000: D Loss=-0.4815, G Loss (Comb)=-2.0100
Epoch 750/1000: D Loss=-0.6458, G Loss (Comb)=-2.4872
Epoch 800/1000: D Loss=-0.7533, G Loss (Comb)=-2.7448
Epoch 850/1000: D Loss=-0.7742, G Loss (Comb)=-3.0509
Epoch 900/1000: D Loss=-0.7437, G Loss (Comb)=-3.1251
Epoch 950/1000: D Loss=-0.8331, G Loss (Comb)=-3.0642
Epoch 999/1000: D Loss=-0.9106, G Loss (Comb)=-3.4282

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0306
    Run 1, Batch 2: ERP Similarity Score: -0.0303
    Run 1, Batch 3: ERP Similarity Score: -0.0344
    Run 1, Batch 4: ERP Similarity Score: -0.0341
    Run 1, Batch 5: ERP Similarity Score: -0.0304
    Run 1, Batch 6: ERP Similarity Score: -0.0277
    Run 1, Batch 7: ERP Similarity Score: -0.0413
    Run 1, Batch 8: ERP Similarity Score: -0.0374
    Run 1, Batch 9: ERP Similarity Score: -0.0303
    Run 1, Batch 10: ERP Similarity Score: -0.0294
    Run 1, Batch 11: ERP Similarity Score: -0.0266
    Run 1, Batch 12: ERP Similarity Score: -0.0301
    Run 1, Batch 13: ERP Similarity Score: -0.0377
    Run 1, Batch 14: ERP Similarity Score: -0.0334
    Run 1, Batch 15: ERP Similarity Score: -0.0288
    Run 1, Batch 16: ERP Similarity Score: -0.0384
    Run 1, Batch 17: ERP Similarity Score: -0.0294
    Run 1, Batch 18: ERP Similarity Score: -0.0277
    Run 1, Batch 19: ERP Similarity Score: -0.0325
    Run 1, Batch 20: ERP Similarity Score: -0.0363
    Run 1, Batch 21: ERP Similarity Score: -0.0301
    Run 1, Batch 22: ERP Similarity Score: -0.0316
    Run 1, Batch 23: ERP Similarity Score: -0.0352
    Run 1, Batch 24: ERP Similarity Score: -0.0298
    Run 1, Batch 25: ERP Similarity Score: -0.0371
    Run 1, Batch 26: ERP Similarity Score: -0.0325
    Run 1, Batch 27: ERP Similarity Score: -0.0285
    Run 1, Batch 28: ERP Similarity Score: -0.0322
    Run 1, Batch 29: ERP Similarity Score: -0.0383
    Run 1, Batch 30: ERP Similarity Score: -0.0283

--- Training cWGAN-GP for Subject 5-6, Run 2 ---
Epoch 0/1000: D Loss=75.5853, G Loss (Comb)=2.2581
Epoch 50/1000: D Loss=-0.6069, G Loss (Comb)=-3.3557
Epoch 100/1000: D Loss=-0.2371, G Loss (Comb)=-2.7521
Epoch 150/1000: D Loss=-0.1980, G Loss (Comb)=-2.2186
Epoch 200/1000: D Loss=-0.2047, G Loss (Comb)=-1.4996
Epoch 250/1000: D Loss=-0.3013, G Loss (Comb)=-0.8537
Epoch 300/1000: D Loss=-0.3862, G Loss (Comb)=0.0187
Epoch 350/1000: D Loss=-0.3263, G Loss (Comb)=0.4930
Epoch 400/1000: D Loss=-0.3253, G Loss (Comb)=0.3347
Epoch 450/1000: D Loss=-0.5249, G Loss (Comb)=-0.3596
Epoch 500/1000: D Loss=-0.4405, G Loss (Comb)=-0.4274
Epoch 550/1000: D Loss=-0.3786, G Loss (Comb)=-0.7324
Epoch 600/1000: D Loss=-0.4969, G Loss (Comb)=-1.6735
Epoch 650/1000: D Loss=-0.6105, G Loss (Comb)=-2.1319
Epoch 700/1000: D Loss=-0.6491, G Loss (Comb)=-2.5691
Epoch 750/1000: D Loss=-0.6524, G Loss (Comb)=-2.6703
Epoch 800/1000: D Loss=-0.7982, G Loss (Comb)=-2.4627
Epoch 850/1000: D Loss=-0.8344, G Loss (Comb)=-2.6636
Epoch 900/1000: D Loss=-0.8457, G Loss (Comb)=-2.6970
Epoch 950/1000: D Loss=-0.9170, G Loss (Comb)=-2.6149
Epoch 999/1000: D Loss=-0.8866, G Loss (Comb)=-2.6330

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0352
    Run 2, Batch 2: ERP Similarity Score: -0.0497
    Run 2, Batch 3: ERP Similarity Score: -0.0302
    Run 2, Batch 4: ERP Similarity Score: -0.0316
    Run 2, Batch 5: ERP Similarity Score: -0.0320
    Run 2, Batch 6: ERP Similarity Score: -0.0335
    Run 2, Batch 7: ERP Similarity Score: -0.0352
    Run 2, Batch 8: ERP Similarity Score: -0.0441
    Run 2, Batch 9: ERP Similarity Score: -0.0343
    Run 2, Batch 10: ERP Similarity Score: -0.0347
    Run 2, Batch 11: ERP Similarity Score: -0.0367
    Run 2, Batch 12: ERP Similarity Score: -0.0353
    Run 2, Batch 13: ERP Similarity Score: -0.0343
    Run 2, Batch 14: ERP Similarity Score: -0.0361
    Run 2, Batch 15: ERP Similarity Score: -0.0510
    Run 2, Batch 16: ERP Similarity Score: -0.0318
    Run 2, Batch 17: ERP Similarity Score: -0.0333
    Run 2, Batch 18: ERP Similarity Score: -0.0376
    Run 2, Batch 19: ERP Similarity Score: -0.0362
    Run 2, Batch 20: ERP Similarity Score: -0.0354
    Run 2, Batch 21: ERP Similarity Score: -0.0303
    Run 2, Batch 22: ERP Similarity Score: -0.0388
    Run 2, Batch 23: ERP Similarity Score: -0.0398
    Run 2, Batch 24: ERP Similarity Score: -0.0299
    Run 2, Batch 25: ERP Similarity Score: -0.0317
    Run 2, Batch 26: ERP Similarity Score: -0.0363
    Run 2, Batch 27: ERP Similarity Score: -0.0415
    Run 2, Batch 28: ERP Similarity Score: -0.0330
    Run 2, Batch 29: ERP Similarity Score: -0.0338
    Run 2, Batch 30: ERP Similarity Score: -0.0325

--- Training cWGAN-GP for Subject 5-6, Run 3 ---
Epoch 0/1000: D Loss=80.0583, G Loss (Comb)=-0.2023
Epoch 50/1000: D Loss=-0.4334, G Loss (Comb)=-5.3751
Epoch 100/1000: D Loss=-0.2642, G Loss (Comb)=-4.8236
Epoch 150/1000: D Loss=-0.3904, G Loss (Comb)=-4.3973
Epoch 200/1000: D Loss=-0.2644, G Loss (Comb)=-3.7572
Epoch 250/1000: D Loss=-0.1103, G Loss (Comb)=-3.2087
Epoch 300/1000: D Loss=-0.3735, G Loss (Comb)=-2.1601
Epoch 350/1000: D Loss=-0.3845, G Loss (Comb)=-2.1106
Epoch 400/1000: D Loss=-0.4251, G Loss (Comb)=-1.8348
Epoch 450/1000: D Loss=-0.5665, G Loss (Comb)=-2.5027
Epoch 500/1000: D Loss=-0.4980, G Loss (Comb)=-2.5153
Epoch 550/1000: D Loss=-0.5927, G Loss (Comb)=-3.4167
Epoch 600/1000: D Loss=-0.6031, G Loss (Comb)=-3.6364
Epoch 650/1000: D Loss=-0.7269, G Loss (Comb)=-3.7882
Epoch 700/1000: D Loss=-0.8193, G Loss (Comb)=-4.0600
Epoch 750/1000: D Loss=-0.7951, G Loss (Comb)=-4.0532
Epoch 800/1000: D Loss=-0.8278, G Loss (Comb)=-4.0367
Epoch 850/1000: D Loss=-0.9104, G Loss (Comb)=-4.0204
Epoch 900/1000: D Loss=-0.9212, G Loss (Comb)=-4.4504
Epoch 950/1000: D Loss=-0.9836, G Loss (Comb)=-4.4338
Epoch 999/1000: D Loss=-1.0409, G Loss (Comb)=-4.4856

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0289
    Run 3, Batch 2: ERP Similarity Score: -0.0296
    Run 3, Batch 3: ERP Similarity Score: -0.0334
    Run 3, Batch 4: ERP Similarity Score: -0.0329
    Run 3, Batch 5: ERP Similarity Score: -0.0312
    Run 3, Batch 6: ERP Similarity Score: -0.0313
    Run 3, Batch 7: ERP Similarity Score: -0.0297
    Run 3, Batch 8: ERP Similarity Score: -0.0353
    Run 3, Batch 9: ERP Similarity Score: -0.0313
    Run 3, Batch 10: ERP Similarity Score: -0.0341
    Run 3, Batch 11: ERP Similarity Score: -0.0327
    Run 3, Batch 12: ERP Similarity Score: -0.0274
    Run 3, Batch 13: ERP Similarity Score: -0.0318
    Run 3, Batch 14: ERP Similarity Score: -0.0352
    Run 3, Batch 15: ERP Similarity Score: -0.0295
    Run 3, Batch 16: ERP Similarity Score: -0.0302
    Run 3, Batch 17: ERP Similarity Score: -0.0276
    Run 3, Batch 18: ERP Similarity Score: -0.0431
    Run 3, Batch 19: ERP Similarity Score: -0.0327
    Run 3, Batch 20: ERP Similarity Score: -0.0353
    Run 3, Batch 21: ERP Similarity Score: -0.0293
    Run 3, Batch 22: ERP Similarity Score: -0.0337
    Run 3, Batch 23: ERP Similarity Score: -0.0322
    Run 3, Batch 24: ERP Similarity Score: -0.0309
    Run 3, Batch 25: ERP Similarity Score: -0.0337
    Run 3, Batch 26: ERP Similarity Score: -0.0308
    Run 3, Batch 27: ERP Similarity Score: -0.0369
    Run 3, Batch 28: ERP Similarity Score: -0.0278
    Run 3, Batch 29: ERP Similarity Score: -0.0306
    Run 3, Batch 30: ERP Similarity Score: -0.0372

--- Training cWGAN-GP for Subject 5-6, Run 4 ---
Epoch 0/1000: D Loss=62.6460, G Loss (Comb)=0.7141
Epoch 50/1000: D Loss=-0.5413, G Loss (Comb)=-3.5976
Epoch 100/1000: D Loss=-0.2439, G Loss (Comb)=-3.4293
Epoch 150/1000: D Loss=-0.2638, G Loss (Comb)=-2.4212
Epoch 200/1000: D Loss=-0.1717, G Loss (Comb)=-2.0378
Epoch 250/1000: D Loss=-0.3928, G Loss (Comb)=-0.7180
Epoch 300/1000: D Loss=-0.3632, G Loss (Comb)=-0.5777
Epoch 350/1000: D Loss=-0.4100, G Loss (Comb)=-0.5870
Epoch 400/1000: D Loss=-0.4844, G Loss (Comb)=-0.8134
Epoch 450/1000: D Loss=-0.5223, G Loss (Comb)=-0.8048
Epoch 500/1000: D Loss=-0.5790, G Loss (Comb)=-1.4599
Epoch 550/1000: D Loss=-0.6143, G Loss (Comb)=-2.6086
Epoch 600/1000: D Loss=-0.6655, G Loss (Comb)=-2.1542
Epoch 650/1000: D Loss=-0.5568, G Loss (Comb)=-2.8679
Epoch 700/1000: D Loss=-0.7929, G Loss (Comb)=-3.0883
Epoch 750/1000: D Loss=-0.7955, G Loss (Comb)=-2.8627
Epoch 800/1000: D Loss=-0.8093, G Loss (Comb)=-3.1653
Epoch 850/1000: D Loss=-0.8779, G Loss (Comb)=-2.9704
Epoch 900/1000: D Loss=-0.8939, G Loss (Comb)=-3.3501
Epoch 950/1000: D Loss=-0.9512, G Loss (Comb)=-3.5848
Epoch 999/1000: D Loss=-1.0249, G Loss (Comb)=-3.4910

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0324
    Run 4, Batch 2: ERP Similarity Score: -0.0361
    Run 4, Batch 3: ERP Similarity Score: -0.0311
    Run 4, Batch 4: ERP Similarity Score: -0.0287
    Run 4, Batch 5: ERP Similarity Score: -0.0361
    Run 4, Batch 6: ERP Similarity Score: -0.0388
    Run 4, Batch 7: ERP Similarity Score: -0.0313
    Run 4, Batch 8: ERP Similarity Score: -0.0339
    Run 4, Batch 9: ERP Similarity Score: -0.0303
    Run 4, Batch 10: ERP Similarity Score: -0.0384
    Run 4, Batch 11: ERP Similarity Score: -0.0324
    Run 4, Batch 12: ERP Similarity Score: -0.0372
    Run 4, Batch 13: ERP Similarity Score: -0.0342
    Run 4, Batch 14: ERP Similarity Score: -0.0350
    Run 4, Batch 15: ERP Similarity Score: -0.0358
    Run 4, Batch 16: ERP Similarity Score: -0.0314
    Run 4, Batch 17: ERP Similarity Score: -0.0343
    Run 4, Batch 18: ERP Similarity Score: -0.0390
    Run 4, Batch 19: ERP Similarity Score: -0.0342
    Run 4, Batch 20: ERP Similarity Score: -0.0331
    Run 4, Batch 21: ERP Similarity Score: -0.0328
    Run 4, Batch 22: ERP Similarity Score: -0.0328
    Run 4, Batch 23: ERP Similarity Score: -0.0334
    Run 4, Batch 24: ERP Similarity Score: -0.0329
    Run 4, Batch 25: ERP Similarity Score: -0.0322
    Run 4, Batch 26: ERP Similarity Score: -0.0378
    Run 4, Batch 27: ERP Similarity Score: -0.0312
    Run 4, Batch 28: ERP Similarity Score: -0.0352
    Run 4, Batch 29: ERP Similarity Score: -0.0336
    Run 4, Batch 30: ERP Similarity Score: -0.0317

--- Training cWGAN-GP for Subject 5-6, Run 5 ---
Epoch 0/1000: D Loss=76.2668, G Loss (Comb)=0.8161
Epoch 50/1000: D Loss=-0.5433, G Loss (Comb)=-3.8990
Epoch 100/1000: D Loss=-0.3061, G Loss (Comb)=-3.4643
Epoch 150/1000: D Loss=-0.3144, G Loss (Comb)=-2.2378
Epoch 200/1000: D Loss=-0.3399, G Loss (Comb)=-2.2432
Epoch 250/1000: D Loss=-0.2299, G Loss (Comb)=-1.6172
Epoch 300/1000: D Loss=-0.2798, G Loss (Comb)=-1.3943
Epoch 350/1000: D Loss=-0.3420, G Loss (Comb)=-0.6022
Epoch 400/1000: D Loss=-0.4819, G Loss (Comb)=-0.3512
Epoch 450/1000: D Loss=-0.4712, G Loss (Comb)=-0.6661
Epoch 500/1000: D Loss=-0.5818, G Loss (Comb)=-1.1868
Epoch 550/1000: D Loss=-0.5650, G Loss (Comb)=-2.0032
Epoch 600/1000: D Loss=-0.6031, G Loss (Comb)=-2.7757
Epoch 650/1000: D Loss=-0.6907, G Loss (Comb)=-3.1052
Epoch 700/1000: D Loss=-0.7799, G Loss (Comb)=-2.9161
Epoch 750/1000: D Loss=-0.7877, G Loss (Comb)=-3.2268
Epoch 800/1000: D Loss=-0.8510, G Loss (Comb)=-3.3250
Epoch 850/1000: D Loss=-0.9035, G Loss (Comb)=-3.5407
Epoch 900/1000: D Loss=-0.9676, G Loss (Comb)=-3.6620
Epoch 950/1000: D Loss=-0.9955, G Loss (Comb)=-3.4014
Epoch 999/1000: D Loss=-1.0287, G Loss (Comb)=-3.4762

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0321
    Run 5, Batch 2: ERP Similarity Score: -0.0310
    Run 5, Batch 3: ERP Similarity Score: -0.0315
    Run 5, Batch 4: ERP Similarity Score: -0.0352
    Run 5, Batch 5: ERP Similarity Score: -0.0379
    Run 5, Batch 6: ERP Similarity Score: -0.0394
    Run 5, Batch 7: ERP Similarity Score: -0.0289
    Run 5, Batch 8: ERP Similarity Score: -0.0333
    Run 5, Batch 9: ERP Similarity Score: -0.0328
    Run 5, Batch 10: ERP Similarity Score: -0.0322
    Run 5, Batch 11: ERP Similarity Score: -0.0369
    Run 5, Batch 12: ERP Similarity Score: -0.0430
    Run 5, Batch 13: ERP Similarity Score: -0.0404
    Run 5, Batch 14: ERP Similarity Score: -0.0374
    Run 5, Batch 15: ERP Similarity Score: -0.0401
    Run 5, Batch 16: ERP Similarity Score: -0.0385
    Run 5, Batch 17: ERP Similarity Score: -0.0432
    Run 5, Batch 18: ERP Similarity Score: -0.0345
    Run 5, Batch 19: ERP Similarity Score: -0.0377
    Run 5, Batch 20: ERP Similarity Score: -0.0296
    Run 5, Batch 21: ERP Similarity Score: -0.0315
    Run 5, Batch 22: ERP Similarity Score: -0.0311
    Run 5, Batch 23: ERP Similarity Score: -0.0407
    Run 5, Batch 24: ERP Similarity Score: -0.0312
    Run 5, Batch 25: ERP Similarity Score: -0.0302
    Run 5, Batch 26: ERP Similarity Score: -0.0331
    Run 5, Batch 27: ERP Similarity Score: -0.0331
    Run 5, Batch 28: ERP Similarity Score: -0.0314
    Run 5, Batch 29: ERP Similarity Score: -0.0316
    Run 5, Batch 30: ERP Similarity Score: -0.0343


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 1, Batch 11, Score: -0.0266
  Top 2: Run 3, Batch 12, Score: -0.0274
  Top 3: Run 3, Batch 17, Score: -0.0276
  Top 4: Run 1, Batch 18, Score: -0.0277
  Top 5: Run 1, Batch 6, Score: -0.0277
  Top 6: Run 3, Batch 28, Score: -0.0278
  Top 7: Run 1, Batch 30, Score: -0.0283
  Top 8: Run 1, Batch 27, Score: -0.0285
  Top 9: Run 4, Batch 4, Score: -0.0287
  Top 10: Run 1, Batch 15, Score: -0.0288

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 1, Batch 11, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 1, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 12, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 3, Batch 12, Strategy 'Augmented (25%)': Validation Acc: 20.00%
    Run 3, Batch 12, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 12, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 17, Strategy 'Synth Only': Validation Acc: 20.00%
    Run 3, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 18, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 1, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 1, Batch 6, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 1, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 3, Batch 28, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 30, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 20.00%
    Run 1, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 27, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 1, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 1, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 4, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 15, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 1, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 80.00%

Found 12 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 1, Batch 11, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0266
  - Strategy (Run 3, Batch 12, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0274
  - Strategy (Run 3, Batch 17, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0276
  - Strategy (Run 3, Batch 17, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0276
  - Strategy (Run 3, Batch 17, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0276
  - Strategy (Run 3, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0278
  - Strategy (Run 1, Batch 30, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0283
  - Strategy (Run 1, Batch 27, Ratio 0): Accuracy=100.00, ERP Score=-0.0285
  - Strategy (Run 1, Batch 27, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0285
  - Strategy (Run 4, Batch 4, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0287
  - Strategy (Run 4, Batch 4, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0287
  - Strategy (Run 1, Batch 15, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0288

Selected best strategy: Run 1, Batch 11, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 77.36%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 88.68%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H9_results/Subject_5-6_results/target_synthetic_data_S5-6.mat
Saved non-target class of best synthetic batch to H9_results/Subject_5-6_results/nontarget_synthetic_data_S5-6.mat
Saved target class of training data to H9_results/Subject_5-6_results/target_training_data_S5-6.mat
Saved non-target class of training data to H9_results/Subject_5-6_results/nontarget_training_data_S5-6.mat

Saved accuracy comparison plot to: H9_results/Subject_5-6_results/accuracy_comparison_S5-6.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 5-6) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H9_results/Subject_5-6_results/GA_ERP_Combined_S5-6_ChCz.png

--- Subject 5-6 processing finished successfully. ---
