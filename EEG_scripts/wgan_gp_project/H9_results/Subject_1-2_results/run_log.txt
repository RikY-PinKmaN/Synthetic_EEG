Log for Subject Pair 1-2 from H9
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H9 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 209 clean Target and 397 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 381

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 24

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 70.83%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=78.7654, G Loss (Comb)=2.1306
Epoch 50/1000: D Loss=-1.5178, G Loss (Comb)=0.4328
Epoch 100/1000: D Loss=-0.7245, G Loss (Comb)=-1.9345
Epoch 150/1000: D Loss=-0.3564, G Loss (Comb)=-1.7836
Epoch 200/1000: D Loss=-0.3323, G Loss (Comb)=-1.2912
Epoch 250/1000: D Loss=-0.4773, G Loss (Comb)=-0.8202
Epoch 300/1000: D Loss=-0.3144, G Loss (Comb)=-0.6815
Epoch 350/1000: D Loss=-0.4209, G Loss (Comb)=0.1574
Epoch 400/1000: D Loss=-0.5288, G Loss (Comb)=0.0202
Epoch 450/1000: D Loss=-0.6317, G Loss (Comb)=0.5303
Epoch 500/1000: D Loss=-0.6720, G Loss (Comb)=0.6857
Epoch 550/1000: D Loss=-0.6128, G Loss (Comb)=0.6846
Epoch 600/1000: D Loss=-0.7810, G Loss (Comb)=0.4568
Epoch 650/1000: D Loss=-0.8527, G Loss (Comb)=0.3758
Epoch 700/1000: D Loss=-0.8193, G Loss (Comb)=0.0235
Epoch 750/1000: D Loss=-0.9103, G Loss (Comb)=-0.0111
Epoch 800/1000: D Loss=-0.9804, G Loss (Comb)=-0.0480
Epoch 850/1000: D Loss=-1.0450, G Loss (Comb)=-0.1489
Epoch 900/1000: D Loss=-1.1394, G Loss (Comb)=-0.1811
Epoch 950/1000: D Loss=-1.1232, G Loss (Comb)=-0.4141
Epoch 999/1000: D Loss=-1.1246, G Loss (Comb)=-0.3478

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0294
    Run 1, Batch 2: ERP Similarity Score: -0.0322
    Run 1, Batch 3: ERP Similarity Score: -0.0317
    Run 1, Batch 4: ERP Similarity Score: -0.0324
    Run 1, Batch 5: ERP Similarity Score: -0.0333
    Run 1, Batch 6: ERP Similarity Score: -0.0396
    Run 1, Batch 7: ERP Similarity Score: -0.0354
    Run 1, Batch 8: ERP Similarity Score: -0.0316
    Run 1, Batch 9: ERP Similarity Score: -0.0343
    Run 1, Batch 10: ERP Similarity Score: -0.0305
    Run 1, Batch 11: ERP Similarity Score: -0.0391
    Run 1, Batch 12: ERP Similarity Score: -0.0315
    Run 1, Batch 13: ERP Similarity Score: -0.0317
    Run 1, Batch 14: ERP Similarity Score: -0.0408
    Run 1, Batch 15: ERP Similarity Score: -0.0361
    Run 1, Batch 16: ERP Similarity Score: -0.0295
    Run 1, Batch 17: ERP Similarity Score: -0.0367
    Run 1, Batch 18: ERP Similarity Score: -0.0303
    Run 1, Batch 19: ERP Similarity Score: -0.0315
    Run 1, Batch 20: ERP Similarity Score: -0.0348
    Run 1, Batch 21: ERP Similarity Score: -0.0341
    Run 1, Batch 22: ERP Similarity Score: -0.0304
    Run 1, Batch 23: ERP Similarity Score: -0.0293
    Run 1, Batch 24: ERP Similarity Score: -0.0319
    Run 1, Batch 25: ERP Similarity Score: -0.0304
    Run 1, Batch 26: ERP Similarity Score: -0.0284
    Run 1, Batch 27: ERP Similarity Score: -0.0327
    Run 1, Batch 28: ERP Similarity Score: -0.0308
    Run 1, Batch 29: ERP Similarity Score: -0.0381
    Run 1, Batch 30: ERP Similarity Score: -0.0321

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=62.2720, G Loss (Comb)=1.4051
Epoch 50/1000: D Loss=-1.7596, G Loss (Comb)=-1.0183
Epoch 100/1000: D Loss=-0.4874, G Loss (Comb)=-3.8298
Epoch 150/1000: D Loss=-0.5555, G Loss (Comb)=-3.5206
Epoch 200/1000: D Loss=-0.4155, G Loss (Comb)=-3.0696
Epoch 250/1000: D Loss=-0.3826, G Loss (Comb)=-2.5995
Epoch 300/1000: D Loss=-0.2073, G Loss (Comb)=-2.0841
Epoch 350/1000: D Loss=-0.3247, G Loss (Comb)=-2.1925
Epoch 400/1000: D Loss=-0.3209, G Loss (Comb)=-1.9385
Epoch 450/1000: D Loss=-0.4103, G Loss (Comb)=-1.6881
Epoch 500/1000: D Loss=-0.5023, G Loss (Comb)=-1.0339
Epoch 550/1000: D Loss=-0.7299, G Loss (Comb)=-0.9725
Epoch 600/1000: D Loss=-0.6634, G Loss (Comb)=-1.3650
Epoch 650/1000: D Loss=-0.7616, G Loss (Comb)=-1.6623
Epoch 700/1000: D Loss=-0.7871, G Loss (Comb)=-1.7328
Epoch 750/1000: D Loss=-0.8011, G Loss (Comb)=-2.0880
Epoch 800/1000: D Loss=-0.9655, G Loss (Comb)=-1.9757
Epoch 850/1000: D Loss=-0.8285, G Loss (Comb)=-2.4180
Epoch 900/1000: D Loss=-0.9164, G Loss (Comb)=-2.5060
Epoch 950/1000: D Loss=-1.0481, G Loss (Comb)=-2.6665
Epoch 999/1000: D Loss=-1.0542, G Loss (Comb)=-2.6590

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0393
    Run 2, Batch 2: ERP Similarity Score: -0.0347
    Run 2, Batch 3: ERP Similarity Score: -0.0421
    Run 2, Batch 4: ERP Similarity Score: -0.0351
    Run 2, Batch 5: ERP Similarity Score: -0.0421
    Run 2, Batch 6: ERP Similarity Score: -0.0375
    Run 2, Batch 7: ERP Similarity Score: -0.0367
    Run 2, Batch 8: ERP Similarity Score: -0.0390
    Run 2, Batch 9: ERP Similarity Score: -0.0350
    Run 2, Batch 10: ERP Similarity Score: -0.0348
    Run 2, Batch 11: ERP Similarity Score: -0.0345
    Run 2, Batch 12: ERP Similarity Score: -0.0367
    Run 2, Batch 13: ERP Similarity Score: -0.0334
    Run 2, Batch 14: ERP Similarity Score: -0.0325
    Run 2, Batch 15: ERP Similarity Score: -0.0326
    Run 2, Batch 16: ERP Similarity Score: -0.0345
    Run 2, Batch 17: ERP Similarity Score: -0.0463
    Run 2, Batch 18: ERP Similarity Score: -0.0413
    Run 2, Batch 19: ERP Similarity Score: -0.0416
    Run 2, Batch 20: ERP Similarity Score: -0.0441
    Run 2, Batch 21: ERP Similarity Score: -0.0332
    Run 2, Batch 22: ERP Similarity Score: -0.0332
    Run 2, Batch 23: ERP Similarity Score: -0.0433
    Run 2, Batch 24: ERP Similarity Score: -0.0459
    Run 2, Batch 25: ERP Similarity Score: -0.0489
    Run 2, Batch 26: ERP Similarity Score: -0.0364
    Run 2, Batch 27: ERP Similarity Score: -0.0404
    Run 2, Batch 28: ERP Similarity Score: -0.0325
    Run 2, Batch 29: ERP Similarity Score: -0.0426
    Run 2, Batch 30: ERP Similarity Score: -0.0463

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=84.9160, G Loss (Comb)=0.2644
Epoch 50/1000: D Loss=-1.6468, G Loss (Comb)=-1.4760
Epoch 100/1000: D Loss=-0.4900, G Loss (Comb)=-5.1286
Epoch 150/1000: D Loss=-0.4233, G Loss (Comb)=-4.1761
Epoch 200/1000: D Loss=-0.4864, G Loss (Comb)=-4.4584
Epoch 250/1000: D Loss=-0.3058, G Loss (Comb)=-4.2636
Epoch 300/1000: D Loss=-0.2223, G Loss (Comb)=-3.7577
Epoch 350/1000: D Loss=-0.3725, G Loss (Comb)=-3.7266
Epoch 400/1000: D Loss=-0.3001, G Loss (Comb)=-3.8238
Epoch 450/1000: D Loss=-0.4054, G Loss (Comb)=-2.8432
Epoch 500/1000: D Loss=-0.5639, G Loss (Comb)=-2.8360
Epoch 550/1000: D Loss=-0.5557, G Loss (Comb)=-2.9783
Epoch 600/1000: D Loss=-0.6783, G Loss (Comb)=-2.6936
Epoch 650/1000: D Loss=-0.6382, G Loss (Comb)=-2.7277
Epoch 700/1000: D Loss=-0.7600, G Loss (Comb)=-2.5175
Epoch 750/1000: D Loss=-0.8010, G Loss (Comb)=-3.1237
Epoch 800/1000: D Loss=-0.7765, G Loss (Comb)=-3.2655
Epoch 850/1000: D Loss=-0.9029, G Loss (Comb)=-3.5092
Epoch 900/1000: D Loss=-0.9690, G Loss (Comb)=-3.4929
Epoch 950/1000: D Loss=-1.0228, G Loss (Comb)=-3.7502
Epoch 999/1000: D Loss=-1.0552, G Loss (Comb)=-3.8808

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0357
    Run 3, Batch 2: ERP Similarity Score: -0.0364
    Run 3, Batch 3: ERP Similarity Score: -0.0362
    Run 3, Batch 4: ERP Similarity Score: -0.0433
    Run 3, Batch 5: ERP Similarity Score: -0.0434
    Run 3, Batch 6: ERP Similarity Score: -0.0358
    Run 3, Batch 7: ERP Similarity Score: -0.0447
    Run 3, Batch 8: ERP Similarity Score: -0.0432
    Run 3, Batch 9: ERP Similarity Score: -0.0359
    Run 3, Batch 10: ERP Similarity Score: -0.0403
    Run 3, Batch 11: ERP Similarity Score: -0.0377
    Run 3, Batch 12: ERP Similarity Score: -0.0374
    Run 3, Batch 13: ERP Similarity Score: -0.0484
    Run 3, Batch 14: ERP Similarity Score: -0.0442
    Run 3, Batch 15: ERP Similarity Score: -0.0378
    Run 3, Batch 16: ERP Similarity Score: -0.0402
    Run 3, Batch 17: ERP Similarity Score: -0.0346
    Run 3, Batch 18: ERP Similarity Score: -0.0409
    Run 3, Batch 19: ERP Similarity Score: -0.0351
    Run 3, Batch 20: ERP Similarity Score: -0.0431
    Run 3, Batch 21: ERP Similarity Score: -0.0402
    Run 3, Batch 22: ERP Similarity Score: -0.0420
    Run 3, Batch 23: ERP Similarity Score: -0.0426
    Run 3, Batch 24: ERP Similarity Score: -0.0354
    Run 3, Batch 25: ERP Similarity Score: -0.0405
    Run 3, Batch 26: ERP Similarity Score: -0.0432
    Run 3, Batch 27: ERP Similarity Score: -0.0369
    Run 3, Batch 28: ERP Similarity Score: -0.0400
    Run 3, Batch 29: ERP Similarity Score: -0.0376
    Run 3, Batch 30: ERP Similarity Score: -0.0395

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=80.7176, G Loss (Comb)=0.8968
Epoch 50/1000: D Loss=-1.5218, G Loss (Comb)=-1.2845
Epoch 100/1000: D Loss=-0.6897, G Loss (Comb)=-3.9407
Epoch 150/1000: D Loss=-0.3594, G Loss (Comb)=-3.8539
Epoch 200/1000: D Loss=-0.4091, G Loss (Comb)=-3.5124
Epoch 250/1000: D Loss=-0.3126, G Loss (Comb)=-3.2806
Epoch 300/1000: D Loss=-0.3725, G Loss (Comb)=-2.4354
Epoch 350/1000: D Loss=-0.3932, G Loss (Comb)=-1.9885
Epoch 400/1000: D Loss=-0.5662, G Loss (Comb)=-1.7137
Epoch 450/1000: D Loss=-0.5779, G Loss (Comb)=-0.9098
Epoch 500/1000: D Loss=-0.5730, G Loss (Comb)=-1.3716
Epoch 550/1000: D Loss=-0.6424, G Loss (Comb)=-0.8740
Epoch 600/1000: D Loss=-0.6972, G Loss (Comb)=-0.9578
Epoch 650/1000: D Loss=-0.8773, G Loss (Comb)=-1.0788
Epoch 700/1000: D Loss=-0.8690, G Loss (Comb)=-1.1017
Epoch 750/1000: D Loss=-0.8249, G Loss (Comb)=-1.1132
Epoch 800/1000: D Loss=-1.0315, G Loss (Comb)=-1.0736
Epoch 850/1000: D Loss=-0.9731, G Loss (Comb)=-1.2852
Epoch 900/1000: D Loss=-1.0385, G Loss (Comb)=-1.2366
Epoch 950/1000: D Loss=-1.1273, G Loss (Comb)=-1.4325
Epoch 999/1000: D Loss=-1.1139, G Loss (Comb)=-1.4350

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0292
    Run 4, Batch 2: ERP Similarity Score: -0.0371
    Run 4, Batch 3: ERP Similarity Score: -0.0274
    Run 4, Batch 4: ERP Similarity Score: -0.0313
    Run 4, Batch 5: ERP Similarity Score: -0.0366
    Run 4, Batch 6: ERP Similarity Score: -0.0283
    Run 4, Batch 7: ERP Similarity Score: -0.0321
    Run 4, Batch 8: ERP Similarity Score: -0.0349
    Run 4, Batch 9: ERP Similarity Score: -0.0335
    Run 4, Batch 10: ERP Similarity Score: -0.0304
    Run 4, Batch 11: ERP Similarity Score: -0.0331
    Run 4, Batch 12: ERP Similarity Score: -0.0328
    Run 4, Batch 13: ERP Similarity Score: -0.0327
    Run 4, Batch 14: ERP Similarity Score: -0.0337
    Run 4, Batch 15: ERP Similarity Score: -0.0309
    Run 4, Batch 16: ERP Similarity Score: -0.0304
    Run 4, Batch 17: ERP Similarity Score: -0.0324
    Run 4, Batch 18: ERP Similarity Score: -0.0281
    Run 4, Batch 19: ERP Similarity Score: -0.0307
    Run 4, Batch 20: ERP Similarity Score: -0.0354
    Run 4, Batch 21: ERP Similarity Score: -0.0306
    Run 4, Batch 22: ERP Similarity Score: -0.0329
    Run 4, Batch 23: ERP Similarity Score: -0.0292
    Run 4, Batch 24: ERP Similarity Score: -0.0294
    Run 4, Batch 25: ERP Similarity Score: -0.0312
    Run 4, Batch 26: ERP Similarity Score: -0.0312
    Run 4, Batch 27: ERP Similarity Score: -0.0333
    Run 4, Batch 28: ERP Similarity Score: -0.0293
    Run 4, Batch 29: ERP Similarity Score: -0.0315
    Run 4, Batch 30: ERP Similarity Score: -0.0306

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=68.8598, G Loss (Comb)=0.4302
Epoch 50/1000: D Loss=-1.6070, G Loss (Comb)=-1.2979
Epoch 100/1000: D Loss=-0.3348, G Loss (Comb)=-3.8308
Epoch 150/1000: D Loss=-0.4830, G Loss (Comb)=-2.2202
Epoch 200/1000: D Loss=-0.3336, G Loss (Comb)=-1.9445
Epoch 250/1000: D Loss=-0.3117, G Loss (Comb)=-1.7699
Epoch 300/1000: D Loss=-0.3523, G Loss (Comb)=-0.7400
Epoch 350/1000: D Loss=-0.3849, G Loss (Comb)=-0.2617
Epoch 400/1000: D Loss=-0.3689, G Loss (Comb)=0.2659
Epoch 450/1000: D Loss=-0.4903, G Loss (Comb)=0.1643
Epoch 500/1000: D Loss=-0.5926, G Loss (Comb)=0.0584
Epoch 550/1000: D Loss=-0.5793, G Loss (Comb)=0.3827
Epoch 600/1000: D Loss=-0.6374, G Loss (Comb)=0.5154
Epoch 650/1000: D Loss=-0.5860, G Loss (Comb)=-0.0705
Epoch 700/1000: D Loss=-0.7878, G Loss (Comb)=0.2465
Epoch 750/1000: D Loss=-0.8069, G Loss (Comb)=-0.2822
Epoch 800/1000: D Loss=-0.8111, G Loss (Comb)=-0.4061
Epoch 850/1000: D Loss=-0.8643, G Loss (Comb)=-0.5566
Epoch 900/1000: D Loss=-0.9075, G Loss (Comb)=-0.5223
Epoch 950/1000: D Loss=-1.0831, G Loss (Comb)=-0.7051
Epoch 999/1000: D Loss=-1.0536, G Loss (Comb)=-0.9310

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0312
    Run 5, Batch 2: ERP Similarity Score: -0.0325
    Run 5, Batch 3: ERP Similarity Score: -0.0398
    Run 5, Batch 4: ERP Similarity Score: -0.0315
    Run 5, Batch 5: ERP Similarity Score: -0.0328
    Run 5, Batch 6: ERP Similarity Score: -0.0391
    Run 5, Batch 7: ERP Similarity Score: -0.0333
    Run 5, Batch 8: ERP Similarity Score: -0.0329
    Run 5, Batch 9: ERP Similarity Score: -0.0344
    Run 5, Batch 10: ERP Similarity Score: -0.0336
    Run 5, Batch 11: ERP Similarity Score: -0.0351
    Run 5, Batch 12: ERP Similarity Score: -0.0380
    Run 5, Batch 13: ERP Similarity Score: -0.0360
    Run 5, Batch 14: ERP Similarity Score: -0.0293
    Run 5, Batch 15: ERP Similarity Score: -0.0304
    Run 5, Batch 16: ERP Similarity Score: -0.0397
    Run 5, Batch 17: ERP Similarity Score: -0.0377
    Run 5, Batch 18: ERP Similarity Score: -0.0363
    Run 5, Batch 19: ERP Similarity Score: -0.0288
    Run 5, Batch 20: ERP Similarity Score: -0.0276
    Run 5, Batch 21: ERP Similarity Score: -0.0322
    Run 5, Batch 22: ERP Similarity Score: -0.0433
    Run 5, Batch 23: ERP Similarity Score: -0.0386
    Run 5, Batch 24: ERP Similarity Score: -0.0310
    Run 5, Batch 25: ERP Similarity Score: -0.0392
    Run 5, Batch 26: ERP Similarity Score: -0.0375
    Run 5, Batch 27: ERP Similarity Score: -0.0367
    Run 5, Batch 28: ERP Similarity Score: -0.0378
    Run 5, Batch 29: ERP Similarity Score: -0.0351
    Run 5, Batch 30: ERP Similarity Score: -0.0323


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 4, Batch 3, Score: -0.0274
  Top 2: Run 5, Batch 20, Score: -0.0276
  Top 3: Run 4, Batch 18, Score: -0.0281
  Top 4: Run 4, Batch 6, Score: -0.0283
  Top 5: Run 1, Batch 26, Score: -0.0284
  Top 6: Run 5, Batch 19, Score: -0.0288
  Top 7: Run 4, Batch 23, Score: -0.0292
  Top 8: Run 4, Batch 1, Score: -0.0292
  Top 9: Run 5, Batch 14, Score: -0.0293
  Top 10: Run 4, Batch 28, Score: -0.0293

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 4, Batch 3, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 3, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 3, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 3, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 5, Batch 20, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 5, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 5, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 6, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 5, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 5, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 23, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 23, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 23, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 23, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 1, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 14, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 28, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 33.33%

Found 3 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 18, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0281
  - Strategy (Run 1, Batch 26, Ratio 0): Accuracy=100.00, ERP Score=-0.0284
  - Strategy (Run 4, Batch 28, Ratio 0): Accuracy=100.00, ERP Score=-0.0293

Selected best strategy: Run 4, Batch 18, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 45.83%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 66.67%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H9_results/Subject_1-2_results/target_synthetic_data_S1-2.mat
Saved non-target class of best synthetic batch to H9_results/Subject_1-2_results/nontarget_synthetic_data_S1-2.mat
Saved target class of training data to H9_results/Subject_1-2_results/target_training_data_S1-2.mat
Saved non-target class of training data to H9_results/Subject_1-2_results/nontarget_training_data_S1-2.mat

Saved accuracy comparison plot to: H9_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H9_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
