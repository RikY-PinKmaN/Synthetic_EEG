Log for Subject Pair 7-8 from H11
========================================


========================= PROCESSING SUBJECT PAIR: 7-8 from H11 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 96 clean Target and 624 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 345

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 22

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 86.36%

--- Training cWGAN-GP for Subject 7-8, Run 1 ---
Epoch 0/1000: D Loss=62.7990, G Loss (Comb)=2.0602
Epoch 50/1000: D Loss=-0.4892, G Loss (Comb)=-2.8217
Epoch 100/1000: D Loss=-0.3486, G Loss (Comb)=-2.6343
Epoch 150/1000: D Loss=-0.0890, G Loss (Comb)=-3.8028
Epoch 200/1000: D Loss=-0.3120, G Loss (Comb)=-3.3922
Epoch 250/1000: D Loss=-0.3781, G Loss (Comb)=-3.0105
Epoch 300/1000: D Loss=-0.2893, G Loss (Comb)=-3.1610
Epoch 350/1000: D Loss=-0.4689, G Loss (Comb)=-3.1274
Epoch 400/1000: D Loss=-0.5772, G Loss (Comb)=-3.1256
Epoch 450/1000: D Loss=-0.5564, G Loss (Comb)=-3.4419
Epoch 500/1000: D Loss=-0.7819, G Loss (Comb)=-3.3714
Epoch 550/1000: D Loss=-0.7755, G Loss (Comb)=-3.3590
Epoch 600/1000: D Loss=-0.8767, G Loss (Comb)=-3.1792
Epoch 650/1000: D Loss=-0.9753, G Loss (Comb)=-3.2547
Epoch 700/1000: D Loss=-1.0988, G Loss (Comb)=-3.0594
Epoch 750/1000: D Loss=-1.1254, G Loss (Comb)=-2.9178
Epoch 800/1000: D Loss=-1.1798, G Loss (Comb)=-2.6958
Epoch 850/1000: D Loss=-1.2577, G Loss (Comb)=-2.6053
Epoch 900/1000: D Loss=-1.3524, G Loss (Comb)=-2.5262
Epoch 950/1000: D Loss=-1.3905, G Loss (Comb)=-2.5576
Epoch 999/1000: D Loss=-1.3965, G Loss (Comb)=-2.2961

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0368
    Run 1, Batch 2: ERP Similarity Score: -0.0417
    Run 1, Batch 3: ERP Similarity Score: -0.0381
    Run 1, Batch 4: ERP Similarity Score: -0.0375
    Run 1, Batch 5: ERP Similarity Score: -0.0388
    Run 1, Batch 6: ERP Similarity Score: -0.0400
    Run 1, Batch 7: ERP Similarity Score: -0.0378
    Run 1, Batch 8: ERP Similarity Score: -0.0364
    Run 1, Batch 9: ERP Similarity Score: -0.0386
    Run 1, Batch 10: ERP Similarity Score: -0.0412
    Run 1, Batch 11: ERP Similarity Score: -0.0361
    Run 1, Batch 12: ERP Similarity Score: -0.0404
    Run 1, Batch 13: ERP Similarity Score: -0.0445
    Run 1, Batch 14: ERP Similarity Score: -0.0376
    Run 1, Batch 15: ERP Similarity Score: -0.0372
    Run 1, Batch 16: ERP Similarity Score: -0.0382
    Run 1, Batch 17: ERP Similarity Score: -0.0424
    Run 1, Batch 18: ERP Similarity Score: -0.0387
    Run 1, Batch 19: ERP Similarity Score: -0.0373
    Run 1, Batch 20: ERP Similarity Score: -0.0391
    Run 1, Batch 21: ERP Similarity Score: -0.0366
    Run 1, Batch 22: ERP Similarity Score: -0.0415
    Run 1, Batch 23: ERP Similarity Score: -0.0414
    Run 1, Batch 24: ERP Similarity Score: -0.0385
    Run 1, Batch 25: ERP Similarity Score: -0.0394
    Run 1, Batch 26: ERP Similarity Score: -0.0378
    Run 1, Batch 27: ERP Similarity Score: -0.0439
    Run 1, Batch 28: ERP Similarity Score: -0.0391
    Run 1, Batch 29: ERP Similarity Score: -0.0386
    Run 1, Batch 30: ERP Similarity Score: -0.0399

--- Training cWGAN-GP for Subject 7-8, Run 2 ---
Epoch 0/1000: D Loss=61.4098, G Loss (Comb)=1.7133
Epoch 50/1000: D Loss=-0.5809, G Loss (Comb)=-3.2722
Epoch 100/1000: D Loss=-0.3993, G Loss (Comb)=-2.9513
Epoch 150/1000: D Loss=-0.1726, G Loss (Comb)=-3.3789
Epoch 200/1000: D Loss=-0.3225, G Loss (Comb)=-3.1878
Epoch 250/1000: D Loss=-0.3862, G Loss (Comb)=-3.3257
Epoch 300/1000: D Loss=-0.4347, G Loss (Comb)=-2.8735
Epoch 350/1000: D Loss=-0.5071, G Loss (Comb)=-2.5278
Epoch 400/1000: D Loss=-0.5655, G Loss (Comb)=-2.4746
Epoch 450/1000: D Loss=-0.6440, G Loss (Comb)=-2.3144
Epoch 500/1000: D Loss=-0.8093, G Loss (Comb)=-2.4065
Epoch 550/1000: D Loss=-0.8488, G Loss (Comb)=-2.4999
Epoch 600/1000: D Loss=-0.9566, G Loss (Comb)=-2.3486
Epoch 650/1000: D Loss=-1.0788, G Loss (Comb)=-2.3260
Epoch 700/1000: D Loss=-1.1129, G Loss (Comb)=-2.4941
Epoch 750/1000: D Loss=-1.1794, G Loss (Comb)=-2.4031
Epoch 800/1000: D Loss=-1.1877, G Loss (Comb)=-2.3961
Epoch 850/1000: D Loss=-1.2511, G Loss (Comb)=-2.3096
Epoch 900/1000: D Loss=-1.2899, G Loss (Comb)=-2.4299
Epoch 950/1000: D Loss=-1.3101, G Loss (Comb)=-2.3716
Epoch 999/1000: D Loss=-1.2888, G Loss (Comb)=-2.4023

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0416
    Run 2, Batch 2: ERP Similarity Score: -0.0460
    Run 2, Batch 3: ERP Similarity Score: -0.0440
    Run 2, Batch 4: ERP Similarity Score: -0.0441
    Run 2, Batch 5: ERP Similarity Score: -0.0393
    Run 2, Batch 6: ERP Similarity Score: -0.0414
    Run 2, Batch 7: ERP Similarity Score: -0.0420
    Run 2, Batch 8: ERP Similarity Score: -0.0452
    Run 2, Batch 9: ERP Similarity Score: -0.0433
    Run 2, Batch 10: ERP Similarity Score: -0.0452
    Run 2, Batch 11: ERP Similarity Score: -0.0431
    Run 2, Batch 12: ERP Similarity Score: -0.0489
    Run 2, Batch 13: ERP Similarity Score: -0.0489
    Run 2, Batch 14: ERP Similarity Score: -0.0424
    Run 2, Batch 15: ERP Similarity Score: -0.0410
    Run 2, Batch 16: ERP Similarity Score: -0.0442
    Run 2, Batch 17: ERP Similarity Score: -0.0410
    Run 2, Batch 18: ERP Similarity Score: -0.0430
    Run 2, Batch 19: ERP Similarity Score: -0.0465
    Run 2, Batch 20: ERP Similarity Score: -0.0436
    Run 2, Batch 21: ERP Similarity Score: -0.0470
    Run 2, Batch 22: ERP Similarity Score: -0.0431
    Run 2, Batch 23: ERP Similarity Score: -0.0419
    Run 2, Batch 24: ERP Similarity Score: -0.0422
    Run 2, Batch 25: ERP Similarity Score: -0.0462
    Run 2, Batch 26: ERP Similarity Score: -0.0456
    Run 2, Batch 27: ERP Similarity Score: -0.0432
    Run 2, Batch 28: ERP Similarity Score: -0.0395
    Run 2, Batch 29: ERP Similarity Score: -0.0476
    Run 2, Batch 30: ERP Similarity Score: -0.0401

--- Training cWGAN-GP for Subject 7-8, Run 3 ---
Epoch 0/1000: D Loss=59.5629, G Loss (Comb)=0.2691
Epoch 50/1000: D Loss=-0.8043, G Loss (Comb)=-3.6556
Epoch 100/1000: D Loss=-0.3088, G Loss (Comb)=-4.7083
Epoch 150/1000: D Loss=-0.2550, G Loss (Comb)=-5.0136
Epoch 200/1000: D Loss=-0.3933, G Loss (Comb)=-4.1733
Epoch 250/1000: D Loss=-0.2592, G Loss (Comb)=-4.1956
Epoch 300/1000: D Loss=-0.4801, G Loss (Comb)=-4.5101
Epoch 350/1000: D Loss=-0.5050, G Loss (Comb)=-4.3321
Epoch 400/1000: D Loss=-0.5841, G Loss (Comb)=-4.0054
Epoch 450/1000: D Loss=-0.6997, G Loss (Comb)=-4.0628
Epoch 500/1000: D Loss=-0.8161, G Loss (Comb)=-3.9426
Epoch 550/1000: D Loss=-0.8594, G Loss (Comb)=-4.1275
Epoch 600/1000: D Loss=-1.0033, G Loss (Comb)=-3.9041
Epoch 650/1000: D Loss=-1.0531, G Loss (Comb)=-4.0686
Epoch 700/1000: D Loss=-1.1208, G Loss (Comb)=-4.1505
Epoch 750/1000: D Loss=-1.1637, G Loss (Comb)=-4.0027
Epoch 800/1000: D Loss=-1.2541, G Loss (Comb)=-4.0073
Epoch 850/1000: D Loss=-1.2622, G Loss (Comb)=-3.8072
Epoch 900/1000: D Loss=-1.3313, G Loss (Comb)=-3.8579
Epoch 950/1000: D Loss=-1.3402, G Loss (Comb)=-3.5092
Epoch 999/1000: D Loss=-1.4216, G Loss (Comb)=-3.2970

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0370
    Run 3, Batch 2: ERP Similarity Score: -0.0351
    Run 3, Batch 3: ERP Similarity Score: -0.0404
    Run 3, Batch 4: ERP Similarity Score: -0.0407
    Run 3, Batch 5: ERP Similarity Score: -0.0405
    Run 3, Batch 6: ERP Similarity Score: -0.0398
    Run 3, Batch 7: ERP Similarity Score: -0.0426
    Run 3, Batch 8: ERP Similarity Score: -0.0376
    Run 3, Batch 9: ERP Similarity Score: -0.0411
    Run 3, Batch 10: ERP Similarity Score: -0.0371
    Run 3, Batch 11: ERP Similarity Score: -0.0381
    Run 3, Batch 12: ERP Similarity Score: -0.0404
    Run 3, Batch 13: ERP Similarity Score: -0.0393
    Run 3, Batch 14: ERP Similarity Score: -0.0410
    Run 3, Batch 15: ERP Similarity Score: -0.0381
    Run 3, Batch 16: ERP Similarity Score: -0.0394
    Run 3, Batch 17: ERP Similarity Score: -0.0409
    Run 3, Batch 18: ERP Similarity Score: -0.0410
    Run 3, Batch 19: ERP Similarity Score: -0.0400
    Run 3, Batch 20: ERP Similarity Score: -0.0406
    Run 3, Batch 21: ERP Similarity Score: -0.0428
    Run 3, Batch 22: ERP Similarity Score: -0.0411
    Run 3, Batch 23: ERP Similarity Score: -0.0391
    Run 3, Batch 24: ERP Similarity Score: -0.0377
    Run 3, Batch 25: ERP Similarity Score: -0.0379
    Run 3, Batch 26: ERP Similarity Score: -0.0377
    Run 3, Batch 27: ERP Similarity Score: -0.0427
    Run 3, Batch 28: ERP Similarity Score: -0.0384
    Run 3, Batch 29: ERP Similarity Score: -0.0401
    Run 3, Batch 30: ERP Similarity Score: -0.0413

--- Training cWGAN-GP for Subject 7-8, Run 4 ---
Epoch 0/1000: D Loss=47.7509, G Loss (Comb)=1.5200
Epoch 50/1000: D Loss=-0.5722, G Loss (Comb)=-4.5027
Epoch 100/1000: D Loss=-0.3092, G Loss (Comb)=-4.6863
Epoch 150/1000: D Loss=-0.2064, G Loss (Comb)=-4.5623
Epoch 200/1000: D Loss=-0.2244, G Loss (Comb)=-4.4796
Epoch 250/1000: D Loss=-0.3973, G Loss (Comb)=-3.9231
Epoch 300/1000: D Loss=-0.4339, G Loss (Comb)=-3.4047
Epoch 350/1000: D Loss=-0.5770, G Loss (Comb)=-3.3485
Epoch 400/1000: D Loss=-0.6390, G Loss (Comb)=-3.1841
Epoch 450/1000: D Loss=-0.6881, G Loss (Comb)=-3.0503
Epoch 500/1000: D Loss=-0.8128, G Loss (Comb)=-2.8514
Epoch 550/1000: D Loss=-0.9633, G Loss (Comb)=-2.8729
Epoch 600/1000: D Loss=-0.9964, G Loss (Comb)=-2.9205
Epoch 650/1000: D Loss=-1.0500, G Loss (Comb)=-2.9986
Epoch 700/1000: D Loss=-1.1368, G Loss (Comb)=-2.9077
Epoch 750/1000: D Loss=-1.1891, G Loss (Comb)=-2.8814
Epoch 800/1000: D Loss=-1.2070, G Loss (Comb)=-2.8406
Epoch 850/1000: D Loss=-1.3223, G Loss (Comb)=-2.7356
Epoch 900/1000: D Loss=-1.3823, G Loss (Comb)=-2.7459
Epoch 950/1000: D Loss=-1.3802, G Loss (Comb)=-2.5530
Epoch 999/1000: D Loss=-1.4263, G Loss (Comb)=-2.5601

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0374
    Run 4, Batch 2: ERP Similarity Score: -0.0418
    Run 4, Batch 3: ERP Similarity Score: -0.0412
    Run 4, Batch 4: ERP Similarity Score: -0.0385
    Run 4, Batch 5: ERP Similarity Score: -0.0367
    Run 4, Batch 6: ERP Similarity Score: -0.0391
    Run 4, Batch 7: ERP Similarity Score: -0.0431
    Run 4, Batch 8: ERP Similarity Score: -0.0387
    Run 4, Batch 9: ERP Similarity Score: -0.0426
    Run 4, Batch 10: ERP Similarity Score: -0.0419
    Run 4, Batch 11: ERP Similarity Score: -0.0385
    Run 4, Batch 12: ERP Similarity Score: -0.0388
    Run 4, Batch 13: ERP Similarity Score: -0.0403
    Run 4, Batch 14: ERP Similarity Score: -0.0407
    Run 4, Batch 15: ERP Similarity Score: -0.0390
    Run 4, Batch 16: ERP Similarity Score: -0.0381
    Run 4, Batch 17: ERP Similarity Score: -0.0430
    Run 4, Batch 18: ERP Similarity Score: -0.0445
    Run 4, Batch 19: ERP Similarity Score: -0.0390
    Run 4, Batch 20: ERP Similarity Score: -0.0404
    Run 4, Batch 21: ERP Similarity Score: -0.0369
    Run 4, Batch 22: ERP Similarity Score: -0.0381
    Run 4, Batch 23: ERP Similarity Score: -0.0407
    Run 4, Batch 24: ERP Similarity Score: -0.0441
    Run 4, Batch 25: ERP Similarity Score: -0.0425
    Run 4, Batch 26: ERP Similarity Score: -0.0406
    Run 4, Batch 27: ERP Similarity Score: -0.0377
    Run 4, Batch 28: ERP Similarity Score: -0.0369
    Run 4, Batch 29: ERP Similarity Score: -0.0421
    Run 4, Batch 30: ERP Similarity Score: -0.0387

--- Training cWGAN-GP for Subject 7-8, Run 5 ---
Epoch 0/1000: D Loss=60.9773, G Loss (Comb)=0.1242
Epoch 50/1000: D Loss=-0.6037, G Loss (Comb)=-5.5828
Epoch 100/1000: D Loss=-0.2790, G Loss (Comb)=-6.1474
Epoch 150/1000: D Loss=-0.2312, G Loss (Comb)=-6.3245
Epoch 200/1000: D Loss=-0.3751, G Loss (Comb)=-5.8475
Epoch 250/1000: D Loss=-0.4880, G Loss (Comb)=-5.1442
Epoch 300/1000: D Loss=-0.4555, G Loss (Comb)=-4.9142
Epoch 350/1000: D Loss=-0.5137, G Loss (Comb)=-4.5608
Epoch 400/1000: D Loss=-0.6029, G Loss (Comb)=-4.0781
Epoch 450/1000: D Loss=-0.7514, G Loss (Comb)=-3.9623
Epoch 500/1000: D Loss=-0.8769, G Loss (Comb)=-3.8381
Epoch 550/1000: D Loss=-0.9648, G Loss (Comb)=-3.7271
Epoch 600/1000: D Loss=-1.0619, G Loss (Comb)=-3.8159
Epoch 650/1000: D Loss=-1.1698, G Loss (Comb)=-3.4674
Epoch 700/1000: D Loss=-1.1812, G Loss (Comb)=-3.5443
Epoch 750/1000: D Loss=-1.2075, G Loss (Comb)=-3.4642
Epoch 800/1000: D Loss=-1.2933, G Loss (Comb)=-3.1590
Epoch 850/1000: D Loss=-1.2941, G Loss (Comb)=-2.9945
Epoch 900/1000: D Loss=-1.3590, G Loss (Comb)=-2.8014
Epoch 950/1000: D Loss=-1.4062, G Loss (Comb)=-2.4933
Epoch 999/1000: D Loss=-1.4136, G Loss (Comb)=-2.2594

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0449
    Run 5, Batch 2: ERP Similarity Score: -0.0404
    Run 5, Batch 3: ERP Similarity Score: -0.0456
    Run 5, Batch 4: ERP Similarity Score: -0.0412
    Run 5, Batch 5: ERP Similarity Score: -0.0439
    Run 5, Batch 6: ERP Similarity Score: -0.0436
    Run 5, Batch 7: ERP Similarity Score: -0.0417
    Run 5, Batch 8: ERP Similarity Score: -0.0391
    Run 5, Batch 9: ERP Similarity Score: -0.0481
    Run 5, Batch 10: ERP Similarity Score: -0.0387
    Run 5, Batch 11: ERP Similarity Score: -0.0393
    Run 5, Batch 12: ERP Similarity Score: -0.0483
    Run 5, Batch 13: ERP Similarity Score: -0.0456
    Run 5, Batch 14: ERP Similarity Score: -0.0430
    Run 5, Batch 15: ERP Similarity Score: -0.0442
    Run 5, Batch 16: ERP Similarity Score: -0.0424
    Run 5, Batch 17: ERP Similarity Score: -0.0412
    Run 5, Batch 18: ERP Similarity Score: -0.0411
    Run 5, Batch 19: ERP Similarity Score: -0.0420
    Run 5, Batch 20: ERP Similarity Score: -0.0439
    Run 5, Batch 21: ERP Similarity Score: -0.0426
    Run 5, Batch 22: ERP Similarity Score: -0.0443
    Run 5, Batch 23: ERP Similarity Score: -0.0408
    Run 5, Batch 24: ERP Similarity Score: -0.0413
    Run 5, Batch 25: ERP Similarity Score: -0.0408
    Run 5, Batch 26: ERP Similarity Score: -0.0395
    Run 5, Batch 27: ERP Similarity Score: -0.0386
    Run 5, Batch 28: ERP Similarity Score: -0.0365
    Run 5, Batch 29: ERP Similarity Score: -0.0399
    Run 5, Batch 30: ERP Similarity Score: -0.0417


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 2, Score: -0.0351
  Top 2: Run 1, Batch 11, Score: -0.0361
  Top 3: Run 1, Batch 8, Score: -0.0364
  Top 4: Run 5, Batch 28, Score: -0.0365
  Top 5: Run 1, Batch 21, Score: -0.0366
  Top 6: Run 4, Batch 5, Score: -0.0367
  Top 7: Run 1, Batch 1, Score: -0.0368
  Top 8: Run 4, Batch 28, Score: -0.0369
  Top 9: Run 4, Batch 21, Score: -0.0369
  Top 10: Run 3, Batch 1, Score: -0.0370

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 2, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 11, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 1, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 8, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 1, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 20.00%
    Run 5, Batch 28, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 5, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 1, Batch 21, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 5, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 1, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 1, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 28, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 21, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 4, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 4, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 1, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 18 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 2, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0351
  - Strategy (Run 3, Batch 2, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0351
  - Strategy (Run 3, Batch 2, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0351
  - Strategy (Run 1, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0361
  - Strategy (Run 1, Batch 11, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0361
  - Strategy (Run 1, Batch 8, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0364
  - Strategy (Run 5, Batch 28, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0365
  - Strategy (Run 5, Batch 28, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0365
  - Strategy (Run 1, Batch 21, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0366
  - Strategy (Run 1, Batch 21, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0366
  - Strategy (Run 1, Batch 21, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0366
  - Strategy (Run 4, Batch 5, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0367
  - Strategy (Run 4, Batch 5, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0367
  - Strategy (Run 1, Batch 1, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0368
  - Strategy (Run 1, Batch 1, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0368
  - Strategy (Run 4, Batch 21, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0369
  - Strategy (Run 3, Batch 1, Ratio 0): Accuracy=100.00, ERP Score=-0.0370
  - Strategy (Run 3, Batch 1, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0370

Selected best strategy: Run 3, Batch 2, Strategy: Augmented (25%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 86.36%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (25%), Val Acc: 100.00%) -> REAL test accuracy: 86.36%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H11_results/Subject_7-8_results/target_synthetic_data_S7-8.mat
Saved non-target class of best synthetic batch to H11_results/Subject_7-8_results/nontarget_synthetic_data_S7-8.mat
Saved target class of training data to H11_results/Subject_7-8_results/target_training_data_S7-8.mat
Saved non-target class of training data to H11_results/Subject_7-8_results/nontarget_training_data_S7-8.mat

Saved accuracy comparison plot to: H11_results/Subject_7-8_results/accuracy_comparison_S7-8.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 7-8) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H11_results/Subject_7-8_results/GA_ERP_Combined_S7-8_ChCz.png

--- Subject 7-8 processing finished successfully. ---
