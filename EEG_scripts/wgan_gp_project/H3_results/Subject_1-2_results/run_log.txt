Log for Subject Pair 1-2 from H3
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H3 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 117 clean Target and 246 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 138

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 8

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 50.00%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=95.1300, G Loss (Comb)=1.9807
Epoch 50/1000: D Loss=-1.5767, G Loss (Comb)=0.2732
Epoch 100/1000: D Loss=-0.7304, G Loss (Comb)=-3.4571
Epoch 150/1000: D Loss=-0.7246, G Loss (Comb)=-2.4023
Epoch 200/1000: D Loss=-0.5504, G Loss (Comb)=-1.7981
Epoch 250/1000: D Loss=-0.4129, G Loss (Comb)=-2.0711
Epoch 300/1000: D Loss=-0.5158, G Loss (Comb)=-1.5517
Epoch 350/1000: D Loss=-0.3913, G Loss (Comb)=-1.7501
Epoch 400/1000: D Loss=-0.5018, G Loss (Comb)=-1.3831
Epoch 450/1000: D Loss=-0.4691, G Loss (Comb)=-1.4451
Epoch 500/1000: D Loss=-0.5126, G Loss (Comb)=-1.7767
Epoch 550/1000: D Loss=-0.6875, G Loss (Comb)=-2.0750
Epoch 600/1000: D Loss=-0.5147, G Loss (Comb)=-2.0528
Epoch 650/1000: D Loss=-0.7852, G Loss (Comb)=-1.9729
Epoch 700/1000: D Loss=-0.6067, G Loss (Comb)=-2.4089
Epoch 750/1000: D Loss=-0.7561, G Loss (Comb)=-2.4546
Epoch 800/1000: D Loss=-0.7662, G Loss (Comb)=-2.7364
Epoch 850/1000: D Loss=-0.8554, G Loss (Comb)=-2.6817
Epoch 900/1000: D Loss=-0.9088, G Loss (Comb)=-2.8423
Epoch 950/1000: D Loss=-0.8742, G Loss (Comb)=-2.7282
Epoch 999/1000: D Loss=-0.9732, G Loss (Comb)=-2.8308

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0363
    Run 1, Batch 2: ERP Similarity Score: -0.0346
    Run 1, Batch 3: ERP Similarity Score: -0.0421
    Run 1, Batch 4: ERP Similarity Score: -0.0363
    Run 1, Batch 5: ERP Similarity Score: -0.0391
    Run 1, Batch 6: ERP Similarity Score: -0.0363
    Run 1, Batch 7: ERP Similarity Score: -0.0382
    Run 1, Batch 8: ERP Similarity Score: -0.0360
    Run 1, Batch 9: ERP Similarity Score: -0.0366
    Run 1, Batch 10: ERP Similarity Score: -0.0356
    Run 1, Batch 11: ERP Similarity Score: -0.0408
    Run 1, Batch 12: ERP Similarity Score: -0.0397
    Run 1, Batch 13: ERP Similarity Score: -0.0360
    Run 1, Batch 14: ERP Similarity Score: -0.0357
    Run 1, Batch 15: ERP Similarity Score: -0.0382
    Run 1, Batch 16: ERP Similarity Score: -0.0346
    Run 1, Batch 17: ERP Similarity Score: -0.0382
    Run 1, Batch 18: ERP Similarity Score: -0.0356
    Run 1, Batch 19: ERP Similarity Score: -0.0318
    Run 1, Batch 20: ERP Similarity Score: -0.0351
    Run 1, Batch 21: ERP Similarity Score: -0.0404
    Run 1, Batch 22: ERP Similarity Score: -0.0359
    Run 1, Batch 23: ERP Similarity Score: -0.0375
    Run 1, Batch 24: ERP Similarity Score: -0.0374
    Run 1, Batch 25: ERP Similarity Score: -0.0333
    Run 1, Batch 26: ERP Similarity Score: -0.0346
    Run 1, Batch 27: ERP Similarity Score: -0.0423
    Run 1, Batch 28: ERP Similarity Score: -0.0311
    Run 1, Batch 29: ERP Similarity Score: -0.0380
    Run 1, Batch 30: ERP Similarity Score: -0.0379

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=75.6974, G Loss (Comb)=0.8998
Epoch 50/1000: D Loss=-1.7115, G Loss (Comb)=-0.2884
Epoch 100/1000: D Loss=-0.6387, G Loss (Comb)=-3.9276
Epoch 150/1000: D Loss=-0.4710, G Loss (Comb)=-3.5731
Epoch 200/1000: D Loss=-0.7121, G Loss (Comb)=-2.8238
Epoch 250/1000: D Loss=-0.3750, G Loss (Comb)=-3.0675
Epoch 300/1000: D Loss=-0.4555, G Loss (Comb)=-2.4659
Epoch 350/1000: D Loss=-0.6413, G Loss (Comb)=-2.4596
Epoch 400/1000: D Loss=-0.6520, G Loss (Comb)=-2.4459
Epoch 450/1000: D Loss=-0.6518, G Loss (Comb)=-2.4098
Epoch 500/1000: D Loss=-0.7659, G Loss (Comb)=-2.2542
Epoch 550/1000: D Loss=-0.8061, G Loss (Comb)=-2.5145
Epoch 600/1000: D Loss=-0.8494, G Loss (Comb)=-2.2972
Epoch 650/1000: D Loss=-0.8591, G Loss (Comb)=-2.2919
Epoch 700/1000: D Loss=-0.8891, G Loss (Comb)=-2.3232
Epoch 750/1000: D Loss=-0.9536, G Loss (Comb)=-2.3511
Epoch 800/1000: D Loss=-0.9726, G Loss (Comb)=-2.2149
Epoch 850/1000: D Loss=-1.0376, G Loss (Comb)=-2.0319
Epoch 900/1000: D Loss=-1.1078, G Loss (Comb)=-1.9111
Epoch 950/1000: D Loss=-1.1809, G Loss (Comb)=-1.9910
Epoch 999/1000: D Loss=-1.1714, G Loss (Comb)=-1.9263

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0405
    Run 2, Batch 2: ERP Similarity Score: -0.0408
    Run 2, Batch 3: ERP Similarity Score: -0.0427
    Run 2, Batch 4: ERP Similarity Score: -0.0359
    Run 2, Batch 5: ERP Similarity Score: -0.0397
    Run 2, Batch 6: ERP Similarity Score: -0.0375
    Run 2, Batch 7: ERP Similarity Score: -0.0405
    Run 2, Batch 8: ERP Similarity Score: -0.0409
    Run 2, Batch 9: ERP Similarity Score: -0.0413
    Run 2, Batch 10: ERP Similarity Score: -0.0399
    Run 2, Batch 11: ERP Similarity Score: -0.0396
    Run 2, Batch 12: ERP Similarity Score: -0.0452
    Run 2, Batch 13: ERP Similarity Score: -0.0389
    Run 2, Batch 14: ERP Similarity Score: -0.0389
    Run 2, Batch 15: ERP Similarity Score: -0.0404
    Run 2, Batch 16: ERP Similarity Score: -0.0438
    Run 2, Batch 17: ERP Similarity Score: -0.0403
    Run 2, Batch 18: ERP Similarity Score: -0.0359
    Run 2, Batch 19: ERP Similarity Score: -0.0397
    Run 2, Batch 20: ERP Similarity Score: -0.0368
    Run 2, Batch 21: ERP Similarity Score: -0.0388
    Run 2, Batch 22: ERP Similarity Score: -0.0398
    Run 2, Batch 23: ERP Similarity Score: -0.0440
    Run 2, Batch 24: ERP Similarity Score: -0.0435
    Run 2, Batch 25: ERP Similarity Score: -0.0413
    Run 2, Batch 26: ERP Similarity Score: -0.0399
    Run 2, Batch 27: ERP Similarity Score: -0.0450
    Run 2, Batch 28: ERP Similarity Score: -0.0421
    Run 2, Batch 29: ERP Similarity Score: -0.0403
    Run 2, Batch 30: ERP Similarity Score: -0.0324

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=89.4029, G Loss (Comb)=1.3943
Epoch 50/1000: D Loss=-1.7521, G Loss (Comb)=0.9481
Epoch 100/1000: D Loss=-0.7650, G Loss (Comb)=-1.4385
Epoch 150/1000: D Loss=-0.4493, G Loss (Comb)=-1.0455
Epoch 200/1000: D Loss=-0.5691, G Loss (Comb)=-0.1531
Epoch 250/1000: D Loss=-0.4744, G Loss (Comb)=0.4027
Epoch 300/1000: D Loss=-0.3732, G Loss (Comb)=0.6093
Epoch 350/1000: D Loss=-0.7143, G Loss (Comb)=0.7594
Epoch 400/1000: D Loss=-0.5801, G Loss (Comb)=0.9019
Epoch 450/1000: D Loss=-0.6290, G Loss (Comb)=0.4806
Epoch 500/1000: D Loss=-0.7144, G Loss (Comb)=0.1635
Epoch 550/1000: D Loss=-0.7150, G Loss (Comb)=-0.0863
Epoch 600/1000: D Loss=-0.8491, G Loss (Comb)=-0.3477
Epoch 650/1000: D Loss=-0.8284, G Loss (Comb)=-0.6443
Epoch 700/1000: D Loss=-0.8149, G Loss (Comb)=-0.6258
Epoch 750/1000: D Loss=-0.8884, G Loss (Comb)=-0.8799
Epoch 800/1000: D Loss=-1.0011, G Loss (Comb)=-1.0716
Epoch 850/1000: D Loss=-0.9133, G Loss (Comb)=-1.5161
Epoch 900/1000: D Loss=-0.9830, G Loss (Comb)=-1.2368
Epoch 950/1000: D Loss=-1.0142, G Loss (Comb)=-1.4443
Epoch 999/1000: D Loss=-1.0972, G Loss (Comb)=-1.6047

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0366
    Run 3, Batch 2: ERP Similarity Score: -0.0438
    Run 3, Batch 3: ERP Similarity Score: -0.0425
    Run 3, Batch 4: ERP Similarity Score: -0.0410
    Run 3, Batch 5: ERP Similarity Score: -0.0431
    Run 3, Batch 6: ERP Similarity Score: -0.0404
    Run 3, Batch 7: ERP Similarity Score: -0.0397
    Run 3, Batch 8: ERP Similarity Score: -0.0397
    Run 3, Batch 9: ERP Similarity Score: -0.0420
    Run 3, Batch 10: ERP Similarity Score: -0.0383
    Run 3, Batch 11: ERP Similarity Score: -0.0467
    Run 3, Batch 12: ERP Similarity Score: -0.0390
    Run 3, Batch 13: ERP Similarity Score: -0.0391
    Run 3, Batch 14: ERP Similarity Score: -0.0412
    Run 3, Batch 15: ERP Similarity Score: -0.0437
    Run 3, Batch 16: ERP Similarity Score: -0.0367
    Run 3, Batch 17: ERP Similarity Score: -0.0459
    Run 3, Batch 18: ERP Similarity Score: -0.0451
    Run 3, Batch 19: ERP Similarity Score: -0.0382
    Run 3, Batch 20: ERP Similarity Score: -0.0434
    Run 3, Batch 21: ERP Similarity Score: -0.0410
    Run 3, Batch 22: ERP Similarity Score: -0.0410
    Run 3, Batch 23: ERP Similarity Score: -0.0401
    Run 3, Batch 24: ERP Similarity Score: -0.0420
    Run 3, Batch 25: ERP Similarity Score: -0.0367
    Run 3, Batch 26: ERP Similarity Score: -0.0361
    Run 3, Batch 27: ERP Similarity Score: -0.0418
    Run 3, Batch 28: ERP Similarity Score: -0.0378
    Run 3, Batch 29: ERP Similarity Score: -0.0410
    Run 3, Batch 30: ERP Similarity Score: -0.0419

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=77.3960, G Loss (Comb)=0.6511
Epoch 50/1000: D Loss=-1.8898, G Loss (Comb)=-1.4363
Epoch 100/1000: D Loss=-0.7616, G Loss (Comb)=-4.5850
Epoch 150/1000: D Loss=-0.4878, G Loss (Comb)=-4.7599
Epoch 200/1000: D Loss=-0.6668, G Loss (Comb)=-3.6502
Epoch 250/1000: D Loss=-0.6040, G Loss (Comb)=-3.6632
Epoch 300/1000: D Loss=-0.4693, G Loss (Comb)=-3.6832
Epoch 350/1000: D Loss=-0.5690, G Loss (Comb)=-3.4249
Epoch 400/1000: D Loss=-0.5354, G Loss (Comb)=-3.6767
Epoch 450/1000: D Loss=-0.5790, G Loss (Comb)=-3.4950
Epoch 500/1000: D Loss=-0.7066, G Loss (Comb)=-3.8446
Epoch 550/1000: D Loss=-0.7170, G Loss (Comb)=-3.8115
Epoch 600/1000: D Loss=-0.7821, G Loss (Comb)=-3.8874
Epoch 650/1000: D Loss=-0.8149, G Loss (Comb)=-3.6821
Epoch 700/1000: D Loss=-0.8414, G Loss (Comb)=-3.3076
Epoch 750/1000: D Loss=-0.8699, G Loss (Comb)=-3.3750
Epoch 800/1000: D Loss=-0.9718, G Loss (Comb)=-3.2282
Epoch 850/1000: D Loss=-1.0018, G Loss (Comb)=-3.2852
Epoch 900/1000: D Loss=-0.9229, G Loss (Comb)=-3.2274
Epoch 950/1000: D Loss=-0.9979, G Loss (Comb)=-2.9923
Epoch 999/1000: D Loss=-1.0098, G Loss (Comb)=-2.7489

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0406
    Run 4, Batch 2: ERP Similarity Score: -0.0378
    Run 4, Batch 3: ERP Similarity Score: -0.0404
    Run 4, Batch 4: ERP Similarity Score: -0.0348
    Run 4, Batch 5: ERP Similarity Score: -0.0380
    Run 4, Batch 6: ERP Similarity Score: -0.0399
    Run 4, Batch 7: ERP Similarity Score: -0.0393
    Run 4, Batch 8: ERP Similarity Score: -0.0367
    Run 4, Batch 9: ERP Similarity Score: -0.0404
    Run 4, Batch 10: ERP Similarity Score: -0.0384
    Run 4, Batch 11: ERP Similarity Score: -0.0369
    Run 4, Batch 12: ERP Similarity Score: -0.0358
    Run 4, Batch 13: ERP Similarity Score: -0.0375
    Run 4, Batch 14: ERP Similarity Score: -0.0421
    Run 4, Batch 15: ERP Similarity Score: -0.0435
    Run 4, Batch 16: ERP Similarity Score: -0.0452
    Run 4, Batch 17: ERP Similarity Score: -0.0375
    Run 4, Batch 18: ERP Similarity Score: -0.0380
    Run 4, Batch 19: ERP Similarity Score: -0.0363
    Run 4, Batch 20: ERP Similarity Score: -0.0378
    Run 4, Batch 21: ERP Similarity Score: -0.0358
    Run 4, Batch 22: ERP Similarity Score: -0.0391
    Run 4, Batch 23: ERP Similarity Score: -0.0382
    Run 4, Batch 24: ERP Similarity Score: -0.0397
    Run 4, Batch 25: ERP Similarity Score: -0.0389
    Run 4, Batch 26: ERP Similarity Score: -0.0368
    Run 4, Batch 27: ERP Similarity Score: -0.0376
    Run 4, Batch 28: ERP Similarity Score: -0.0358
    Run 4, Batch 29: ERP Similarity Score: -0.0391
    Run 4, Batch 30: ERP Similarity Score: -0.0417

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=82.4352, G Loss (Comb)=0.3546
Epoch 50/1000: D Loss=-1.9071, G Loss (Comb)=-1.3836
Epoch 100/1000: D Loss=-0.6620, G Loss (Comb)=-4.7153
Epoch 150/1000: D Loss=-0.5222, G Loss (Comb)=-4.9683
Epoch 200/1000: D Loss=-0.5546, G Loss (Comb)=-3.8703
Epoch 250/1000: D Loss=-0.4322, G Loss (Comb)=-3.4714
Epoch 300/1000: D Loss=-0.5079, G Loss (Comb)=-3.3432
Epoch 350/1000: D Loss=-0.5279, G Loss (Comb)=-3.3124
Epoch 400/1000: D Loss=-0.5720, G Loss (Comb)=-3.5133
Epoch 450/1000: D Loss=-0.5814, G Loss (Comb)=-3.4710
Epoch 500/1000: D Loss=-0.6886, G Loss (Comb)=-3.4011
Epoch 550/1000: D Loss=-0.6532, G Loss (Comb)=-3.6192
Epoch 600/1000: D Loss=-0.7893, G Loss (Comb)=-3.8669
Epoch 650/1000: D Loss=-0.8033, G Loss (Comb)=-4.0351
Epoch 700/1000: D Loss=-0.8126, G Loss (Comb)=-3.8162
Epoch 750/1000: D Loss=-0.8288, G Loss (Comb)=-3.8412
Epoch 800/1000: D Loss=-0.8154, G Loss (Comb)=-3.5614
Epoch 850/1000: D Loss=-1.0010, G Loss (Comb)=-3.6574
Epoch 900/1000: D Loss=-0.9362, G Loss (Comb)=-3.5614
Epoch 950/1000: D Loss=-1.0126, G Loss (Comb)=-3.5066
Epoch 999/1000: D Loss=-1.0382, G Loss (Comb)=-3.4066

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0341
    Run 5, Batch 2: ERP Similarity Score: -0.0357
    Run 5, Batch 3: ERP Similarity Score: -0.0425
    Run 5, Batch 4: ERP Similarity Score: -0.0404
    Run 5, Batch 5: ERP Similarity Score: -0.0381
    Run 5, Batch 6: ERP Similarity Score: -0.0472
    Run 5, Batch 7: ERP Similarity Score: -0.0345
    Run 5, Batch 8: ERP Similarity Score: -0.0415
    Run 5, Batch 9: ERP Similarity Score: -0.0389
    Run 5, Batch 10: ERP Similarity Score: -0.0380
    Run 5, Batch 11: ERP Similarity Score: -0.0369
    Run 5, Batch 12: ERP Similarity Score: -0.0423
    Run 5, Batch 13: ERP Similarity Score: -0.0389
    Run 5, Batch 14: ERP Similarity Score: -0.0412
    Run 5, Batch 15: ERP Similarity Score: -0.0352
    Run 5, Batch 16: ERP Similarity Score: -0.0426
    Run 5, Batch 17: ERP Similarity Score: -0.0435
    Run 5, Batch 18: ERP Similarity Score: -0.0372
    Run 5, Batch 19: ERP Similarity Score: -0.0343
    Run 5, Batch 20: ERP Similarity Score: -0.0410
    Run 5, Batch 21: ERP Similarity Score: -0.0357
    Run 5, Batch 22: ERP Similarity Score: -0.0418
    Run 5, Batch 23: ERP Similarity Score: -0.0366
    Run 5, Batch 24: ERP Similarity Score: -0.0365
    Run 5, Batch 25: ERP Similarity Score: -0.0406
    Run 5, Batch 26: ERP Similarity Score: -0.0365
    Run 5, Batch 27: ERP Similarity Score: -0.0418
    Run 5, Batch 28: ERP Similarity Score: -0.0413
    Run 5, Batch 29: ERP Similarity Score: -0.0357
    Run 5, Batch 30: ERP Similarity Score: -0.0382


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 1, Batch 28, Score: -0.0311
  Top 2: Run 1, Batch 19, Score: -0.0318
  Top 3: Run 2, Batch 30, Score: -0.0324
  Top 4: Run 1, Batch 25, Score: -0.0333
  Top 5: Run 5, Batch 1, Score: -0.0341
  Top 6: Run 5, Batch 19, Score: -0.0343
  Top 7: Run 5, Batch 7, Score: -0.0345
  Top 8: Run 1, Batch 2, Score: -0.0346
  Top 9: Run 1, Batch 16, Score: -0.0346
  Top 10: Run 1, Batch 26, Score: -0.0346

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 1, Batch 28, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 19, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 30, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 25, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 1, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 5, Batch 1, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 5, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 5, Batch 7, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 7, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 7, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 7, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 2, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 16, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 1, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 1, Batch 26, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 1, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 33.33%

Found 10 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 1, Batch 28, Ratio 0): Accuracy=100.00, ERP Score=-0.0311
  - Strategy (Run 1, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0311
  - Strategy (Run 1, Batch 19, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 1, Batch 19, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 2, Batch 30, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0324
  - Strategy (Run 5, Batch 1, Ratio 0): Accuracy=100.00, ERP Score=-0.0341
  - Strategy (Run 5, Batch 19, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0343
  - Strategy (Run 5, Batch 19, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0343
  - Strategy (Run 5, Batch 7, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0345
  - Strategy (Run 1, Batch 26, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0346

Selected best strategy: Run 1, Batch 28, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 50.00%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 50.00%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H3_results/Subject_1-2_results/target_synthetic_data_S1-2.mat
Saved non-target class of best synthetic batch to H3_results/Subject_1-2_results/nontarget_synthetic_data_S1-2.mat
Saved target class of training data to H3_results/Subject_1-2_results/target_training_data_S1-2.mat
Saved non-target class of training data to H3_results/Subject_1-2_results/nontarget_training_data_S1-2.mat

Saved accuracy comparison plot to: H3_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H3_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
