Log for Subject Pair 7-8 from H3
========================================


========================= PROCESSING SUBJECT PAIR: 7-8 from H3 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 100 clean Target and 471 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 196

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 12

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 91.67%

--- Training cWGAN-GP for Subject 7-8, Run 1 ---
Epoch 0/1000: D Loss=39.3623, G Loss (Comb)=1.6645
Epoch 50/1000: D Loss=-0.5082, G Loss (Comb)=-6.2166
Epoch 100/1000: D Loss=-0.3167, G Loss (Comb)=-5.3996
Epoch 150/1000: D Loss=-0.5323, G Loss (Comb)=-2.8945
Epoch 200/1000: D Loss=-0.2575, G Loss (Comb)=-4.6881
Epoch 250/1000: D Loss=-0.1060, G Loss (Comb)=-2.5504
Epoch 300/1000: D Loss=-0.1758, G Loss (Comb)=-3.2107
Epoch 350/1000: D Loss=-0.3332, G Loss (Comb)=-1.5264
Epoch 400/1000: D Loss=-0.2530, G Loss (Comb)=-2.2738
Epoch 450/1000: D Loss=-0.2907, G Loss (Comb)=-2.2661
Epoch 500/1000: D Loss=-0.1932, G Loss (Comb)=-4.4321
Epoch 550/1000: D Loss=-0.1912, G Loss (Comb)=-3.8857
Epoch 600/1000: D Loss=-0.1718, G Loss (Comb)=-3.8917
Epoch 650/1000: D Loss=-0.2178, G Loss (Comb)=-3.5995
Epoch 700/1000: D Loss=-0.2751, G Loss (Comb)=-2.4871
Epoch 750/1000: D Loss=-0.2785, G Loss (Comb)=-4.6595
Epoch 800/1000: D Loss=-0.2111, G Loss (Comb)=-4.2903
Epoch 850/1000: D Loss=-0.2644, G Loss (Comb)=-6.0745
Epoch 900/1000: D Loss=-0.2880, G Loss (Comb)=-5.2249
Epoch 950/1000: D Loss=-0.2539, G Loss (Comb)=-4.4714
Epoch 999/1000: D Loss=-0.2410, G Loss (Comb)=-5.6969

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0311
    Run 1, Batch 2: ERP Similarity Score: -0.0356
    Run 1, Batch 3: ERP Similarity Score: -0.0349
    Run 1, Batch 4: ERP Similarity Score: -0.0343
    Run 1, Batch 5: ERP Similarity Score: -0.0346
    Run 1, Batch 6: ERP Similarity Score: -0.0326
    Run 1, Batch 7: ERP Similarity Score: -0.0362
    Run 1, Batch 8: ERP Similarity Score: -0.0349
    Run 1, Batch 9: ERP Similarity Score: -0.0357
    Run 1, Batch 10: ERP Similarity Score: -0.0337
    Run 1, Batch 11: ERP Similarity Score: -0.0335
    Run 1, Batch 12: ERP Similarity Score: -0.0331
    Run 1, Batch 13: ERP Similarity Score: -0.0349
    Run 1, Batch 14: ERP Similarity Score: -0.0367
    Run 1, Batch 15: ERP Similarity Score: -0.0351
    Run 1, Batch 16: ERP Similarity Score: -0.0355
    Run 1, Batch 17: ERP Similarity Score: -0.0350
    Run 1, Batch 18: ERP Similarity Score: -0.0328
    Run 1, Batch 19: ERP Similarity Score: -0.0382
    Run 1, Batch 20: ERP Similarity Score: -0.0347
    Run 1, Batch 21: ERP Similarity Score: -0.0332
    Run 1, Batch 22: ERP Similarity Score: -0.0390
    Run 1, Batch 23: ERP Similarity Score: -0.0355
    Run 1, Batch 24: ERP Similarity Score: -0.0342
    Run 1, Batch 25: ERP Similarity Score: -0.0323
    Run 1, Batch 26: ERP Similarity Score: -0.0312
    Run 1, Batch 27: ERP Similarity Score: -0.0329
    Run 1, Batch 28: ERP Similarity Score: -0.0372
    Run 1, Batch 29: ERP Similarity Score: -0.0374
    Run 1, Batch 30: ERP Similarity Score: -0.0350

--- Training cWGAN-GP for Subject 7-8, Run 2 ---
Epoch 0/1000: D Loss=29.9087, G Loss (Comb)=0.8229
Epoch 50/1000: D Loss=-0.4182, G Loss (Comb)=-6.1547
Epoch 100/1000: D Loss=-0.1769, G Loss (Comb)=-7.1277
Epoch 150/1000: D Loss=-0.3805, G Loss (Comb)=-4.9145
Epoch 200/1000: D Loss=-0.2257, G Loss (Comb)=-5.5001
Epoch 250/1000: D Loss=-0.4234, G Loss (Comb)=-4.0242
Epoch 300/1000: D Loss=-0.1847, G Loss (Comb)=-5.2912
Epoch 350/1000: D Loss=-0.0995, G Loss (Comb)=-3.3679
Epoch 400/1000: D Loss=0.0135, G Loss (Comb)=-4.1310
Epoch 450/1000: D Loss=-0.1621, G Loss (Comb)=-4.3837
Epoch 500/1000: D Loss=-0.2462, G Loss (Comb)=-5.8240
Epoch 550/1000: D Loss=-0.1496, G Loss (Comb)=-4.2641
Epoch 600/1000: D Loss=-0.1587, G Loss (Comb)=-4.7015
Epoch 650/1000: D Loss=-0.0152, G Loss (Comb)=-3.6837
Epoch 700/1000: D Loss=-0.1197, G Loss (Comb)=-5.6256
Epoch 750/1000: D Loss=-0.1992, G Loss (Comb)=-6.8125
Epoch 800/1000: D Loss=-0.1204, G Loss (Comb)=-6.1710
Epoch 850/1000: D Loss=-0.2325, G Loss (Comb)=-5.3072
Epoch 900/1000: D Loss=-0.2827, G Loss (Comb)=-5.6701
Epoch 950/1000: D Loss=-0.2163, G Loss (Comb)=-8.3787
Epoch 999/1000: D Loss=-0.2445, G Loss (Comb)=-7.6649

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0406
    Run 2, Batch 2: ERP Similarity Score: -0.0402
    Run 2, Batch 3: ERP Similarity Score: -0.0363
    Run 2, Batch 4: ERP Similarity Score: -0.0409
    Run 2, Batch 5: ERP Similarity Score: -0.0375
    Run 2, Batch 6: ERP Similarity Score: -0.0400
    Run 2, Batch 7: ERP Similarity Score: -0.0384
    Run 2, Batch 8: ERP Similarity Score: -0.0408
    Run 2, Batch 9: ERP Similarity Score: -0.0401
    Run 2, Batch 10: ERP Similarity Score: -0.0350
    Run 2, Batch 11: ERP Similarity Score: -0.0381
    Run 2, Batch 12: ERP Similarity Score: -0.0372
    Run 2, Batch 13: ERP Similarity Score: -0.0390
    Run 2, Batch 14: ERP Similarity Score: -0.0387
    Run 2, Batch 15: ERP Similarity Score: -0.0381
    Run 2, Batch 16: ERP Similarity Score: -0.0353
    Run 2, Batch 17: ERP Similarity Score: -0.0410
    Run 2, Batch 18: ERP Similarity Score: -0.0374
    Run 2, Batch 19: ERP Similarity Score: -0.0364
    Run 2, Batch 20: ERP Similarity Score: -0.0394
    Run 2, Batch 21: ERP Similarity Score: -0.0382
    Run 2, Batch 22: ERP Similarity Score: -0.0346
    Run 2, Batch 23: ERP Similarity Score: -0.0327
    Run 2, Batch 24: ERP Similarity Score: -0.0418
    Run 2, Batch 25: ERP Similarity Score: -0.0359
    Run 2, Batch 26: ERP Similarity Score: -0.0396
    Run 2, Batch 27: ERP Similarity Score: -0.0359
    Run 2, Batch 28: ERP Similarity Score: -0.0392
    Run 2, Batch 29: ERP Similarity Score: -0.0390
    Run 2, Batch 30: ERP Similarity Score: -0.0373

--- Training cWGAN-GP for Subject 7-8, Run 3 ---
Epoch 0/1000: D Loss=30.1449, G Loss (Comb)=0.5300
Epoch 50/1000: D Loss=-0.3634, G Loss (Comb)=-4.2113
Epoch 100/1000: D Loss=-0.2550, G Loss (Comb)=-4.9672
Epoch 150/1000: D Loss=-0.3005, G Loss (Comb)=-3.0873
Epoch 200/1000: D Loss=-0.1899, G Loss (Comb)=-1.8927
Epoch 250/1000: D Loss=-0.2323, G Loss (Comb)=-0.9368
Epoch 300/1000: D Loss=-0.0161, G Loss (Comb)=-0.8252
Epoch 350/1000: D Loss=-0.2108, G Loss (Comb)=-0.7837
Epoch 400/1000: D Loss=-0.1697, G Loss (Comb)=-2.1856
Epoch 450/1000: D Loss=-0.1462, G Loss (Comb)=-1.7258
Epoch 500/1000: D Loss=-0.2895, G Loss (Comb)=-2.6925
Epoch 550/1000: D Loss=-0.1723, G Loss (Comb)=-3.2369
Epoch 600/1000: D Loss=-0.2525, G Loss (Comb)=-1.7809
Epoch 650/1000: D Loss=-0.2648, G Loss (Comb)=-3.7675
Epoch 700/1000: D Loss=-0.1241, G Loss (Comb)=-3.9118
Epoch 750/1000: D Loss=-0.0874, G Loss (Comb)=-4.1139
Epoch 800/1000: D Loss=-0.3040, G Loss (Comb)=-4.4564
Epoch 850/1000: D Loss=-0.3756, G Loss (Comb)=-3.5626
Epoch 900/1000: D Loss=-0.2565, G Loss (Comb)=-5.8758
Epoch 950/1000: D Loss=-0.2638, G Loss (Comb)=-5.4293
Epoch 999/1000: D Loss=-0.2589, G Loss (Comb)=-5.9227

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0324
    Run 3, Batch 2: ERP Similarity Score: -0.0378
    Run 3, Batch 3: ERP Similarity Score: -0.0355
    Run 3, Batch 4: ERP Similarity Score: -0.0375
    Run 3, Batch 5: ERP Similarity Score: -0.0357
    Run 3, Batch 6: ERP Similarity Score: -0.0364
    Run 3, Batch 7: ERP Similarity Score: -0.0329
    Run 3, Batch 8: ERP Similarity Score: -0.0360
    Run 3, Batch 9: ERP Similarity Score: -0.0321
    Run 3, Batch 10: ERP Similarity Score: -0.0354
    Run 3, Batch 11: ERP Similarity Score: -0.0342
    Run 3, Batch 12: ERP Similarity Score: -0.0344
    Run 3, Batch 13: ERP Similarity Score: -0.0359
    Run 3, Batch 14: ERP Similarity Score: -0.0347
    Run 3, Batch 15: ERP Similarity Score: -0.0328
    Run 3, Batch 16: ERP Similarity Score: -0.0357
    Run 3, Batch 17: ERP Similarity Score: -0.0362
    Run 3, Batch 18: ERP Similarity Score: -0.0339
    Run 3, Batch 19: ERP Similarity Score: -0.0345
    Run 3, Batch 20: ERP Similarity Score: -0.0356
    Run 3, Batch 21: ERP Similarity Score: -0.0359
    Run 3, Batch 22: ERP Similarity Score: -0.0344
    Run 3, Batch 23: ERP Similarity Score: -0.0356
    Run 3, Batch 24: ERP Similarity Score: -0.0323
    Run 3, Batch 25: ERP Similarity Score: -0.0395
    Run 3, Batch 26: ERP Similarity Score: -0.0373
    Run 3, Batch 27: ERP Similarity Score: -0.0358
    Run 3, Batch 28: ERP Similarity Score: -0.0357
    Run 3, Batch 29: ERP Similarity Score: -0.0348
    Run 3, Batch 30: ERP Similarity Score: -0.0336

--- Training cWGAN-GP for Subject 7-8, Run 4 ---
Epoch 0/1000: D Loss=24.5338, G Loss (Comb)=0.7467
Epoch 50/1000: D Loss=-0.4030, G Loss (Comb)=-5.5562
Epoch 100/1000: D Loss=-0.3141, G Loss (Comb)=-5.2727
Epoch 150/1000: D Loss=-0.3091, G Loss (Comb)=-4.7984
Epoch 200/1000: D Loss=-0.1365, G Loss (Comb)=-4.9108
Epoch 250/1000: D Loss=-0.2747, G Loss (Comb)=-5.2607
Epoch 300/1000: D Loss=-0.2258, G Loss (Comb)=-4.9191
Epoch 350/1000: D Loss=-0.0365, G Loss (Comb)=-4.6032
Epoch 400/1000: D Loss=-0.1852, G Loss (Comb)=-3.6879
Epoch 450/1000: D Loss=-0.0455, G Loss (Comb)=-3.7411
Epoch 500/1000: D Loss=-0.3471, G Loss (Comb)=-4.4186
Epoch 550/1000: D Loss=-0.1749, G Loss (Comb)=-4.1575
Epoch 600/1000: D Loss=-0.1948, G Loss (Comb)=-4.0002
Epoch 650/1000: D Loss=-0.1940, G Loss (Comb)=-5.1975
Epoch 700/1000: D Loss=-0.1103, G Loss (Comb)=-5.9380
Epoch 750/1000: D Loss=-0.2675, G Loss (Comb)=-5.0873
Epoch 800/1000: D Loss=-0.2203, G Loss (Comb)=-5.4291
Epoch 850/1000: D Loss=-0.3399, G Loss (Comb)=-5.4264
Epoch 900/1000: D Loss=-0.2150, G Loss (Comb)=-6.2675
Epoch 950/1000: D Loss=-0.3221, G Loss (Comb)=-6.6684
Epoch 999/1000: D Loss=-0.1825, G Loss (Comb)=-7.0528

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0359
    Run 4, Batch 2: ERP Similarity Score: -0.0317
    Run 4, Batch 3: ERP Similarity Score: -0.0352
    Run 4, Batch 4: ERP Similarity Score: -0.0323
    Run 4, Batch 5: ERP Similarity Score: -0.0348
    Run 4, Batch 6: ERP Similarity Score: -0.0316
    Run 4, Batch 7: ERP Similarity Score: -0.0365
    Run 4, Batch 8: ERP Similarity Score: -0.0341
    Run 4, Batch 9: ERP Similarity Score: -0.0342
    Run 4, Batch 10: ERP Similarity Score: -0.0351
    Run 4, Batch 11: ERP Similarity Score: -0.0333
    Run 4, Batch 12: ERP Similarity Score: -0.0341
    Run 4, Batch 13: ERP Similarity Score: -0.0339
    Run 4, Batch 14: ERP Similarity Score: -0.0309
    Run 4, Batch 15: ERP Similarity Score: -0.0343
    Run 4, Batch 16: ERP Similarity Score: -0.0324
    Run 4, Batch 17: ERP Similarity Score: -0.0326
    Run 4, Batch 18: ERP Similarity Score: -0.0381
    Run 4, Batch 19: ERP Similarity Score: -0.0340
    Run 4, Batch 20: ERP Similarity Score: -0.0347
    Run 4, Batch 21: ERP Similarity Score: -0.0316
    Run 4, Batch 22: ERP Similarity Score: -0.0365
    Run 4, Batch 23: ERP Similarity Score: -0.0315
    Run 4, Batch 24: ERP Similarity Score: -0.0303
    Run 4, Batch 25: ERP Similarity Score: -0.0344
    Run 4, Batch 26: ERP Similarity Score: -0.0332
    Run 4, Batch 27: ERP Similarity Score: -0.0354
    Run 4, Batch 28: ERP Similarity Score: -0.0343
    Run 4, Batch 29: ERP Similarity Score: -0.0330
    Run 4, Batch 30: ERP Similarity Score: -0.0310

--- Training cWGAN-GP for Subject 7-8, Run 5 ---
Epoch 0/1000: D Loss=28.2139, G Loss (Comb)=-0.2589
Epoch 50/1000: D Loss=-0.5999, G Loss (Comb)=-5.6564
Epoch 100/1000: D Loss=-0.5257, G Loss (Comb)=-6.6418
Epoch 150/1000: D Loss=-0.2174, G Loss (Comb)=-5.1182
Epoch 200/1000: D Loss=-0.1481, G Loss (Comb)=-5.6260
Epoch 250/1000: D Loss=-0.2209, G Loss (Comb)=-7.2429
Epoch 300/1000: D Loss=-0.2479, G Loss (Comb)=-4.4973
Epoch 350/1000: D Loss=-0.3332, G Loss (Comb)=-6.4353
Epoch 400/1000: D Loss=0.0387, G Loss (Comb)=-5.6165
Epoch 450/1000: D Loss=0.1025, G Loss (Comb)=-3.8397
Epoch 500/1000: D Loss=-0.1797, G Loss (Comb)=-5.9189
Epoch 550/1000: D Loss=0.0370, G Loss (Comb)=-5.1834
Epoch 600/1000: D Loss=-0.3138, G Loss (Comb)=-5.8127
Epoch 650/1000: D Loss=-0.2820, G Loss (Comb)=-4.6935
Epoch 700/1000: D Loss=-0.2356, G Loss (Comb)=-4.6859
Epoch 750/1000: D Loss=-0.1352, G Loss (Comb)=-5.6748
Epoch 800/1000: D Loss=-0.1695, G Loss (Comb)=-6.5249
Epoch 850/1000: D Loss=-0.2377, G Loss (Comb)=-6.4091
Epoch 900/1000: D Loss=-0.2129, G Loss (Comb)=-7.2373
Epoch 950/1000: D Loss=-0.2715, G Loss (Comb)=-8.7901
Epoch 999/1000: D Loss=-0.2106, G Loss (Comb)=-7.8425

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0351
    Run 5, Batch 2: ERP Similarity Score: -0.0351
    Run 5, Batch 3: ERP Similarity Score: -0.0368
    Run 5, Batch 4: ERP Similarity Score: -0.0397
    Run 5, Batch 5: ERP Similarity Score: -0.0390
    Run 5, Batch 6: ERP Similarity Score: -0.0390
    Run 5, Batch 7: ERP Similarity Score: -0.0429
    Run 5, Batch 8: ERP Similarity Score: -0.0396
    Run 5, Batch 9: ERP Similarity Score: -0.0370
    Run 5, Batch 10: ERP Similarity Score: -0.0386
    Run 5, Batch 11: ERP Similarity Score: -0.0400
    Run 5, Batch 12: ERP Similarity Score: -0.0417
    Run 5, Batch 13: ERP Similarity Score: -0.0376
    Run 5, Batch 14: ERP Similarity Score: -0.0403
    Run 5, Batch 15: ERP Similarity Score: -0.0383
    Run 5, Batch 16: ERP Similarity Score: -0.0379
    Run 5, Batch 17: ERP Similarity Score: -0.0399
    Run 5, Batch 18: ERP Similarity Score: -0.0390
    Run 5, Batch 19: ERP Similarity Score: -0.0380
    Run 5, Batch 20: ERP Similarity Score: -0.0387
    Run 5, Batch 21: ERP Similarity Score: -0.0373
    Run 5, Batch 22: ERP Similarity Score: -0.0416
    Run 5, Batch 23: ERP Similarity Score: -0.0371
    Run 5, Batch 24: ERP Similarity Score: -0.0384
    Run 5, Batch 25: ERP Similarity Score: -0.0380
    Run 5, Batch 26: ERP Similarity Score: -0.0406
    Run 5, Batch 27: ERP Similarity Score: -0.0391
    Run 5, Batch 28: ERP Similarity Score: -0.0406
    Run 5, Batch 29: ERP Similarity Score: -0.0393
    Run 5, Batch 30: ERP Similarity Score: -0.0383


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 4, Batch 24, Score: -0.0303
  Top 2: Run 4, Batch 14, Score: -0.0309
  Top 3: Run 4, Batch 30, Score: -0.0310
  Top 4: Run 1, Batch 1, Score: -0.0311
  Top 5: Run 1, Batch 26, Score: -0.0312
  Top 6: Run 4, Batch 23, Score: -0.0315
  Top 7: Run 4, Batch 6, Score: -0.0316
  Top 8: Run 4, Batch 21, Score: -0.0316
  Top 9: Run 4, Batch 2, Score: -0.0317
  Top 10: Run 3, Batch 9, Score: -0.0321

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 4, Batch 24, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 4, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 4, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 14, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 4, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 30, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 4, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 1, Batch 1, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 1, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 1, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 26, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 1, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 1, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 4, Batch 23, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 23, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 23, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 23, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 4, Batch 6, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 4, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 21, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 4, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 2, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 4, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 4, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 3, Batch 9, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 3, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 60.00%

Found 11 strategies with the top validation accuracy of 80.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 14, Ratio 0): Accuracy=80.00, ERP Score=-0.0309
  - Strategy (Run 4, Batch 14, Ratio 1.0): Accuracy=80.00, ERP Score=-0.0309
  - Strategy (Run 1, Batch 1, Ratio 0): Accuracy=80.00, ERP Score=-0.0311
  - Strategy (Run 1, Batch 1, Ratio 1.0): Accuracy=80.00, ERP Score=-0.0311
  - Strategy (Run 4, Batch 23, Ratio 0.25): Accuracy=80.00, ERP Score=-0.0315
  - Strategy (Run 4, Batch 23, Ratio 0.5): Accuracy=80.00, ERP Score=-0.0315
  - Strategy (Run 4, Batch 6, Ratio 0.25): Accuracy=80.00, ERP Score=-0.0316
  - Strategy (Run 4, Batch 21, Ratio 0): Accuracy=80.00, ERP Score=-0.0316
  - Strategy (Run 4, Batch 21, Ratio 0.5): Accuracy=80.00, ERP Score=-0.0316
  - Strategy (Run 3, Batch 9, Ratio 0): Accuracy=80.00, ERP Score=-0.0321
  - Strategy (Run 3, Batch 9, Ratio 0.5): Accuracy=80.00, ERP Score=-0.0321

Selected best strategy: Run 4, Batch 14, Strategy: Synth Only with a validation accuracy of 80.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 80.00%) -> REAL test accuracy: 91.67%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 80.00%) -> REAL test accuracy: 91.67%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H3_results/Subject_7-8_results/target_synthetic_data_S7-8.mat
Saved non-target class of best synthetic batch to H3_results/Subject_7-8_results/nontarget_synthetic_data_S7-8.mat
Saved target class of training data to H3_results/Subject_7-8_results/target_training_data_S7-8.mat
Saved non-target class of training data to H3_results/Subject_7-8_results/nontarget_training_data_S7-8.mat

Saved accuracy comparison plot to: H3_results/Subject_7-8_results/accuracy_comparison_S7-8.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 7-8) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H3_results/Subject_7-8_results/GA_ERP_Combined_S7-8_ChCz.png

--- Subject 7-8 processing finished successfully. ---
