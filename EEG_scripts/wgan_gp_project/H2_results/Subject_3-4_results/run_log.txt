Log for Subject Pair 3-4 from H2
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H2 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 203 clean Target and 375 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 353

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 23

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 69.57%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=71.9856, G Loss (Comb)=1.4351
Epoch 50/1000: D Loss=-1.5794, G Loss (Comb)=-0.3845
Epoch 100/1000: D Loss=-0.4971, G Loss (Comb)=-4.0657
Epoch 150/1000: D Loss=-0.2408, G Loss (Comb)=-4.0917
Epoch 200/1000: D Loss=-0.3695, G Loss (Comb)=-3.9204
Epoch 250/1000: D Loss=-0.3461, G Loss (Comb)=-4.3690
Epoch 300/1000: D Loss=-0.2257, G Loss (Comb)=-4.5654
Epoch 350/1000: D Loss=-0.4038, G Loss (Comb)=-3.4680
Epoch 400/1000: D Loss=-0.3517, G Loss (Comb)=-3.9389
Epoch 450/1000: D Loss=-0.3633, G Loss (Comb)=-3.6895
Epoch 500/1000: D Loss=-0.3429, G Loss (Comb)=-3.5133
Epoch 550/1000: D Loss=-0.4132, G Loss (Comb)=-3.7642
Epoch 600/1000: D Loss=-0.4901, G Loss (Comb)=-3.7656
Epoch 650/1000: D Loss=-0.5118, G Loss (Comb)=-3.1630
Epoch 700/1000: D Loss=-0.4870, G Loss (Comb)=-3.5298
Epoch 750/1000: D Loss=-0.5304, G Loss (Comb)=-3.3102
Epoch 800/1000: D Loss=-0.6144, G Loss (Comb)=-3.5577
Epoch 850/1000: D Loss=-0.6111, G Loss (Comb)=-3.4645
Epoch 900/1000: D Loss=-0.5181, G Loss (Comb)=-3.4471
Epoch 950/1000: D Loss=-0.6568, G Loss (Comb)=-3.3765
Epoch 999/1000: D Loss=-0.6379, G Loss (Comb)=-3.6941

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0304
    Run 1, Batch 2: ERP Similarity Score: -0.0266
    Run 1, Batch 3: ERP Similarity Score: -0.0326
    Run 1, Batch 4: ERP Similarity Score: -0.0260
    Run 1, Batch 5: ERP Similarity Score: -0.0297
    Run 1, Batch 6: ERP Similarity Score: -0.0333
    Run 1, Batch 7: ERP Similarity Score: -0.0289
    Run 1, Batch 8: ERP Similarity Score: -0.0309
    Run 1, Batch 9: ERP Similarity Score: -0.0345
    Run 1, Batch 10: ERP Similarity Score: -0.0290
    Run 1, Batch 11: ERP Similarity Score: -0.0288
    Run 1, Batch 12: ERP Similarity Score: -0.0327
    Run 1, Batch 13: ERP Similarity Score: -0.0297
    Run 1, Batch 14: ERP Similarity Score: -0.0297
    Run 1, Batch 15: ERP Similarity Score: -0.0312
    Run 1, Batch 16: ERP Similarity Score: -0.0305
    Run 1, Batch 17: ERP Similarity Score: -0.0275
    Run 1, Batch 18: ERP Similarity Score: -0.0303
    Run 1, Batch 19: ERP Similarity Score: -0.0293
    Run 1, Batch 20: ERP Similarity Score: -0.0385
    Run 1, Batch 21: ERP Similarity Score: -0.0342
    Run 1, Batch 22: ERP Similarity Score: -0.0386
    Run 1, Batch 23: ERP Similarity Score: -0.0300
    Run 1, Batch 24: ERP Similarity Score: -0.0406
    Run 1, Batch 25: ERP Similarity Score: -0.0349
    Run 1, Batch 26: ERP Similarity Score: -0.0280
    Run 1, Batch 27: ERP Similarity Score: -0.0307
    Run 1, Batch 28: ERP Similarity Score: -0.0267
    Run 1, Batch 29: ERP Similarity Score: -0.0324
    Run 1, Batch 30: ERP Similarity Score: -0.0289

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=76.5409, G Loss (Comb)=0.9221
Epoch 50/1000: D Loss=-1.7215, G Loss (Comb)=-1.2049
Epoch 100/1000: D Loss=-0.5205, G Loss (Comb)=-5.0319
Epoch 150/1000: D Loss=-0.1215, G Loss (Comb)=-5.3696
Epoch 200/1000: D Loss=-0.3057, G Loss (Comb)=-5.2261
Epoch 250/1000: D Loss=-0.4094, G Loss (Comb)=-4.9826
Epoch 300/1000: D Loss=-0.2887, G Loss (Comb)=-4.8127
Epoch 350/1000: D Loss=-0.3342, G Loss (Comb)=-5.0215
Epoch 400/1000: D Loss=-0.3077, G Loss (Comb)=-5.1804
Epoch 450/1000: D Loss=-0.4078, G Loss (Comb)=-4.4804
Epoch 500/1000: D Loss=-0.2910, G Loss (Comb)=-4.3492
Epoch 550/1000: D Loss=-0.3394, G Loss (Comb)=-4.3987
Epoch 600/1000: D Loss=-0.4411, G Loss (Comb)=-4.2034
Epoch 650/1000: D Loss=-0.4973, G Loss (Comb)=-4.2133
Epoch 700/1000: D Loss=-0.5488, G Loss (Comb)=-4.0077
Epoch 750/1000: D Loss=-0.6191, G Loss (Comb)=-3.8636
Epoch 800/1000: D Loss=-0.6201, G Loss (Comb)=-3.8037
Epoch 850/1000: D Loss=-0.6598, G Loss (Comb)=-3.8351
Epoch 900/1000: D Loss=-0.7129, G Loss (Comb)=-3.8006
Epoch 950/1000: D Loss=-0.6755, G Loss (Comb)=-3.9561
Epoch 999/1000: D Loss=-0.7581, G Loss (Comb)=-3.8133

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0329
    Run 2, Batch 2: ERP Similarity Score: -0.0357
    Run 2, Batch 3: ERP Similarity Score: -0.0326
    Run 2, Batch 4: ERP Similarity Score: -0.0282
    Run 2, Batch 5: ERP Similarity Score: -0.0313
    Run 2, Batch 6: ERP Similarity Score: -0.0372
    Run 2, Batch 7: ERP Similarity Score: -0.0369
    Run 2, Batch 8: ERP Similarity Score: -0.0407
    Run 2, Batch 9: ERP Similarity Score: -0.0337
    Run 2, Batch 10: ERP Similarity Score: -0.0295
    Run 2, Batch 11: ERP Similarity Score: -0.0361
    Run 2, Batch 12: ERP Similarity Score: -0.0355
    Run 2, Batch 13: ERP Similarity Score: -0.0338
    Run 2, Batch 14: ERP Similarity Score: -0.0319
    Run 2, Batch 15: ERP Similarity Score: -0.0408
    Run 2, Batch 16: ERP Similarity Score: -0.0325
    Run 2, Batch 17: ERP Similarity Score: -0.0308
    Run 2, Batch 18: ERP Similarity Score: -0.0404
    Run 2, Batch 19: ERP Similarity Score: -0.0400
    Run 2, Batch 20: ERP Similarity Score: -0.0296
    Run 2, Batch 21: ERP Similarity Score: -0.0417
    Run 2, Batch 22: ERP Similarity Score: -0.0354
    Run 2, Batch 23: ERP Similarity Score: -0.0338
    Run 2, Batch 24: ERP Similarity Score: -0.0333
    Run 2, Batch 25: ERP Similarity Score: -0.0323
    Run 2, Batch 26: ERP Similarity Score: -0.0311
    Run 2, Batch 27: ERP Similarity Score: -0.0310
    Run 2, Batch 28: ERP Similarity Score: -0.0339
    Run 2, Batch 29: ERP Similarity Score: -0.0344
    Run 2, Batch 30: ERP Similarity Score: -0.0376

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=85.2082, G Loss (Comb)=0.4180
Epoch 50/1000: D Loss=-1.7914, G Loss (Comb)=-1.6054
Epoch 100/1000: D Loss=-0.4063, G Loss (Comb)=-5.8371
Epoch 150/1000: D Loss=-0.2841, G Loss (Comb)=-5.2635
Epoch 200/1000: D Loss=-0.4230, G Loss (Comb)=-4.6417
Epoch 250/1000: D Loss=-0.2200, G Loss (Comb)=-4.3488
Epoch 300/1000: D Loss=-0.3731, G Loss (Comb)=-4.7671
Epoch 350/1000: D Loss=-0.3077, G Loss (Comb)=-4.7929
Epoch 400/1000: D Loss=-0.3840, G Loss (Comb)=-4.6449
Epoch 450/1000: D Loss=-0.4317, G Loss (Comb)=-4.7097
Epoch 500/1000: D Loss=-0.3948, G Loss (Comb)=-4.6251
Epoch 550/1000: D Loss=-0.3948, G Loss (Comb)=-4.7351
Epoch 600/1000: D Loss=-0.3647, G Loss (Comb)=-4.3812
Epoch 650/1000: D Loss=-0.3897, G Loss (Comb)=-4.2613
Epoch 700/1000: D Loss=-0.5463, G Loss (Comb)=-3.8475
Epoch 750/1000: D Loss=-0.4180, G Loss (Comb)=-3.8809
Epoch 800/1000: D Loss=-0.5464, G Loss (Comb)=-3.8098
Epoch 850/1000: D Loss=-0.6525, G Loss (Comb)=-3.5844
Epoch 900/1000: D Loss=-0.6056, G Loss (Comb)=-3.7764
Epoch 950/1000: D Loss=-0.6799, G Loss (Comb)=-3.8527
Epoch 999/1000: D Loss=-0.6818, G Loss (Comb)=-3.8417

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0339
    Run 3, Batch 2: ERP Similarity Score: -0.0382
    Run 3, Batch 3: ERP Similarity Score: -0.0354
    Run 3, Batch 4: ERP Similarity Score: -0.0339
    Run 3, Batch 5: ERP Similarity Score: -0.0381
    Run 3, Batch 6: ERP Similarity Score: -0.0417
    Run 3, Batch 7: ERP Similarity Score: -0.0354
    Run 3, Batch 8: ERP Similarity Score: -0.0357
    Run 3, Batch 9: ERP Similarity Score: -0.0362
    Run 3, Batch 10: ERP Similarity Score: -0.0408
    Run 3, Batch 11: ERP Similarity Score: -0.0375
    Run 3, Batch 12: ERP Similarity Score: -0.0362
    Run 3, Batch 13: ERP Similarity Score: -0.0380
    Run 3, Batch 14: ERP Similarity Score: -0.0356
    Run 3, Batch 15: ERP Similarity Score: -0.0391
    Run 3, Batch 16: ERP Similarity Score: -0.0404
    Run 3, Batch 17: ERP Similarity Score: -0.0366
    Run 3, Batch 18: ERP Similarity Score: -0.0336
    Run 3, Batch 19: ERP Similarity Score: -0.0350
    Run 3, Batch 20: ERP Similarity Score: -0.0346
    Run 3, Batch 21: ERP Similarity Score: -0.0505
    Run 3, Batch 22: ERP Similarity Score: -0.0316
    Run 3, Batch 23: ERP Similarity Score: -0.0414
    Run 3, Batch 24: ERP Similarity Score: -0.0389
    Run 3, Batch 25: ERP Similarity Score: -0.0384
    Run 3, Batch 26: ERP Similarity Score: -0.0339
    Run 3, Batch 27: ERP Similarity Score: -0.0376
    Run 3, Batch 28: ERP Similarity Score: -0.0345
    Run 3, Batch 29: ERP Similarity Score: -0.0363
    Run 3, Batch 30: ERP Similarity Score: -0.0352

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=80.4591, G Loss (Comb)=-1.2739
Epoch 50/1000: D Loss=-1.6410, G Loss (Comb)=-3.2293
Epoch 100/1000: D Loss=-0.3847, G Loss (Comb)=-7.0292
Epoch 150/1000: D Loss=-0.3459, G Loss (Comb)=-6.5063
Epoch 200/1000: D Loss=-0.3661, G Loss (Comb)=-6.7255
Epoch 250/1000: D Loss=-0.3595, G Loss (Comb)=-7.0694
Epoch 300/1000: D Loss=-0.3398, G Loss (Comb)=-6.5650
Epoch 350/1000: D Loss=-0.1983, G Loss (Comb)=-6.5139
Epoch 400/1000: D Loss=-0.3665, G Loss (Comb)=-6.2765
Epoch 450/1000: D Loss=-0.2363, G Loss (Comb)=-6.6706
Epoch 500/1000: D Loss=-0.4312, G Loss (Comb)=-6.3565
Epoch 550/1000: D Loss=-0.4054, G Loss (Comb)=-6.0383
Epoch 600/1000: D Loss=-0.5164, G Loss (Comb)=-6.0076
Epoch 650/1000: D Loss=-0.5102, G Loss (Comb)=-5.8092
Epoch 700/1000: D Loss=-0.5490, G Loss (Comb)=-5.8464
Epoch 750/1000: D Loss=-0.5893, G Loss (Comb)=-5.6192
Epoch 800/1000: D Loss=-0.5902, G Loss (Comb)=-5.7301
Epoch 850/1000: D Loss=-0.6150, G Loss (Comb)=-5.4216
Epoch 900/1000: D Loss=-0.6473, G Loss (Comb)=-5.5231
Epoch 950/1000: D Loss=-0.7322, G Loss (Comb)=-5.5262
Epoch 999/1000: D Loss=-0.7044, G Loss (Comb)=-5.4865

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0340
    Run 4, Batch 2: ERP Similarity Score: -0.0344
    Run 4, Batch 3: ERP Similarity Score: -0.0368
    Run 4, Batch 4: ERP Similarity Score: -0.0382
    Run 4, Batch 5: ERP Similarity Score: -0.0376
    Run 4, Batch 6: ERP Similarity Score: -0.0402
    Run 4, Batch 7: ERP Similarity Score: -0.0458
    Run 4, Batch 8: ERP Similarity Score: -0.0348
    Run 4, Batch 9: ERP Similarity Score: -0.0406
    Run 4, Batch 10: ERP Similarity Score: -0.0290
    Run 4, Batch 11: ERP Similarity Score: -0.0294
    Run 4, Batch 12: ERP Similarity Score: -0.0340
    Run 4, Batch 13: ERP Similarity Score: -0.0319
    Run 4, Batch 14: ERP Similarity Score: -0.0355
    Run 4, Batch 15: ERP Similarity Score: -0.0342
    Run 4, Batch 16: ERP Similarity Score: -0.0385
    Run 4, Batch 17: ERP Similarity Score: -0.0327
    Run 4, Batch 18: ERP Similarity Score: -0.0343
    Run 4, Batch 19: ERP Similarity Score: -0.0317
    Run 4, Batch 20: ERP Similarity Score: -0.0369
    Run 4, Batch 21: ERP Similarity Score: -0.0415
    Run 4, Batch 22: ERP Similarity Score: -0.0370
    Run 4, Batch 23: ERP Similarity Score: -0.0404
    Run 4, Batch 24: ERP Similarity Score: -0.0309
    Run 4, Batch 25: ERP Similarity Score: -0.0399
    Run 4, Batch 26: ERP Similarity Score: -0.0385
    Run 4, Batch 27: ERP Similarity Score: -0.0301
    Run 4, Batch 28: ERP Similarity Score: -0.0317
    Run 4, Batch 29: ERP Similarity Score: -0.0404
    Run 4, Batch 30: ERP Similarity Score: -0.0335

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=74.5448, G Loss (Comb)=1.7711
Epoch 50/1000: D Loss=-1.4534, G Loss (Comb)=-0.8933
Epoch 100/1000: D Loss=-0.5033, G Loss (Comb)=-3.8738
Epoch 150/1000: D Loss=-0.2318, G Loss (Comb)=-4.2734
Epoch 200/1000: D Loss=-0.3292, G Loss (Comb)=-3.8945
Epoch 250/1000: D Loss=-0.3338, G Loss (Comb)=-3.7335
Epoch 300/1000: D Loss=-0.3212, G Loss (Comb)=-3.0923
Epoch 350/1000: D Loss=-0.4368, G Loss (Comb)=-3.0413
Epoch 400/1000: D Loss=-0.5109, G Loss (Comb)=-2.9911
Epoch 450/1000: D Loss=-0.3205, G Loss (Comb)=-3.0288
Epoch 500/1000: D Loss=-0.3945, G Loss (Comb)=-3.0852
Epoch 550/1000: D Loss=-0.4315, G Loss (Comb)=-2.6291
Epoch 600/1000: D Loss=-0.4872, G Loss (Comb)=-2.7707
Epoch 650/1000: D Loss=-0.4594, G Loss (Comb)=-2.4281
Epoch 700/1000: D Loss=-0.5498, G Loss (Comb)=-2.6230
Epoch 750/1000: D Loss=-0.5903, G Loss (Comb)=-2.5475
Epoch 800/1000: D Loss=-0.5698, G Loss (Comb)=-2.5551
Epoch 850/1000: D Loss=-0.6924, G Loss (Comb)=-2.5115
Epoch 900/1000: D Loss=-0.6241, G Loss (Comb)=-2.4692
Epoch 950/1000: D Loss=-0.6822, G Loss (Comb)=-2.6608
Epoch 999/1000: D Loss=-0.6940, G Loss (Comb)=-2.5115

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0465
    Run 5, Batch 2: ERP Similarity Score: -0.0417
    Run 5, Batch 3: ERP Similarity Score: -0.0344
    Run 5, Batch 4: ERP Similarity Score: -0.0491
    Run 5, Batch 5: ERP Similarity Score: -0.0355
    Run 5, Batch 6: ERP Similarity Score: -0.0413
    Run 5, Batch 7: ERP Similarity Score: -0.0425
    Run 5, Batch 8: ERP Similarity Score: -0.0436
    Run 5, Batch 9: ERP Similarity Score: -0.0458
    Run 5, Batch 10: ERP Similarity Score: -0.0402
    Run 5, Batch 11: ERP Similarity Score: -0.0358
    Run 5, Batch 12: ERP Similarity Score: -0.0365
    Run 5, Batch 13: ERP Similarity Score: -0.0383
    Run 5, Batch 14: ERP Similarity Score: -0.0373
    Run 5, Batch 15: ERP Similarity Score: -0.0303
    Run 5, Batch 16: ERP Similarity Score: -0.0412
    Run 5, Batch 17: ERP Similarity Score: -0.0303
    Run 5, Batch 18: ERP Similarity Score: -0.0448
    Run 5, Batch 19: ERP Similarity Score: -0.0338
    Run 5, Batch 20: ERP Similarity Score: -0.0450
    Run 5, Batch 21: ERP Similarity Score: -0.0417
    Run 5, Batch 22: ERP Similarity Score: -0.0433
    Run 5, Batch 23: ERP Similarity Score: -0.0433
    Run 5, Batch 24: ERP Similarity Score: -0.0421
    Run 5, Batch 25: ERP Similarity Score: -0.0387
    Run 5, Batch 26: ERP Similarity Score: -0.0389
    Run 5, Batch 27: ERP Similarity Score: -0.0407
    Run 5, Batch 28: ERP Similarity Score: -0.0381
    Run 5, Batch 29: ERP Similarity Score: -0.0489
    Run 5, Batch 30: ERP Similarity Score: -0.0339


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 1, Batch 4, Score: -0.0260
  Top 2: Run 1, Batch 2, Score: -0.0266
  Top 3: Run 1, Batch 28, Score: -0.0267
  Top 4: Run 1, Batch 17, Score: -0.0275
  Top 5: Run 1, Batch 26, Score: -0.0280
  Top 6: Run 2, Batch 4, Score: -0.0282
  Top 7: Run 1, Batch 11, Score: -0.0288
  Top 8: Run 1, Batch 30, Score: -0.0289
  Top 9: Run 1, Batch 7, Score: -0.0289
  Top 10: Run 4, Batch 10, Score: -0.0290

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 1, Batch 4, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 2, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 0.00%
    Run 1, Batch 28, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 17, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 26, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 4, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 2, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 11, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 30, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 7, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 1, Batch 7, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 7, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 7, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 10, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 27 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 1, Batch 4, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0260
  - Strategy (Run 1, Batch 4, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0260
  - Strategy (Run 1, Batch 4, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0260
  - Strategy (Run 1, Batch 2, Ratio 0): Accuracy=100.00, ERP Score=-0.0266
  - Strategy (Run 1, Batch 2, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0266
  - Strategy (Run 1, Batch 28, Ratio 0): Accuracy=100.00, ERP Score=-0.0267
  - Strategy (Run 1, Batch 28, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0267
  - Strategy (Run 1, Batch 28, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0267
  - Strategy (Run 1, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0267
  - Strategy (Run 1, Batch 17, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0275
  - Strategy (Run 1, Batch 17, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0275
  - Strategy (Run 1, Batch 17, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0275
  - Strategy (Run 1, Batch 26, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0280
  - Strategy (Run 1, Batch 26, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0280
  - Strategy (Run 1, Batch 26, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0280
  - Strategy (Run 2, Batch 4, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0282
  - Strategy (Run 2, Batch 4, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0282
  - Strategy (Run 1, Batch 11, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0288
  - Strategy (Run 1, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0288
  - Strategy (Run 1, Batch 11, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0288
  - Strategy (Run 1, Batch 30, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0289
  - Strategy (Run 1, Batch 30, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0289
  - Strategy (Run 1, Batch 30, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0289
  - Strategy (Run 1, Batch 7, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0289
  - Strategy (Run 1, Batch 7, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0289
  - Strategy (Run 1, Batch 7, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0289
  - Strategy (Run 4, Batch 10, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0290

Selected best strategy: Run 1, Batch 4, Strategy: Augmented (25%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 73.91%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (25%), Val Acc: 100.00%) -> REAL test accuracy: 73.91%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H2_results/Subject_3-4_results/target_synthetic_data_S3-4.mat
Saved non-target class of best synthetic batch to H2_results/Subject_3-4_results/nontarget_synthetic_data_S3-4.mat
Saved target class of training data to H2_results/Subject_3-4_results/target_training_data_S3-4.mat
Saved non-target class of training data to H2_results/Subject_3-4_results/nontarget_training_data_S3-4.mat

Saved accuracy comparison plot to: H2_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H2_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
