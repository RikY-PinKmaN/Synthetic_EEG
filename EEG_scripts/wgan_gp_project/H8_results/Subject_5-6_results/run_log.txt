Log for Subject Pair 5-6 from H8
========================================


========================= PROCESSING SUBJECT PAIR: 5-6 from H8 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 255 clean Target and 997 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 877

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 58

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 82.76%

--- Training cWGAN-GP for Subject 5-6, Run 1 ---
Epoch 0/1000: D Loss=72.2510, G Loss (Comb)=1.1164
Epoch 50/1000: D Loss=-0.3528, G Loss (Comb)=-4.4043
Epoch 100/1000: D Loss=-0.2544, G Loss (Comb)=-4.1626
Epoch 150/1000: D Loss=-0.2723, G Loss (Comb)=-3.8856
Epoch 200/1000: D Loss=-0.2644, G Loss (Comb)=-4.2249
Epoch 250/1000: D Loss=-0.2228, G Loss (Comb)=-4.0578
Epoch 300/1000: D Loss=-0.3198, G Loss (Comb)=-4.1408
Epoch 350/1000: D Loss=-0.2134, G Loss (Comb)=-4.1467
Epoch 400/1000: D Loss=-0.2341, G Loss (Comb)=-4.2211
Epoch 450/1000: D Loss=-0.2865, G Loss (Comb)=-3.8817
Epoch 500/1000: D Loss=-0.3546, G Loss (Comb)=-3.8827
Epoch 550/1000: D Loss=-0.3519, G Loss (Comb)=-4.0948
Epoch 600/1000: D Loss=-0.4335, G Loss (Comb)=-4.2210
Epoch 650/1000: D Loss=-0.4775, G Loss (Comb)=-4.3892
Epoch 700/1000: D Loss=-0.4811, G Loss (Comb)=-4.2439
Epoch 750/1000: D Loss=-0.5556, G Loss (Comb)=-4.4294
Epoch 800/1000: D Loss=-0.4903, G Loss (Comb)=-4.4306
Epoch 850/1000: D Loss=-0.5802, G Loss (Comb)=-4.6457
Epoch 900/1000: D Loss=-0.5980, G Loss (Comb)=-4.7198
Epoch 950/1000: D Loss=-0.6730, G Loss (Comb)=-4.5887
Epoch 999/1000: D Loss=-0.6502, G Loss (Comb)=-4.6628

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0503
    Run 1, Batch 2: ERP Similarity Score: -0.0509
    Run 1, Batch 3: ERP Similarity Score: -0.0406
    Run 1, Batch 4: ERP Similarity Score: -0.0469
    Run 1, Batch 5: ERP Similarity Score: -0.0414
    Run 1, Batch 6: ERP Similarity Score: -0.0466
    Run 1, Batch 7: ERP Similarity Score: -0.0487
    Run 1, Batch 8: ERP Similarity Score: -0.0442
    Run 1, Batch 9: ERP Similarity Score: -0.0484
    Run 1, Batch 10: ERP Similarity Score: -0.0476
    Run 1, Batch 11: ERP Similarity Score: -0.0487
    Run 1, Batch 12: ERP Similarity Score: -0.0459
    Run 1, Batch 13: ERP Similarity Score: -0.0484
    Run 1, Batch 14: ERP Similarity Score: -0.0433
    Run 1, Batch 15: ERP Similarity Score: -0.0539
    Run 1, Batch 16: ERP Similarity Score: -0.0420
    Run 1, Batch 17: ERP Similarity Score: -0.0379
    Run 1, Batch 18: ERP Similarity Score: -0.0504
    Run 1, Batch 19: ERP Similarity Score: -0.0472
    Run 1, Batch 20: ERP Similarity Score: -0.0340
    Run 1, Batch 21: ERP Similarity Score: -0.0494
    Run 1, Batch 22: ERP Similarity Score: -0.0394
    Run 1, Batch 23: ERP Similarity Score: -0.0412
    Run 1, Batch 24: ERP Similarity Score: -0.0492
    Run 1, Batch 25: ERP Similarity Score: -0.0392
    Run 1, Batch 26: ERP Similarity Score: -0.0495
    Run 1, Batch 27: ERP Similarity Score: -0.0464
    Run 1, Batch 28: ERP Similarity Score: -0.0448
    Run 1, Batch 29: ERP Similarity Score: -0.0520
    Run 1, Batch 30: ERP Similarity Score: -0.0437

--- Training cWGAN-GP for Subject 5-6, Run 2 ---
Epoch 0/1000: D Loss=79.4000, G Loss (Comb)=1.5001
Epoch 50/1000: D Loss=-0.3771, G Loss (Comb)=-4.8470
Epoch 100/1000: D Loss=-0.2042, G Loss (Comb)=-4.5648
Epoch 150/1000: D Loss=-0.1191, G Loss (Comb)=-3.8744
Epoch 200/1000: D Loss=-0.0454, G Loss (Comb)=-4.0298
Epoch 250/1000: D Loss=-0.0401, G Loss (Comb)=-3.5952
Epoch 300/1000: D Loss=-0.2212, G Loss (Comb)=-3.7920
Epoch 350/1000: D Loss=-0.2912, G Loss (Comb)=-3.5981
Epoch 400/1000: D Loss=-0.3170, G Loss (Comb)=-4.0346
Epoch 450/1000: D Loss=-0.2423, G Loss (Comb)=-3.8388
Epoch 500/1000: D Loss=-0.2348, G Loss (Comb)=-4.1172
Epoch 550/1000: D Loss=-0.4220, G Loss (Comb)=-3.7322
Epoch 600/1000: D Loss=-0.3883, G Loss (Comb)=-4.1202
Epoch 650/1000: D Loss=-0.4726, G Loss (Comb)=-4.0073
Epoch 700/1000: D Loss=-0.4688, G Loss (Comb)=-4.3045
Epoch 750/1000: D Loss=-0.5298, G Loss (Comb)=-4.3045
Epoch 800/1000: D Loss=-0.5073, G Loss (Comb)=-4.4120
Epoch 850/1000: D Loss=-0.5402, G Loss (Comb)=-4.3778
Epoch 900/1000: D Loss=-0.5920, G Loss (Comb)=-4.4323
Epoch 950/1000: D Loss=-0.6534, G Loss (Comb)=-4.6188
Epoch 999/1000: D Loss=-0.6923, G Loss (Comb)=-4.5812

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0401
    Run 2, Batch 2: ERP Similarity Score: -0.0338
    Run 2, Batch 3: ERP Similarity Score: -0.0366
    Run 2, Batch 4: ERP Similarity Score: -0.0472
    Run 2, Batch 5: ERP Similarity Score: -0.0425
    Run 2, Batch 6: ERP Similarity Score: -0.0396
    Run 2, Batch 7: ERP Similarity Score: -0.0457
    Run 2, Batch 8: ERP Similarity Score: -0.0405
    Run 2, Batch 9: ERP Similarity Score: -0.0515
    Run 2, Batch 10: ERP Similarity Score: -0.0520
    Run 2, Batch 11: ERP Similarity Score: -0.0437
    Run 2, Batch 12: ERP Similarity Score: -0.0449
    Run 2, Batch 13: ERP Similarity Score: -0.0444
    Run 2, Batch 14: ERP Similarity Score: -0.0438
    Run 2, Batch 15: ERP Similarity Score: -0.0434
    Run 2, Batch 16: ERP Similarity Score: -0.0410
    Run 2, Batch 17: ERP Similarity Score: -0.0408
    Run 2, Batch 18: ERP Similarity Score: -0.0458
    Run 2, Batch 19: ERP Similarity Score: -0.0433
    Run 2, Batch 20: ERP Similarity Score: -0.0434
    Run 2, Batch 21: ERP Similarity Score: -0.0433
    Run 2, Batch 22: ERP Similarity Score: -0.0467
    Run 2, Batch 23: ERP Similarity Score: -0.0430
    Run 2, Batch 24: ERP Similarity Score: -0.0434
    Run 2, Batch 25: ERP Similarity Score: -0.0346
    Run 2, Batch 26: ERP Similarity Score: -0.0401
    Run 2, Batch 27: ERP Similarity Score: -0.0475
    Run 2, Batch 28: ERP Similarity Score: -0.0441
    Run 2, Batch 29: ERP Similarity Score: -0.0324
    Run 2, Batch 30: ERP Similarity Score: -0.0439

--- Training cWGAN-GP for Subject 5-6, Run 3 ---
Epoch 0/1000: D Loss=81.9545, G Loss (Comb)=0.5519
Epoch 50/1000: D Loss=-0.4877, G Loss (Comb)=-5.3570
Epoch 100/1000: D Loss=-0.1404, G Loss (Comb)=-5.4733
Epoch 150/1000: D Loss=-0.2972, G Loss (Comb)=-5.0295
Epoch 200/1000: D Loss=-0.1395, G Loss (Comb)=-4.8205
Epoch 250/1000: D Loss=-0.2360, G Loss (Comb)=-4.8930
Epoch 300/1000: D Loss=-0.3514, G Loss (Comb)=-4.6831
Epoch 350/1000: D Loss=-0.2315, G Loss (Comb)=-4.6477
Epoch 400/1000: D Loss=-0.2332, G Loss (Comb)=-4.9493
Epoch 450/1000: D Loss=-0.3408, G Loss (Comb)=-4.9761
Epoch 500/1000: D Loss=-0.3931, G Loss (Comb)=-4.7929
Epoch 550/1000: D Loss=-0.4120, G Loss (Comb)=-4.7530
Epoch 600/1000: D Loss=-0.5084, G Loss (Comb)=-4.8970
Epoch 650/1000: D Loss=-0.5043, G Loss (Comb)=-4.8581
Epoch 700/1000: D Loss=-0.6060, G Loss (Comb)=-4.9554
Epoch 750/1000: D Loss=-0.5893, G Loss (Comb)=-5.3595
Epoch 800/1000: D Loss=-0.6063, G Loss (Comb)=-5.3962
Epoch 850/1000: D Loss=-0.7010, G Loss (Comb)=-5.5690
Epoch 900/1000: D Loss=-0.7088, G Loss (Comb)=-5.8580
Epoch 950/1000: D Loss=-0.7544, G Loss (Comb)=-5.8820
Epoch 999/1000: D Loss=-0.7933, G Loss (Comb)=-5.9281

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0494
    Run 3, Batch 2: ERP Similarity Score: -0.0507
    Run 3, Batch 3: ERP Similarity Score: -0.0445
    Run 3, Batch 4: ERP Similarity Score: -0.0399
    Run 3, Batch 5: ERP Similarity Score: -0.0356
    Run 3, Batch 6: ERP Similarity Score: -0.0482
    Run 3, Batch 7: ERP Similarity Score: -0.0432
    Run 3, Batch 8: ERP Similarity Score: -0.0452
    Run 3, Batch 9: ERP Similarity Score: -0.0482
    Run 3, Batch 10: ERP Similarity Score: -0.0509
    Run 3, Batch 11: ERP Similarity Score: -0.0424
    Run 3, Batch 12: ERP Similarity Score: -0.0444
    Run 3, Batch 13: ERP Similarity Score: -0.0281
    Run 3, Batch 14: ERP Similarity Score: -0.0458
    Run 3, Batch 15: ERP Similarity Score: -0.0370
    Run 3, Batch 16: ERP Similarity Score: -0.0412
    Run 3, Batch 17: ERP Similarity Score: -0.0381
    Run 3, Batch 18: ERP Similarity Score: -0.0324
    Run 3, Batch 19: ERP Similarity Score: -0.0541
    Run 3, Batch 20: ERP Similarity Score: -0.0391
    Run 3, Batch 21: ERP Similarity Score: -0.0408
    Run 3, Batch 22: ERP Similarity Score: -0.0393
    Run 3, Batch 23: ERP Similarity Score: -0.0368
    Run 3, Batch 24: ERP Similarity Score: -0.0389
    Run 3, Batch 25: ERP Similarity Score: -0.0418
    Run 3, Batch 26: ERP Similarity Score: -0.0383
    Run 3, Batch 27: ERP Similarity Score: -0.0349
    Run 3, Batch 28: ERP Similarity Score: -0.0439
    Run 3, Batch 29: ERP Similarity Score: -0.0382
    Run 3, Batch 30: ERP Similarity Score: -0.0408

--- Training cWGAN-GP for Subject 5-6, Run 4 ---
Epoch 0/1000: D Loss=83.0924, G Loss (Comb)=1.3156
Epoch 50/1000: D Loss=-0.3393, G Loss (Comb)=-5.0184
Epoch 100/1000: D Loss=-0.2388, G Loss (Comb)=-4.3099
Epoch 150/1000: D Loss=-0.0244, G Loss (Comb)=-4.0579
Epoch 200/1000: D Loss=-0.1209, G Loss (Comb)=-4.0178
Epoch 250/1000: D Loss=-0.1927, G Loss (Comb)=-3.5955
Epoch 300/1000: D Loss=-0.3228, G Loss (Comb)=-3.5570
Epoch 350/1000: D Loss=-0.0655, G Loss (Comb)=-3.6838
Epoch 400/1000: D Loss=-0.2041, G Loss (Comb)=-4.2219
Epoch 450/1000: D Loss=-0.3933, G Loss (Comb)=-4.2329
Epoch 500/1000: D Loss=-0.3624, G Loss (Comb)=-4.3151
Epoch 550/1000: D Loss=-0.3965, G Loss (Comb)=-4.3334
Epoch 600/1000: D Loss=-0.3870, G Loss (Comb)=-4.7393
Epoch 650/1000: D Loss=-0.4536, G Loss (Comb)=-5.1893
Epoch 700/1000: D Loss=-0.5274, G Loss (Comb)=-5.1647
Epoch 750/1000: D Loss=-0.5267, G Loss (Comb)=-5.5825
Epoch 800/1000: D Loss=-0.5826, G Loss (Comb)=-5.6569
Epoch 850/1000: D Loss=-0.6106, G Loss (Comb)=-5.7385
Epoch 900/1000: D Loss=-0.6619, G Loss (Comb)=-5.9192
Epoch 950/1000: D Loss=-0.6982, G Loss (Comb)=-6.1252
Epoch 999/1000: D Loss=-0.6995, G Loss (Comb)=-6.1513

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0427
    Run 4, Batch 2: ERP Similarity Score: -0.0400
    Run 4, Batch 3: ERP Similarity Score: -0.0439
    Run 4, Batch 4: ERP Similarity Score: -0.0348
    Run 4, Batch 5: ERP Similarity Score: -0.0427
    Run 4, Batch 6: ERP Similarity Score: -0.0424
    Run 4, Batch 7: ERP Similarity Score: -0.0472
    Run 4, Batch 8: ERP Similarity Score: -0.0401
    Run 4, Batch 9: ERP Similarity Score: -0.0355
    Run 4, Batch 10: ERP Similarity Score: -0.0456
    Run 4, Batch 11: ERP Similarity Score: -0.0413
    Run 4, Batch 12: ERP Similarity Score: -0.0428
    Run 4, Batch 13: ERP Similarity Score: -0.0430
    Run 4, Batch 14: ERP Similarity Score: -0.0409
    Run 4, Batch 15: ERP Similarity Score: -0.0398
    Run 4, Batch 16: ERP Similarity Score: -0.0357
    Run 4, Batch 17: ERP Similarity Score: -0.0413
    Run 4, Batch 18: ERP Similarity Score: -0.0433
    Run 4, Batch 19: ERP Similarity Score: -0.0361
    Run 4, Batch 20: ERP Similarity Score: -0.0370
    Run 4, Batch 21: ERP Similarity Score: -0.0415
    Run 4, Batch 22: ERP Similarity Score: -0.0419
    Run 4, Batch 23: ERP Similarity Score: -0.0478
    Run 4, Batch 24: ERP Similarity Score: -0.0408
    Run 4, Batch 25: ERP Similarity Score: -0.0387
    Run 4, Batch 26: ERP Similarity Score: -0.0437
    Run 4, Batch 27: ERP Similarity Score: -0.0410
    Run 4, Batch 28: ERP Similarity Score: -0.0387
    Run 4, Batch 29: ERP Similarity Score: -0.0494
    Run 4, Batch 30: ERP Similarity Score: -0.0411

--- Training cWGAN-GP for Subject 5-6, Run 5 ---
Epoch 0/1000: D Loss=78.7188, G Loss (Comb)=0.9893
Epoch 50/1000: D Loss=-0.3995, G Loss (Comb)=-4.4756
Epoch 100/1000: D Loss=-0.1869, G Loss (Comb)=-4.0901
Epoch 150/1000: D Loss=-0.1715, G Loss (Comb)=-3.7236
Epoch 200/1000: D Loss=-0.1783, G Loss (Comb)=-4.0552
Epoch 250/1000: D Loss=-0.3023, G Loss (Comb)=-3.7753
Epoch 300/1000: D Loss=-0.2587, G Loss (Comb)=-3.5315
Epoch 350/1000: D Loss=-0.2374, G Loss (Comb)=-3.4866
Epoch 400/1000: D Loss=-0.2744, G Loss (Comb)=-3.5125
Epoch 450/1000: D Loss=-0.3424, G Loss (Comb)=-3.5997
Epoch 500/1000: D Loss=-0.3314, G Loss (Comb)=-3.8644
Epoch 550/1000: D Loss=-0.4149, G Loss (Comb)=-3.9696
Epoch 600/1000: D Loss=-0.3783, G Loss (Comb)=-4.1055
Epoch 650/1000: D Loss=-0.4745, G Loss (Comb)=-4.4025
Epoch 700/1000: D Loss=-0.5644, G Loss (Comb)=-4.3647
Epoch 750/1000: D Loss=-0.5657, G Loss (Comb)=-4.5174
Epoch 800/1000: D Loss=-0.5515, G Loss (Comb)=-4.5356
Epoch 850/1000: D Loss=-0.6080, G Loss (Comb)=-4.6510
Epoch 900/1000: D Loss=-0.6513, G Loss (Comb)=-4.8169
Epoch 950/1000: D Loss=-0.6937, G Loss (Comb)=-4.8366
Epoch 999/1000: D Loss=-0.6971, G Loss (Comb)=-4.8174

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0404
    Run 5, Batch 2: ERP Similarity Score: -0.0315
    Run 5, Batch 3: ERP Similarity Score: -0.0392
    Run 5, Batch 4: ERP Similarity Score: -0.0434
    Run 5, Batch 5: ERP Similarity Score: -0.0468
    Run 5, Batch 6: ERP Similarity Score: -0.0361
    Run 5, Batch 7: ERP Similarity Score: -0.0416
    Run 5, Batch 8: ERP Similarity Score: -0.0398
    Run 5, Batch 9: ERP Similarity Score: -0.0457
    Run 5, Batch 10: ERP Similarity Score: -0.0395
    Run 5, Batch 11: ERP Similarity Score: -0.0470
    Run 5, Batch 12: ERP Similarity Score: -0.0399
    Run 5, Batch 13: ERP Similarity Score: -0.0352
    Run 5, Batch 14: ERP Similarity Score: -0.0386
    Run 5, Batch 15: ERP Similarity Score: -0.0394
    Run 5, Batch 16: ERP Similarity Score: -0.0408
    Run 5, Batch 17: ERP Similarity Score: -0.0410
    Run 5, Batch 18: ERP Similarity Score: -0.0453
    Run 5, Batch 19: ERP Similarity Score: -0.0347
    Run 5, Batch 20: ERP Similarity Score: -0.0361
    Run 5, Batch 21: ERP Similarity Score: -0.0412
    Run 5, Batch 22: ERP Similarity Score: -0.0346
    Run 5, Batch 23: ERP Similarity Score: -0.0362
    Run 5, Batch 24: ERP Similarity Score: -0.0442
    Run 5, Batch 25: ERP Similarity Score: -0.0391
    Run 5, Batch 26: ERP Similarity Score: -0.0382
    Run 5, Batch 27: ERP Similarity Score: -0.0370
    Run 5, Batch 28: ERP Similarity Score: -0.0432
    Run 5, Batch 29: ERP Similarity Score: -0.0372
    Run 5, Batch 30: ERP Similarity Score: -0.0370


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 13, Score: -0.0281
  Top 2: Run 5, Batch 2, Score: -0.0315
  Top 3: Run 3, Batch 18, Score: -0.0324
  Top 4: Run 2, Batch 29, Score: -0.0324
  Top 5: Run 2, Batch 2, Score: -0.0338
  Top 6: Run 1, Batch 20, Score: -0.0340
  Top 7: Run 2, Batch 25, Score: -0.0346
  Top 8: Run 5, Batch 22, Score: -0.0346
  Top 9: Run 5, Batch 19, Score: -0.0347
  Top 10: Run 4, Batch 4, Score: -0.0348

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 13, Strategy 'Synth Only': Validation Acc: 20.00%
    Run 3, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 5, Batch 2, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 5, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 5, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 18, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 3, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 29, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 2, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 2, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 2, Batch 2, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 2, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 2, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 2, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 1, Batch 20, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 1, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 1, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 2, Batch 25, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 2, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 2, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 5, Batch 22, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 5, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 5, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 5, Batch 19, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 5, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 5, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 4, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 4 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 18, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0324
  - Strategy (Run 2, Batch 29, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0324
  - Strategy (Run 2, Batch 25, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0346
  - Strategy (Run 4, Batch 4, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0348

Selected best strategy: Run 3, Batch 18, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 80.00%) -> REAL test accuracy: 60.34%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 91.38%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H8_results/Subject_5-6_results/target_synthetic_data_S5-6.mat
Saved non-target class of best synthetic batch to H8_results/Subject_5-6_results/nontarget_synthetic_data_S5-6.mat
Saved target class of training data to H8_results/Subject_5-6_results/target_training_data_S5-6.mat
Saved non-target class of training data to H8_results/Subject_5-6_results/nontarget_training_data_S5-6.mat

Saved accuracy comparison plot to: H8_results/Subject_5-6_results/accuracy_comparison_S5-6.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 5-6) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H8_results/Subject_5-6_results/GA_ERP_Combined_S5-6_ChCz.png

--- Subject 5-6 processing finished successfully. ---
