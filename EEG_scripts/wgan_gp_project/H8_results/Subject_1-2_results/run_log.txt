Log for Subject Pair 1-2 from H8
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H8 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 266 clean Target and 531 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 572

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 37

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 72.97%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=67.3978, G Loss (Comb)=1.0118
Epoch 50/1000: D Loss=-1.7780, G Loss (Comb)=-1.9582
Epoch 100/1000: D Loss=-0.5026, G Loss (Comb)=-4.0630
Epoch 150/1000: D Loss=-0.6646, G Loss (Comb)=-4.4676
Epoch 200/1000: D Loss=-0.1921, G Loss (Comb)=-3.7974
Epoch 250/1000: D Loss=-0.2574, G Loss (Comb)=-4.3651
Epoch 300/1000: D Loss=-0.2178, G Loss (Comb)=-3.5558
Epoch 350/1000: D Loss=-0.5544, G Loss (Comb)=-3.4877
Epoch 400/1000: D Loss=-0.3471, G Loss (Comb)=-3.9380
Epoch 450/1000: D Loss=-0.4799, G Loss (Comb)=-4.0733
Epoch 500/1000: D Loss=-0.4174, G Loss (Comb)=-3.7696
Epoch 550/1000: D Loss=-0.5955, G Loss (Comb)=-3.6486
Epoch 600/1000: D Loss=-0.6149, G Loss (Comb)=-3.7690
Epoch 650/1000: D Loss=-0.6206, G Loss (Comb)=-3.3075
Epoch 700/1000: D Loss=-0.6989, G Loss (Comb)=-3.1431
Epoch 750/1000: D Loss=-0.7466, G Loss (Comb)=-2.8605
Epoch 800/1000: D Loss=-0.7741, G Loss (Comb)=-2.5318
Epoch 850/1000: D Loss=-0.7852, G Loss (Comb)=-2.6496
Epoch 900/1000: D Loss=-0.8638, G Loss (Comb)=-2.7508
Epoch 950/1000: D Loss=-0.8833, G Loss (Comb)=-2.5998
Epoch 999/1000: D Loss=-0.8603, G Loss (Comb)=-2.5764

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0516
    Run 1, Batch 2: ERP Similarity Score: -0.0407
    Run 1, Batch 3: ERP Similarity Score: -0.0386
    Run 1, Batch 4: ERP Similarity Score: -0.0384
    Run 1, Batch 5: ERP Similarity Score: -0.0438
    Run 1, Batch 6: ERP Similarity Score: -0.0419
    Run 1, Batch 7: ERP Similarity Score: -0.0382
    Run 1, Batch 8: ERP Similarity Score: -0.0456
    Run 1, Batch 9: ERP Similarity Score: -0.0418
    Run 1, Batch 10: ERP Similarity Score: -0.0407
    Run 1, Batch 11: ERP Similarity Score: -0.0445
    Run 1, Batch 12: ERP Similarity Score: -0.0383
    Run 1, Batch 13: ERP Similarity Score: -0.0430
    Run 1, Batch 14: ERP Similarity Score: -0.0526
    Run 1, Batch 15: ERP Similarity Score: -0.0382
    Run 1, Batch 16: ERP Similarity Score: -0.0401
    Run 1, Batch 17: ERP Similarity Score: -0.0414
    Run 1, Batch 18: ERP Similarity Score: -0.0399
    Run 1, Batch 19: ERP Similarity Score: -0.0378
    Run 1, Batch 20: ERP Similarity Score: -0.0420
    Run 1, Batch 21: ERP Similarity Score: -0.0359
    Run 1, Batch 22: ERP Similarity Score: -0.0382
    Run 1, Batch 23: ERP Similarity Score: -0.0498
    Run 1, Batch 24: ERP Similarity Score: -0.0380
    Run 1, Batch 25: ERP Similarity Score: -0.0377
    Run 1, Batch 26: ERP Similarity Score: -0.0408
    Run 1, Batch 27: ERP Similarity Score: -0.0449
    Run 1, Batch 28: ERP Similarity Score: -0.0377
    Run 1, Batch 29: ERP Similarity Score: -0.0343
    Run 1, Batch 30: ERP Similarity Score: -0.0421

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=65.3093, G Loss (Comb)=0.0501
Epoch 50/1000: D Loss=-2.1793, G Loss (Comb)=-2.6350
Epoch 100/1000: D Loss=-0.4439, G Loss (Comb)=-6.0350
Epoch 150/1000: D Loss=-0.4094, G Loss (Comb)=-6.0280
Epoch 200/1000: D Loss=-0.2328, G Loss (Comb)=-7.0761
Epoch 250/1000: D Loss=-0.4313, G Loss (Comb)=-5.8358
Epoch 300/1000: D Loss=-0.2421, G Loss (Comb)=-6.3984
Epoch 350/1000: D Loss=-0.3514, G Loss (Comb)=-6.7664
Epoch 400/1000: D Loss=-0.3748, G Loss (Comb)=-6.7206
Epoch 450/1000: D Loss=-0.2566, G Loss (Comb)=-6.2473
Epoch 500/1000: D Loss=-0.3228, G Loss (Comb)=-6.5228
Epoch 550/1000: D Loss=-0.3697, G Loss (Comb)=-6.6018
Epoch 600/1000: D Loss=-0.5419, G Loss (Comb)=-5.8669
Epoch 650/1000: D Loss=-0.5484, G Loss (Comb)=-5.6937
Epoch 700/1000: D Loss=-0.6253, G Loss (Comb)=-5.2361
Epoch 750/1000: D Loss=-0.6307, G Loss (Comb)=-4.7995
Epoch 800/1000: D Loss=-0.7761, G Loss (Comb)=-5.1543
Epoch 850/1000: D Loss=-0.6967, G Loss (Comb)=-5.0411
Epoch 900/1000: D Loss=-0.7040, G Loss (Comb)=-4.5810
Epoch 950/1000: D Loss=-0.8673, G Loss (Comb)=-4.6900
Epoch 999/1000: D Loss=-0.8446, G Loss (Comb)=-4.8724

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0504
    Run 2, Batch 2: ERP Similarity Score: -0.0395
    Run 2, Batch 3: ERP Similarity Score: -0.0365
    Run 2, Batch 4: ERP Similarity Score: -0.0427
    Run 2, Batch 5: ERP Similarity Score: -0.0467
    Run 2, Batch 6: ERP Similarity Score: -0.0427
    Run 2, Batch 7: ERP Similarity Score: -0.0472
    Run 2, Batch 8: ERP Similarity Score: -0.0377
    Run 2, Batch 9: ERP Similarity Score: -0.0459
    Run 2, Batch 10: ERP Similarity Score: -0.0428
    Run 2, Batch 11: ERP Similarity Score: -0.0423
    Run 2, Batch 12: ERP Similarity Score: -0.0412
    Run 2, Batch 13: ERP Similarity Score: -0.0423
    Run 2, Batch 14: ERP Similarity Score: -0.0345
    Run 2, Batch 15: ERP Similarity Score: -0.0312
    Run 2, Batch 16: ERP Similarity Score: -0.0480
    Run 2, Batch 17: ERP Similarity Score: -0.0493
    Run 2, Batch 18: ERP Similarity Score: -0.0356
    Run 2, Batch 19: ERP Similarity Score: -0.0421
    Run 2, Batch 20: ERP Similarity Score: -0.0420
    Run 2, Batch 21: ERP Similarity Score: -0.0414
    Run 2, Batch 22: ERP Similarity Score: -0.0490
    Run 2, Batch 23: ERP Similarity Score: -0.0440
    Run 2, Batch 24: ERP Similarity Score: -0.0382
    Run 2, Batch 25: ERP Similarity Score: -0.0327
    Run 2, Batch 26: ERP Similarity Score: -0.0410
    Run 2, Batch 27: ERP Similarity Score: -0.0485
    Run 2, Batch 28: ERP Similarity Score: -0.0381
    Run 2, Batch 29: ERP Similarity Score: -0.0425
    Run 2, Batch 30: ERP Similarity Score: -0.0414

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=65.0237, G Loss (Comb)=0.7693
Epoch 50/1000: D Loss=-1.9819, G Loss (Comb)=-0.9482
Epoch 100/1000: D Loss=-0.2793, G Loss (Comb)=-4.3930
Epoch 150/1000: D Loss=-0.2946, G Loss (Comb)=-4.5329
Epoch 200/1000: D Loss=-0.4017, G Loss (Comb)=-3.8643
Epoch 250/1000: D Loss=-0.2172, G Loss (Comb)=-5.0609
Epoch 300/1000: D Loss=-0.1830, G Loss (Comb)=-4.4660
Epoch 350/1000: D Loss=-0.3324, G Loss (Comb)=-4.9423
Epoch 400/1000: D Loss=-0.2227, G Loss (Comb)=-4.3848
Epoch 450/1000: D Loss=-0.2869, G Loss (Comb)=-4.7617
Epoch 500/1000: D Loss=-0.4833, G Loss (Comb)=-4.1914
Epoch 550/1000: D Loss=-0.3448, G Loss (Comb)=-4.2392
Epoch 600/1000: D Loss=-0.4878, G Loss (Comb)=-4.0041
Epoch 650/1000: D Loss=-0.5270, G Loss (Comb)=-3.8513
Epoch 700/1000: D Loss=-0.5306, G Loss (Comb)=-3.6582
Epoch 750/1000: D Loss=-0.6451, G Loss (Comb)=-3.7369
Epoch 800/1000: D Loss=-0.6355, G Loss (Comb)=-3.9868
Epoch 850/1000: D Loss=-0.7399, G Loss (Comb)=-4.0649
Epoch 900/1000: D Loss=-0.7541, G Loss (Comb)=-3.8747
Epoch 950/1000: D Loss=-0.8247, G Loss (Comb)=-3.8334
Epoch 999/1000: D Loss=-0.8393, G Loss (Comb)=-3.8121

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0418
    Run 3, Batch 2: ERP Similarity Score: -0.0407
    Run 3, Batch 3: ERP Similarity Score: -0.0439
    Run 3, Batch 4: ERP Similarity Score: -0.0340
    Run 3, Batch 5: ERP Similarity Score: -0.0433
    Run 3, Batch 6: ERP Similarity Score: -0.0427
    Run 3, Batch 7: ERP Similarity Score: -0.0418
    Run 3, Batch 8: ERP Similarity Score: -0.0417
    Run 3, Batch 9: ERP Similarity Score: -0.0413
    Run 3, Batch 10: ERP Similarity Score: -0.0491
    Run 3, Batch 11: ERP Similarity Score: -0.0421
    Run 3, Batch 12: ERP Similarity Score: -0.0460
    Run 3, Batch 13: ERP Similarity Score: -0.0390
    Run 3, Batch 14: ERP Similarity Score: -0.0328
    Run 3, Batch 15: ERP Similarity Score: -0.0335
    Run 3, Batch 16: ERP Similarity Score: -0.0456
    Run 3, Batch 17: ERP Similarity Score: -0.0479
    Run 3, Batch 18: ERP Similarity Score: -0.0466
    Run 3, Batch 19: ERP Similarity Score: -0.0437
    Run 3, Batch 20: ERP Similarity Score: -0.0415
    Run 3, Batch 21: ERP Similarity Score: -0.0433
    Run 3, Batch 22: ERP Similarity Score: -0.0440
    Run 3, Batch 23: ERP Similarity Score: -0.0521
    Run 3, Batch 24: ERP Similarity Score: -0.0485
    Run 3, Batch 25: ERP Similarity Score: -0.0394
    Run 3, Batch 26: ERP Similarity Score: -0.0434
    Run 3, Batch 27: ERP Similarity Score: -0.0350
    Run 3, Batch 28: ERP Similarity Score: -0.0391
    Run 3, Batch 29: ERP Similarity Score: -0.0369
    Run 3, Batch 30: ERP Similarity Score: -0.0392

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=62.4020, G Loss (Comb)=1.0325
Epoch 50/1000: D Loss=-1.6688, G Loss (Comb)=-1.5293
Epoch 100/1000: D Loss=-0.5608, G Loss (Comb)=-4.7981
Epoch 150/1000: D Loss=-0.2853, G Loss (Comb)=-4.7239
Epoch 200/1000: D Loss=-0.3444, G Loss (Comb)=-4.6978
Epoch 250/1000: D Loss=-0.3060, G Loss (Comb)=-4.1723
Epoch 300/1000: D Loss=-0.2197, G Loss (Comb)=-4.3617
Epoch 350/1000: D Loss=-0.3232, G Loss (Comb)=-5.4172
Epoch 400/1000: D Loss=-0.4327, G Loss (Comb)=-5.0194
Epoch 450/1000: D Loss=-0.4179, G Loss (Comb)=-4.6996
Epoch 500/1000: D Loss=-0.5038, G Loss (Comb)=-4.6608
Epoch 550/1000: D Loss=-0.4674, G Loss (Comb)=-4.7041
Epoch 600/1000: D Loss=-0.6066, G Loss (Comb)=-4.3578
Epoch 650/1000: D Loss=-0.5671, G Loss (Comb)=-4.3094
Epoch 700/1000: D Loss=-0.6550, G Loss (Comb)=-3.7633
Epoch 750/1000: D Loss=-0.7448, G Loss (Comb)=-3.5925
Epoch 800/1000: D Loss=-0.7678, G Loss (Comb)=-3.8248
Epoch 850/1000: D Loss=-0.8115, G Loss (Comb)=-3.6107
Epoch 900/1000: D Loss=-0.7471, G Loss (Comb)=-3.8168
Epoch 950/1000: D Loss=-0.8967, G Loss (Comb)=-3.7676
Epoch 999/1000: D Loss=-0.8815, G Loss (Comb)=-3.7840

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0410
    Run 4, Batch 2: ERP Similarity Score: -0.0391
    Run 4, Batch 3: ERP Similarity Score: -0.0404
    Run 4, Batch 4: ERP Similarity Score: -0.0380
    Run 4, Batch 5: ERP Similarity Score: -0.0423
    Run 4, Batch 6: ERP Similarity Score: -0.0341
    Run 4, Batch 7: ERP Similarity Score: -0.0477
    Run 4, Batch 8: ERP Similarity Score: -0.0517
    Run 4, Batch 9: ERP Similarity Score: -0.0441
    Run 4, Batch 10: ERP Similarity Score: -0.0339
    Run 4, Batch 11: ERP Similarity Score: -0.0396
    Run 4, Batch 12: ERP Similarity Score: -0.0456
    Run 4, Batch 13: ERP Similarity Score: -0.0432
    Run 4, Batch 14: ERP Similarity Score: -0.0354
    Run 4, Batch 15: ERP Similarity Score: -0.0371
    Run 4, Batch 16: ERP Similarity Score: -0.0371
    Run 4, Batch 17: ERP Similarity Score: -0.0410
    Run 4, Batch 18: ERP Similarity Score: -0.0381
    Run 4, Batch 19: ERP Similarity Score: -0.0461
    Run 4, Batch 20: ERP Similarity Score: -0.0448
    Run 4, Batch 21: ERP Similarity Score: -0.0486
    Run 4, Batch 22: ERP Similarity Score: -0.0470
    Run 4, Batch 23: ERP Similarity Score: -0.0493
    Run 4, Batch 24: ERP Similarity Score: -0.0414
    Run 4, Batch 25: ERP Similarity Score: -0.0494
    Run 4, Batch 26: ERP Similarity Score: -0.0405
    Run 4, Batch 27: ERP Similarity Score: -0.0442
    Run 4, Batch 28: ERP Similarity Score: -0.0436
    Run 4, Batch 29: ERP Similarity Score: -0.0496
    Run 4, Batch 30: ERP Similarity Score: -0.0448

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=61.4665, G Loss (Comb)=0.6172
Epoch 50/1000: D Loss=-1.5936, G Loss (Comb)=-1.4737
Epoch 100/1000: D Loss=-0.4714, G Loss (Comb)=-4.1577
Epoch 150/1000: D Loss=-0.3993, G Loss (Comb)=-3.9648
Epoch 200/1000: D Loss=-0.2084, G Loss (Comb)=-5.1972
Epoch 250/1000: D Loss=-0.2389, G Loss (Comb)=-5.1724
Epoch 300/1000: D Loss=-0.4144, G Loss (Comb)=-5.3502
Epoch 350/1000: D Loss=-0.3025, G Loss (Comb)=-5.3872
Epoch 400/1000: D Loss=-0.3561, G Loss (Comb)=-4.8531
Epoch 450/1000: D Loss=-0.3996, G Loss (Comb)=-5.2331
Epoch 500/1000: D Loss=-0.4855, G Loss (Comb)=-4.5469
Epoch 550/1000: D Loss=-0.6328, G Loss (Comb)=-4.5435
Epoch 600/1000: D Loss=-0.5897, G Loss (Comb)=-4.4797
Epoch 650/1000: D Loss=-0.5209, G Loss (Comb)=-4.0904
Epoch 700/1000: D Loss=-0.6493, G Loss (Comb)=-4.1699
Epoch 750/1000: D Loss=-0.6551, G Loss (Comb)=-4.0984
Epoch 800/1000: D Loss=-0.7249, G Loss (Comb)=-4.0375
Epoch 850/1000: D Loss=-0.7576, G Loss (Comb)=-3.9264
Epoch 900/1000: D Loss=-0.8326, G Loss (Comb)=-3.8681
Epoch 950/1000: D Loss=-0.7912, G Loss (Comb)=-4.0788
Epoch 999/1000: D Loss=-0.8182, G Loss (Comb)=-4.1082

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0305
    Run 5, Batch 2: ERP Similarity Score: -0.0462
    Run 5, Batch 3: ERP Similarity Score: -0.0402
    Run 5, Batch 4: ERP Similarity Score: -0.0386
    Run 5, Batch 5: ERP Similarity Score: -0.0384
    Run 5, Batch 6: ERP Similarity Score: -0.0414
    Run 5, Batch 7: ERP Similarity Score: -0.0397
    Run 5, Batch 8: ERP Similarity Score: -0.0333
    Run 5, Batch 9: ERP Similarity Score: -0.0398
    Run 5, Batch 10: ERP Similarity Score: -0.0356
    Run 5, Batch 11: ERP Similarity Score: -0.0384
    Run 5, Batch 12: ERP Similarity Score: -0.0398
    Run 5, Batch 13: ERP Similarity Score: -0.0526
    Run 5, Batch 14: ERP Similarity Score: -0.0357
    Run 5, Batch 15: ERP Similarity Score: -0.0384
    Run 5, Batch 16: ERP Similarity Score: -0.0448
    Run 5, Batch 17: ERP Similarity Score: -0.0426
    Run 5, Batch 18: ERP Similarity Score: -0.0360
    Run 5, Batch 19: ERP Similarity Score: -0.0429
    Run 5, Batch 20: ERP Similarity Score: -0.0325
    Run 5, Batch 21: ERP Similarity Score: -0.0395
    Run 5, Batch 22: ERP Similarity Score: -0.0461
    Run 5, Batch 23: ERP Similarity Score: -0.0512
    Run 5, Batch 24: ERP Similarity Score: -0.0362
    Run 5, Batch 25: ERP Similarity Score: -0.0334
    Run 5, Batch 26: ERP Similarity Score: -0.0377
    Run 5, Batch 27: ERP Similarity Score: -0.0408
    Run 5, Batch 28: ERP Similarity Score: -0.0412
    Run 5, Batch 29: ERP Similarity Score: -0.0419
    Run 5, Batch 30: ERP Similarity Score: -0.0353


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 5, Batch 1, Score: -0.0305
  Top 2: Run 2, Batch 15, Score: -0.0312
  Top 3: Run 5, Batch 20, Score: -0.0325
  Top 4: Run 2, Batch 25, Score: -0.0327
  Top 5: Run 3, Batch 14, Score: -0.0328
  Top 6: Run 5, Batch 8, Score: -0.0333
  Top 7: Run 5, Batch 25, Score: -0.0334
  Top 8: Run 3, Batch 15, Score: -0.0335
  Top 9: Run 4, Batch 10, Score: -0.0339
  Top 10: Run 3, Batch 4, Score: -0.0340

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 5, Batch 1, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 15, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 20, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 5, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 0.00%
    Run 3, Batch 14, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 8, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 25, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 15, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 10, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 4, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 5 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 5, Batch 1, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0305
  - Strategy (Run 2, Batch 15, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0312
  - Strategy (Run 5, Batch 20, Ratio 0): Accuracy=100.00, ERP Score=-0.0325
  - Strategy (Run 5, Batch 25, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0334
  - Strategy (Run 3, Batch 4, Ratio 0): Accuracy=100.00, ERP Score=-0.0340

Selected best strategy: Run 5, Batch 1, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 56.76%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 70.27%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H8_results/Subject_1-2_results/target_synthetic_data_S1-2.mat
Saved non-target class of best synthetic batch to H8_results/Subject_1-2_results/nontarget_synthetic_data_S1-2.mat
Saved target class of training data to H8_results/Subject_1-2_results/target_training_data_S1-2.mat
Saved non-target class of training data to H8_results/Subject_1-2_results/nontarget_training_data_S1-2.mat

Saved accuracy comparison plot to: H8_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H8_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
