Log for Subject Pair 3-4 from H12
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H12 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 246 clean Target and 506 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 527

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 34

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 79.41%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=48.9404, G Loss (Comb)=1.5982
Epoch 50/1000: D Loss=-1.3323, G Loss (Comb)=-0.7298
Epoch 100/1000: D Loss=-0.5202, G Loss (Comb)=-3.4040
Epoch 150/1000: D Loss=-0.4528, G Loss (Comb)=-2.9438
Epoch 200/1000: D Loss=-0.3302, G Loss (Comb)=-2.7600
Epoch 250/1000: D Loss=-0.4565, G Loss (Comb)=-2.8160
Epoch 300/1000: D Loss=-0.4483, G Loss (Comb)=-2.4970
Epoch 350/1000: D Loss=-0.3859, G Loss (Comb)=-2.5635
Epoch 400/1000: D Loss=-0.4920, G Loss (Comb)=-1.6782
Epoch 450/1000: D Loss=-0.4087, G Loss (Comb)=-1.6984
Epoch 500/1000: D Loss=-0.5486, G Loss (Comb)=-1.3911
Epoch 550/1000: D Loss=-0.6812, G Loss (Comb)=-0.9233
Epoch 600/1000: D Loss=-0.6266, G Loss (Comb)=-1.2120
Epoch 650/1000: D Loss=-0.6541, G Loss (Comb)=-1.3678
Epoch 700/1000: D Loss=-0.8090, G Loss (Comb)=-1.2813
Epoch 750/1000: D Loss=-0.8632, G Loss (Comb)=-1.2204
Epoch 800/1000: D Loss=-0.8312, G Loss (Comb)=-1.4265
Epoch 850/1000: D Loss=-0.9066, G Loss (Comb)=-1.3229
Epoch 900/1000: D Loss=-0.9299, G Loss (Comb)=-1.3345
Epoch 950/1000: D Loss=-0.9588, G Loss (Comb)=-1.2689
Epoch 999/1000: D Loss=-1.0839, G Loss (Comb)=-1.3129

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0424
    Run 1, Batch 2: ERP Similarity Score: -0.0382
    Run 1, Batch 3: ERP Similarity Score: -0.0340
    Run 1, Batch 4: ERP Similarity Score: -0.0519
    Run 1, Batch 5: ERP Similarity Score: -0.0488
    Run 1, Batch 6: ERP Similarity Score: -0.0293
    Run 1, Batch 7: ERP Similarity Score: -0.0494
    Run 1, Batch 8: ERP Similarity Score: -0.0479
    Run 1, Batch 9: ERP Similarity Score: -0.0379
    Run 1, Batch 10: ERP Similarity Score: -0.0469
    Run 1, Batch 11: ERP Similarity Score: -0.0393
    Run 1, Batch 12: ERP Similarity Score: -0.0506
    Run 1, Batch 13: ERP Similarity Score: -0.0435
    Run 1, Batch 14: ERP Similarity Score: -0.0445
    Run 1, Batch 15: ERP Similarity Score: -0.0399
    Run 1, Batch 16: ERP Similarity Score: -0.0482
    Run 1, Batch 17: ERP Similarity Score: -0.0387
    Run 1, Batch 18: ERP Similarity Score: -0.0366
    Run 1, Batch 19: ERP Similarity Score: -0.0316
    Run 1, Batch 20: ERP Similarity Score: -0.0419
    Run 1, Batch 21: ERP Similarity Score: -0.0466
    Run 1, Batch 22: ERP Similarity Score: -0.0367
    Run 1, Batch 23: ERP Similarity Score: -0.0338
    Run 1, Batch 24: ERP Similarity Score: -0.0387
    Run 1, Batch 25: ERP Similarity Score: -0.0481
    Run 1, Batch 26: ERP Similarity Score: -0.0395
    Run 1, Batch 27: ERP Similarity Score: -0.0410
    Run 1, Batch 28: ERP Similarity Score: -0.0486
    Run 1, Batch 29: ERP Similarity Score: -0.0478
    Run 1, Batch 30: ERP Similarity Score: -0.0360

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=67.5178, G Loss (Comb)=1.1764
Epoch 50/1000: D Loss=-1.2545, G Loss (Comb)=-0.4755
Epoch 100/1000: D Loss=-0.5434, G Loss (Comb)=-3.5858
Epoch 150/1000: D Loss=-0.4991, G Loss (Comb)=-3.1970
Epoch 200/1000: D Loss=-0.3614, G Loss (Comb)=-3.1005
Epoch 250/1000: D Loss=-0.4187, G Loss (Comb)=-3.0015
Epoch 300/1000: D Loss=-0.4593, G Loss (Comb)=-2.8837
Epoch 350/1000: D Loss=-0.5778, G Loss (Comb)=-2.8592
Epoch 400/1000: D Loss=-0.5589, G Loss (Comb)=-2.5685
Epoch 450/1000: D Loss=-0.4671, G Loss (Comb)=-2.4186
Epoch 500/1000: D Loss=-0.6122, G Loss (Comb)=-2.1864
Epoch 550/1000: D Loss=-0.5462, G Loss (Comb)=-1.7855
Epoch 600/1000: D Loss=-0.6695, G Loss (Comb)=-1.8571
Epoch 650/1000: D Loss=-0.7539, G Loss (Comb)=-1.7793
Epoch 700/1000: D Loss=-0.6185, G Loss (Comb)=-1.6583
Epoch 750/1000: D Loss=-0.7270, G Loss (Comb)=-1.7285
Epoch 800/1000: D Loss=-0.7823, G Loss (Comb)=-1.5273
Epoch 850/1000: D Loss=-0.7509, G Loss (Comb)=-1.5410
Epoch 900/1000: D Loss=-0.8095, G Loss (Comb)=-1.7018
Epoch 950/1000: D Loss=-0.8448, G Loss (Comb)=-1.8333
Epoch 999/1000: D Loss=-0.8839, G Loss (Comb)=-1.8570

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0355
    Run 2, Batch 2: ERP Similarity Score: -0.0380
    Run 2, Batch 3: ERP Similarity Score: -0.0391
    Run 2, Batch 4: ERP Similarity Score: -0.0371
    Run 2, Batch 5: ERP Similarity Score: -0.0416
    Run 2, Batch 6: ERP Similarity Score: -0.0369
    Run 2, Batch 7: ERP Similarity Score: -0.0374
    Run 2, Batch 8: ERP Similarity Score: -0.0375
    Run 2, Batch 9: ERP Similarity Score: -0.0324
    Run 2, Batch 10: ERP Similarity Score: -0.0328
    Run 2, Batch 11: ERP Similarity Score: -0.0350
    Run 2, Batch 12: ERP Similarity Score: -0.0350
    Run 2, Batch 13: ERP Similarity Score: -0.0356
    Run 2, Batch 14: ERP Similarity Score: -0.0332
    Run 2, Batch 15: ERP Similarity Score: -0.0490
    Run 2, Batch 16: ERP Similarity Score: -0.0371
    Run 2, Batch 17: ERP Similarity Score: -0.0408
    Run 2, Batch 18: ERP Similarity Score: -0.0591
    Run 2, Batch 19: ERP Similarity Score: -0.0342
    Run 2, Batch 20: ERP Similarity Score: -0.0448
    Run 2, Batch 21: ERP Similarity Score: -0.0371
    Run 2, Batch 22: ERP Similarity Score: -0.0351
    Run 2, Batch 23: ERP Similarity Score: -0.0360
    Run 2, Batch 24: ERP Similarity Score: -0.0393
    Run 2, Batch 25: ERP Similarity Score: -0.0325
    Run 2, Batch 26: ERP Similarity Score: -0.0369
    Run 2, Batch 27: ERP Similarity Score: -0.0414
    Run 2, Batch 28: ERP Similarity Score: -0.0420
    Run 2, Batch 29: ERP Similarity Score: -0.0353
    Run 2, Batch 30: ERP Similarity Score: -0.0372

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=47.2889, G Loss (Comb)=1.5357
Epoch 50/1000: D Loss=-1.4847, G Loss (Comb)=-0.3490
Epoch 100/1000: D Loss=-0.4429, G Loss (Comb)=-3.0766
Epoch 150/1000: D Loss=-0.5104, G Loss (Comb)=-2.5039
Epoch 200/1000: D Loss=-0.3390, G Loss (Comb)=-2.3396
Epoch 250/1000: D Loss=-0.5297, G Loss (Comb)=-2.4785
Epoch 300/1000: D Loss=-0.2845, G Loss (Comb)=-2.2218
Epoch 350/1000: D Loss=-0.5170, G Loss (Comb)=-1.5347
Epoch 400/1000: D Loss=-0.4599, G Loss (Comb)=-1.5451
Epoch 450/1000: D Loss=-0.4626, G Loss (Comb)=-1.1078
Epoch 500/1000: D Loss=-0.6156, G Loss (Comb)=-0.7741
Epoch 550/1000: D Loss=-0.5703, G Loss (Comb)=-0.9962
Epoch 600/1000: D Loss=-0.6310, G Loss (Comb)=-0.9982
Epoch 650/1000: D Loss=-0.7404, G Loss (Comb)=-1.1453
Epoch 700/1000: D Loss=-0.7985, G Loss (Comb)=-0.9241
Epoch 750/1000: D Loss=-0.8323, G Loss (Comb)=-1.0507
Epoch 800/1000: D Loss=-0.8659, G Loss (Comb)=-1.1666
Epoch 850/1000: D Loss=-0.8827, G Loss (Comb)=-1.1439
Epoch 900/1000: D Loss=-0.8993, G Loss (Comb)=-1.0966
Epoch 950/1000: D Loss=-0.9942, G Loss (Comb)=-0.9193
Epoch 999/1000: D Loss=-0.9625, G Loss (Comb)=-1.2682

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0435
    Run 3, Batch 2: ERP Similarity Score: -0.0407
    Run 3, Batch 3: ERP Similarity Score: -0.0437
    Run 3, Batch 4: ERP Similarity Score: -0.0304
    Run 3, Batch 5: ERP Similarity Score: -0.0344
    Run 3, Batch 6: ERP Similarity Score: -0.0496
    Run 3, Batch 7: ERP Similarity Score: -0.0373
    Run 3, Batch 8: ERP Similarity Score: -0.0319
    Run 3, Batch 9: ERP Similarity Score: -0.0393
    Run 3, Batch 10: ERP Similarity Score: -0.0305
    Run 3, Batch 11: ERP Similarity Score: -0.0280
    Run 3, Batch 12: ERP Similarity Score: -0.0390
    Run 3, Batch 13: ERP Similarity Score: -0.0321
    Run 3, Batch 14: ERP Similarity Score: -0.0360
    Run 3, Batch 15: ERP Similarity Score: -0.0393
    Run 3, Batch 16: ERP Similarity Score: -0.0313
    Run 3, Batch 17: ERP Similarity Score: -0.0411
    Run 3, Batch 18: ERP Similarity Score: -0.0425
    Run 3, Batch 19: ERP Similarity Score: -0.0313
    Run 3, Batch 20: ERP Similarity Score: -0.0379
    Run 3, Batch 21: ERP Similarity Score: -0.0374
    Run 3, Batch 22: ERP Similarity Score: -0.0456
    Run 3, Batch 23: ERP Similarity Score: -0.0367
    Run 3, Batch 24: ERP Similarity Score: -0.0348
    Run 3, Batch 25: ERP Similarity Score: -0.0383
    Run 3, Batch 26: ERP Similarity Score: -0.0326
    Run 3, Batch 27: ERP Similarity Score: -0.0374
    Run 3, Batch 28: ERP Similarity Score: -0.0334
    Run 3, Batch 29: ERP Similarity Score: -0.0403
    Run 3, Batch 30: ERP Similarity Score: -0.0318

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=57.6467, G Loss (Comb)=0.0833
Epoch 50/1000: D Loss=-1.4988, G Loss (Comb)=-0.9177
Epoch 100/1000: D Loss=-0.5571, G Loss (Comb)=-2.9956
Epoch 150/1000: D Loss=-0.4989, G Loss (Comb)=-2.4036
Epoch 200/1000: D Loss=-0.3777, G Loss (Comb)=-2.7821
Epoch 250/1000: D Loss=-0.5417, G Loss (Comb)=-2.2380
Epoch 300/1000: D Loss=-0.4140, G Loss (Comb)=-2.4655
Epoch 350/1000: D Loss=-0.3513, G Loss (Comb)=-2.6127
Epoch 400/1000: D Loss=-0.5907, G Loss (Comb)=-2.1415
Epoch 450/1000: D Loss=-0.5064, G Loss (Comb)=-2.1322
Epoch 500/1000: D Loss=-0.6411, G Loss (Comb)=-1.1186
Epoch 550/1000: D Loss=-0.6169, G Loss (Comb)=-1.4058
Epoch 600/1000: D Loss=-0.6956, G Loss (Comb)=-1.4045
Epoch 650/1000: D Loss=-0.6780, G Loss (Comb)=-1.3137
Epoch 700/1000: D Loss=-0.7004, G Loss (Comb)=-1.4609
Epoch 750/1000: D Loss=-0.8028, G Loss (Comb)=-1.7196
Epoch 800/1000: D Loss=-0.8015, G Loss (Comb)=-1.4893
Epoch 850/1000: D Loss=-0.7817, G Loss (Comb)=-1.5732
Epoch 900/1000: D Loss=-0.8237, G Loss (Comb)=-1.4876
Epoch 950/1000: D Loss=-0.8990, G Loss (Comb)=-1.7001
Epoch 999/1000: D Loss=-0.9756, G Loss (Comb)=-1.7430

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0342
    Run 4, Batch 2: ERP Similarity Score: -0.0381
    Run 4, Batch 3: ERP Similarity Score: -0.0357
    Run 4, Batch 4: ERP Similarity Score: -0.0371
    Run 4, Batch 5: ERP Similarity Score: -0.0417
    Run 4, Batch 6: ERP Similarity Score: -0.0424
    Run 4, Batch 7: ERP Similarity Score: -0.0345
    Run 4, Batch 8: ERP Similarity Score: -0.0393
    Run 4, Batch 9: ERP Similarity Score: -0.0356
    Run 4, Batch 10: ERP Similarity Score: -0.0326
    Run 4, Batch 11: ERP Similarity Score: -0.0393
    Run 4, Batch 12: ERP Similarity Score: -0.0380
    Run 4, Batch 13: ERP Similarity Score: -0.0420
    Run 4, Batch 14: ERP Similarity Score: -0.0412
    Run 4, Batch 15: ERP Similarity Score: -0.0375
    Run 4, Batch 16: ERP Similarity Score: -0.0350
    Run 4, Batch 17: ERP Similarity Score: -0.0373
    Run 4, Batch 18: ERP Similarity Score: -0.0380
    Run 4, Batch 19: ERP Similarity Score: -0.0413
    Run 4, Batch 20: ERP Similarity Score: -0.0405
    Run 4, Batch 21: ERP Similarity Score: -0.0445
    Run 4, Batch 22: ERP Similarity Score: -0.0373
    Run 4, Batch 23: ERP Similarity Score: -0.0372
    Run 4, Batch 24: ERP Similarity Score: -0.0385
    Run 4, Batch 25: ERP Similarity Score: -0.0389
    Run 4, Batch 26: ERP Similarity Score: -0.0372
    Run 4, Batch 27: ERP Similarity Score: -0.0375
    Run 4, Batch 28: ERP Similarity Score: -0.0372
    Run 4, Batch 29: ERP Similarity Score: -0.0451
    Run 4, Batch 30: ERP Similarity Score: -0.0333

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=51.2700, G Loss (Comb)=1.2463
Epoch 50/1000: D Loss=-1.1769, G Loss (Comb)=-0.7118
Epoch 100/1000: D Loss=-0.4196, G Loss (Comb)=-3.2132
Epoch 150/1000: D Loss=-0.4784, G Loss (Comb)=-2.8052
Epoch 200/1000: D Loss=-0.3670, G Loss (Comb)=-3.1860
Epoch 250/1000: D Loss=-0.4021, G Loss (Comb)=-2.7073
Epoch 300/1000: D Loss=-0.5276, G Loss (Comb)=-2.5379
Epoch 350/1000: D Loss=-0.5690, G Loss (Comb)=-1.9343
Epoch 400/1000: D Loss=-0.5866, G Loss (Comb)=-1.5874
Epoch 450/1000: D Loss=-0.6129, G Loss (Comb)=-0.9200
Epoch 500/1000: D Loss=-0.5711, G Loss (Comb)=-1.3173
Epoch 550/1000: D Loss=-0.6346, G Loss (Comb)=-1.2367
Epoch 600/1000: D Loss=-0.6990, G Loss (Comb)=-1.0278
Epoch 650/1000: D Loss=-0.7132, G Loss (Comb)=-1.0543
Epoch 700/1000: D Loss=-0.7597, G Loss (Comb)=-1.4078
Epoch 750/1000: D Loss=-0.8878, G Loss (Comb)=-1.4532
Epoch 800/1000: D Loss=-0.8896, G Loss (Comb)=-1.5511
Epoch 850/1000: D Loss=-0.8954, G Loss (Comb)=-1.5135
Epoch 900/1000: D Loss=-0.9147, G Loss (Comb)=-1.7592
Epoch 950/1000: D Loss=-1.0044, G Loss (Comb)=-1.9435
Epoch 999/1000: D Loss=-1.0883, G Loss (Comb)=-1.7269

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0388
    Run 5, Batch 2: ERP Similarity Score: -0.0353
    Run 5, Batch 3: ERP Similarity Score: -0.0457
    Run 5, Batch 4: ERP Similarity Score: -0.0461
    Run 5, Batch 5: ERP Similarity Score: -0.0354
    Run 5, Batch 6: ERP Similarity Score: -0.0369
    Run 5, Batch 7: ERP Similarity Score: -0.0331
    Run 5, Batch 8: ERP Similarity Score: -0.0442
    Run 5, Batch 9: ERP Similarity Score: -0.0463
    Run 5, Batch 10: ERP Similarity Score: -0.0351
    Run 5, Batch 11: ERP Similarity Score: -0.0365
    Run 5, Batch 12: ERP Similarity Score: -0.0444
    Run 5, Batch 13: ERP Similarity Score: -0.0338
    Run 5, Batch 14: ERP Similarity Score: -0.0375
    Run 5, Batch 15: ERP Similarity Score: -0.0386
    Run 5, Batch 16: ERP Similarity Score: -0.0383
    Run 5, Batch 17: ERP Similarity Score: -0.0511
    Run 5, Batch 18: ERP Similarity Score: -0.0509
    Run 5, Batch 19: ERP Similarity Score: -0.0393
    Run 5, Batch 20: ERP Similarity Score: -0.0388
    Run 5, Batch 21: ERP Similarity Score: -0.0392
    Run 5, Batch 22: ERP Similarity Score: -0.0375
    Run 5, Batch 23: ERP Similarity Score: -0.0436
    Run 5, Batch 24: ERP Similarity Score: -0.0361
    Run 5, Batch 25: ERP Similarity Score: -0.0443
    Run 5, Batch 26: ERP Similarity Score: -0.0459
    Run 5, Batch 27: ERP Similarity Score: -0.0380
    Run 5, Batch 28: ERP Similarity Score: -0.0465
    Run 5, Batch 29: ERP Similarity Score: -0.0399
    Run 5, Batch 30: ERP Similarity Score: -0.0402


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 11, Score: -0.0280
  Top 2: Run 1, Batch 6, Score: -0.0293
  Top 3: Run 3, Batch 4, Score: -0.0304
  Top 4: Run 3, Batch 10, Score: -0.0305
  Top 5: Run 3, Batch 19, Score: -0.0313
  Top 6: Run 3, Batch 16, Score: -0.0313
  Top 7: Run 1, Batch 19, Score: -0.0316
  Top 8: Run 3, Batch 30, Score: -0.0318
  Top 9: Run 3, Batch 8, Score: -0.0319
  Top 10: Run 3, Batch 13, Score: -0.0321

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 11, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 6, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 4, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 10, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 16, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 19, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 30, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 8, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 13, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 13 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0280
  - Strategy (Run 3, Batch 11, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0280
  - Strategy (Run 1, Batch 6, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0293
  - Strategy (Run 1, Batch 6, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0293
  - Strategy (Run 1, Batch 6, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0293
  - Strategy (Run 3, Batch 4, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0304
  - Strategy (Run 3, Batch 4, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0304
  - Strategy (Run 1, Batch 19, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0316
  - Strategy (Run 1, Batch 19, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0316
  - Strategy (Run 1, Batch 19, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0316
  - Strategy (Run 3, Batch 30, Ratio 0): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 3, Batch 30, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 3, Batch 30, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0318

Selected best strategy: Run 3, Batch 11, Strategy: Augmented (50%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 79.41%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (50%), Val Acc: 100.00%) -> REAL test accuracy: 61.76%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H12_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H12_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
