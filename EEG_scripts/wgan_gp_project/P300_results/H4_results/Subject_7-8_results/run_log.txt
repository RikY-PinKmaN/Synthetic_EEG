Log for Subject Pair 7-8 from H4
========================================


========================= PROCESSING SUBJECT PAIR: 7-8 from H4 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 269 clean Target and 1079 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 973

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 63

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 84.13%

--- Training cWGAN-GP for Subject 7-8, Run 1 ---
Epoch 0/1000: D Loss=69.5449, G Loss (Comb)=2.2035
Epoch 50/1000: D Loss=-0.3466, G Loss (Comb)=-2.1775
Epoch 100/1000: D Loss=-0.2317, G Loss (Comb)=-1.7425
Epoch 150/1000: D Loss=-0.2315, G Loss (Comb)=-1.5426
Epoch 200/1000: D Loss=-0.1131, G Loss (Comb)=-1.4411
Epoch 250/1000: D Loss=-0.2735, G Loss (Comb)=-1.6731
Epoch 300/1000: D Loss=-0.1440, G Loss (Comb)=-1.6412
Epoch 350/1000: D Loss=-0.1909, G Loss (Comb)=-1.5377
Epoch 400/1000: D Loss=-0.2379, G Loss (Comb)=-1.6240
Epoch 450/1000: D Loss=-0.3036, G Loss (Comb)=-1.5713
Epoch 500/1000: D Loss=-0.2981, G Loss (Comb)=-1.6947
Epoch 550/1000: D Loss=-0.4508, G Loss (Comb)=-1.8892
Epoch 600/1000: D Loss=-0.4317, G Loss (Comb)=-2.1760
Epoch 650/1000: D Loss=-0.4784, G Loss (Comb)=-2.1194
Epoch 700/1000: D Loss=-0.5843, G Loss (Comb)=-2.3358
Epoch 750/1000: D Loss=-0.5609, G Loss (Comb)=-2.4850
Epoch 800/1000: D Loss=-0.6405, G Loss (Comb)=-2.4474
Epoch 850/1000: D Loss=-0.6914, G Loss (Comb)=-2.6075
Epoch 900/1000: D Loss=-0.7690, G Loss (Comb)=-2.7305
Epoch 950/1000: D Loss=-0.7641, G Loss (Comb)=-2.8149
Epoch 999/1000: D Loss=-0.8283, G Loss (Comb)=-2.9481

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0599
    Run 1, Batch 2: ERP Similarity Score: -0.0592
    Run 1, Batch 3: ERP Similarity Score: -0.0467
    Run 1, Batch 4: ERP Similarity Score: -0.0560
    Run 1, Batch 5: ERP Similarity Score: -0.0490
    Run 1, Batch 6: ERP Similarity Score: -0.0513
    Run 1, Batch 7: ERP Similarity Score: -0.0440
    Run 1, Batch 8: ERP Similarity Score: -0.0519
    Run 1, Batch 9: ERP Similarity Score: -0.0451
    Run 1, Batch 10: ERP Similarity Score: -0.0509
    Run 1, Batch 11: ERP Similarity Score: -0.0545
    Run 1, Batch 12: ERP Similarity Score: -0.0543
    Run 1, Batch 13: ERP Similarity Score: -0.0465
    Run 1, Batch 14: ERP Similarity Score: -0.0443
    Run 1, Batch 15: ERP Similarity Score: -0.0472
    Run 1, Batch 16: ERP Similarity Score: -0.0491
    Run 1, Batch 17: ERP Similarity Score: -0.0536
    Run 1, Batch 18: ERP Similarity Score: -0.0534
    Run 1, Batch 19: ERP Similarity Score: -0.0501
    Run 1, Batch 20: ERP Similarity Score: -0.0510
    Run 1, Batch 21: ERP Similarity Score: -0.0449
    Run 1, Batch 22: ERP Similarity Score: -0.0477
    Run 1, Batch 23: ERP Similarity Score: -0.0475
    Run 1, Batch 24: ERP Similarity Score: -0.0388
    Run 1, Batch 25: ERP Similarity Score: -0.0457
    Run 1, Batch 26: ERP Similarity Score: -0.0572
    Run 1, Batch 27: ERP Similarity Score: -0.0533
    Run 1, Batch 28: ERP Similarity Score: -0.0355
    Run 1, Batch 29: ERP Similarity Score: -0.0573
    Run 1, Batch 30: ERP Similarity Score: -0.0493

--- Training cWGAN-GP for Subject 7-8, Run 2 ---
Epoch 0/1000: D Loss=89.2374, G Loss (Comb)=1.6605
Epoch 50/1000: D Loss=-0.4622, G Loss (Comb)=-2.3650
Epoch 100/1000: D Loss=-0.2752, G Loss (Comb)=-2.5188
Epoch 150/1000: D Loss=-0.1549, G Loss (Comb)=-2.7987
Epoch 200/1000: D Loss=-0.0361, G Loss (Comb)=-2.7596
Epoch 250/1000: D Loss=-0.1447, G Loss (Comb)=-2.6052
Epoch 300/1000: D Loss=-0.2961, G Loss (Comb)=-2.3836
Epoch 350/1000: D Loss=-0.1791, G Loss (Comb)=-2.4198
Epoch 400/1000: D Loss=-0.2896, G Loss (Comb)=-2.4320
Epoch 450/1000: D Loss=-0.3423, G Loss (Comb)=-2.5386
Epoch 500/1000: D Loss=-0.3660, G Loss (Comb)=-2.7148
Epoch 550/1000: D Loss=-0.4176, G Loss (Comb)=-2.9111
Epoch 600/1000: D Loss=-0.4648, G Loss (Comb)=-2.9122
Epoch 650/1000: D Loss=-0.5140, G Loss (Comb)=-3.0814
Epoch 700/1000: D Loss=-0.6290, G Loss (Comb)=-3.1379
Epoch 750/1000: D Loss=-0.5950, G Loss (Comb)=-3.1570
Epoch 800/1000: D Loss=-0.6653, G Loss (Comb)=-3.4026
Epoch 850/1000: D Loss=-0.6695, G Loss (Comb)=-3.3968
Epoch 900/1000: D Loss=-0.6947, G Loss (Comb)=-3.5130
Epoch 950/1000: D Loss=-0.8243, G Loss (Comb)=-3.5617
Epoch 999/1000: D Loss=-0.8168, G Loss (Comb)=-3.6948

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0658
    Run 2, Batch 2: ERP Similarity Score: -0.0498
    Run 2, Batch 3: ERP Similarity Score: -0.0634
    Run 2, Batch 4: ERP Similarity Score: -0.0635
    Run 2, Batch 5: ERP Similarity Score: -0.0533
    Run 2, Batch 6: ERP Similarity Score: -0.0568
    Run 2, Batch 7: ERP Similarity Score: -0.0504
    Run 2, Batch 8: ERP Similarity Score: -0.0599
    Run 2, Batch 9: ERP Similarity Score: -0.0651
    Run 2, Batch 10: ERP Similarity Score: -0.0526
    Run 2, Batch 11: ERP Similarity Score: -0.0561
    Run 2, Batch 12: ERP Similarity Score: -0.0602
    Run 2, Batch 13: ERP Similarity Score: -0.0528
    Run 2, Batch 14: ERP Similarity Score: -0.0566
    Run 2, Batch 15: ERP Similarity Score: -0.0516
    Run 2, Batch 16: ERP Similarity Score: -0.0461
    Run 2, Batch 17: ERP Similarity Score: -0.0526
    Run 2, Batch 18: ERP Similarity Score: -0.0660
    Run 2, Batch 19: ERP Similarity Score: -0.0528
    Run 2, Batch 20: ERP Similarity Score: -0.0526
    Run 2, Batch 21: ERP Similarity Score: -0.0536
    Run 2, Batch 22: ERP Similarity Score: -0.0635
    Run 2, Batch 23: ERP Similarity Score: -0.0550
    Run 2, Batch 24: ERP Similarity Score: -0.0508
    Run 2, Batch 25: ERP Similarity Score: -0.0573
    Run 2, Batch 26: ERP Similarity Score: -0.0549
    Run 2, Batch 27: ERP Similarity Score: -0.0555
    Run 2, Batch 28: ERP Similarity Score: -0.0597
    Run 2, Batch 29: ERP Similarity Score: -0.0463
    Run 2, Batch 30: ERP Similarity Score: -0.0546

--- Training cWGAN-GP for Subject 7-8, Run 3 ---
Epoch 0/1000: D Loss=81.7813, G Loss (Comb)=0.2860
Epoch 50/1000: D Loss=-0.3665, G Loss (Comb)=-5.6190
Epoch 100/1000: D Loss=-0.4934, G Loss (Comb)=-4.7920
Epoch 150/1000: D Loss=-0.3941, G Loss (Comb)=-3.8665
Epoch 200/1000: D Loss=-0.2015, G Loss (Comb)=-4.5348
Epoch 250/1000: D Loss=0.0056, G Loss (Comb)=-5.2662
Epoch 300/1000: D Loss=-0.0645, G Loss (Comb)=-5.2369
Epoch 350/1000: D Loss=-0.1570, G Loss (Comb)=-5.3970
Epoch 400/1000: D Loss=-0.2188, G Loss (Comb)=-5.0265
Epoch 450/1000: D Loss=-0.2370, G Loss (Comb)=-4.9370
Epoch 500/1000: D Loss=-0.3199, G Loss (Comb)=-5.3863
Epoch 550/1000: D Loss=-0.4499, G Loss (Comb)=-5.1789
Epoch 600/1000: D Loss=-0.4389, G Loss (Comb)=-5.6287
Epoch 650/1000: D Loss=-0.4775, G Loss (Comb)=-5.6803
Epoch 700/1000: D Loss=-0.5572, G Loss (Comb)=-5.7144
Epoch 750/1000: D Loss=-0.5417, G Loss (Comb)=-6.0431
Epoch 800/1000: D Loss=-0.6416, G Loss (Comb)=-6.0603
Epoch 850/1000: D Loss=-0.6593, G Loss (Comb)=-6.2369
Epoch 900/1000: D Loss=-0.7326, G Loss (Comb)=-6.4582
Epoch 950/1000: D Loss=-0.7354, G Loss (Comb)=-6.3855
Epoch 999/1000: D Loss=-0.7707, G Loss (Comb)=-6.4517

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0638
    Run 3, Batch 2: ERP Similarity Score: -0.0577
    Run 3, Batch 3: ERP Similarity Score: -0.0558
    Run 3, Batch 4: ERP Similarity Score: -0.0611
    Run 3, Batch 5: ERP Similarity Score: -0.0568
    Run 3, Batch 6: ERP Similarity Score: -0.0504
    Run 3, Batch 7: ERP Similarity Score: -0.0620
    Run 3, Batch 8: ERP Similarity Score: -0.0663
    Run 3, Batch 9: ERP Similarity Score: -0.0564
    Run 3, Batch 10: ERP Similarity Score: -0.0578
    Run 3, Batch 11: ERP Similarity Score: -0.0645
    Run 3, Batch 12: ERP Similarity Score: -0.0561
    Run 3, Batch 13: ERP Similarity Score: -0.0555
    Run 3, Batch 14: ERP Similarity Score: -0.0538
    Run 3, Batch 15: ERP Similarity Score: -0.0548
    Run 3, Batch 16: ERP Similarity Score: -0.0646
    Run 3, Batch 17: ERP Similarity Score: -0.0566
    Run 3, Batch 18: ERP Similarity Score: -0.0490
    Run 3, Batch 19: ERP Similarity Score: -0.0541
    Run 3, Batch 20: ERP Similarity Score: -0.0554
    Run 3, Batch 21: ERP Similarity Score: -0.0555
    Run 3, Batch 22: ERP Similarity Score: -0.0555
    Run 3, Batch 23: ERP Similarity Score: -0.0597
    Run 3, Batch 24: ERP Similarity Score: -0.0552
    Run 3, Batch 25: ERP Similarity Score: -0.0604
    Run 3, Batch 26: ERP Similarity Score: -0.0690
    Run 3, Batch 27: ERP Similarity Score: -0.0587
    Run 3, Batch 28: ERP Similarity Score: -0.0578
    Run 3, Batch 29: ERP Similarity Score: -0.0539
    Run 3, Batch 30: ERP Similarity Score: -0.0631

--- Training cWGAN-GP for Subject 7-8, Run 4 ---
Epoch 0/1000: D Loss=72.5196, G Loss (Comb)=1.2701
Epoch 50/1000: D Loss=-0.3724, G Loss (Comb)=-3.5759
Epoch 100/1000: D Loss=-0.2254, G Loss (Comb)=-3.3580
Epoch 150/1000: D Loss=-0.2551, G Loss (Comb)=-3.4006
Epoch 200/1000: D Loss=-0.1901, G Loss (Comb)=-3.3404
Epoch 250/1000: D Loss=-0.3093, G Loss (Comb)=-3.4636
Epoch 300/1000: D Loss=-0.1691, G Loss (Comb)=-3.1207
Epoch 350/1000: D Loss=-0.3300, G Loss (Comb)=-2.8702
Epoch 400/1000: D Loss=-0.3591, G Loss (Comb)=-3.4607
Epoch 450/1000: D Loss=-0.3434, G Loss (Comb)=-3.3335
Epoch 500/1000: D Loss=-0.5718, G Loss (Comb)=-3.6332
Epoch 550/1000: D Loss=-0.5080, G Loss (Comb)=-3.7740
Epoch 600/1000: D Loss=-0.5398, G Loss (Comb)=-4.0056
Epoch 650/1000: D Loss=-0.5898, G Loss (Comb)=-4.0639
Epoch 700/1000: D Loss=-0.6402, G Loss (Comb)=-4.2106
Epoch 750/1000: D Loss=-0.6401, G Loss (Comb)=-4.4795
Epoch 800/1000: D Loss=-0.7032, G Loss (Comb)=-4.6124
Epoch 850/1000: D Loss=-0.7764, G Loss (Comb)=-4.6429
Epoch 900/1000: D Loss=-0.7291, G Loss (Comb)=-4.7168
Epoch 950/1000: D Loss=-0.8511, G Loss (Comb)=-4.7596
Epoch 999/1000: D Loss=-0.8863, G Loss (Comb)=-4.8289

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0444
    Run 4, Batch 2: ERP Similarity Score: -0.0368
    Run 4, Batch 3: ERP Similarity Score: -0.0416
    Run 4, Batch 4: ERP Similarity Score: -0.0445
    Run 4, Batch 5: ERP Similarity Score: -0.0418
    Run 4, Batch 6: ERP Similarity Score: -0.0414
    Run 4, Batch 7: ERP Similarity Score: -0.0322
    Run 4, Batch 8: ERP Similarity Score: -0.0347
    Run 4, Batch 9: ERP Similarity Score: -0.0453
    Run 4, Batch 10: ERP Similarity Score: -0.0486
    Run 4, Batch 11: ERP Similarity Score: -0.0384
    Run 4, Batch 12: ERP Similarity Score: -0.0446
    Run 4, Batch 13: ERP Similarity Score: -0.0542
    Run 4, Batch 14: ERP Similarity Score: -0.0366
    Run 4, Batch 15: ERP Similarity Score: -0.0355
    Run 4, Batch 16: ERP Similarity Score: -0.0431
    Run 4, Batch 17: ERP Similarity Score: -0.0343
    Run 4, Batch 18: ERP Similarity Score: -0.0428
    Run 4, Batch 19: ERP Similarity Score: -0.0356
    Run 4, Batch 20: ERP Similarity Score: -0.0440
    Run 4, Batch 21: ERP Similarity Score: -0.0332
    Run 4, Batch 22: ERP Similarity Score: -0.0337
    Run 4, Batch 23: ERP Similarity Score: -0.0366
    Run 4, Batch 24: ERP Similarity Score: -0.0419
    Run 4, Batch 25: ERP Similarity Score: -0.0420
    Run 4, Batch 26: ERP Similarity Score: -0.0420
    Run 4, Batch 27: ERP Similarity Score: -0.0449
    Run 4, Batch 28: ERP Similarity Score: -0.0444
    Run 4, Batch 29: ERP Similarity Score: -0.0539
    Run 4, Batch 30: ERP Similarity Score: -0.0432

--- Training cWGAN-GP for Subject 7-8, Run 5 ---
Epoch 0/1000: D Loss=64.4645, G Loss (Comb)=0.4803
Epoch 50/1000: D Loss=-0.2472, G Loss (Comb)=-4.9635
Epoch 100/1000: D Loss=-0.3806, G Loss (Comb)=-4.4439
Epoch 150/1000: D Loss=-0.1706, G Loss (Comb)=-4.5538
Epoch 200/1000: D Loss=-0.2651, G Loss (Comb)=-4.8034
Epoch 250/1000: D Loss=-0.2829, G Loss (Comb)=-4.8316
Epoch 300/1000: D Loss=-0.1423, G Loss (Comb)=-5.3306
Epoch 350/1000: D Loss=-0.2349, G Loss (Comb)=-4.7967
Epoch 400/1000: D Loss=-0.3532, G Loss (Comb)=-5.2924
Epoch 450/1000: D Loss=-0.2766, G Loss (Comb)=-5.2425
Epoch 500/1000: D Loss=-0.3916, G Loss (Comb)=-5.3201
Epoch 550/1000: D Loss=-0.4501, G Loss (Comb)=-5.5445
Epoch 600/1000: D Loss=-0.4881, G Loss (Comb)=-5.6210
Epoch 650/1000: D Loss=-0.5499, G Loss (Comb)=-5.5824
Epoch 700/1000: D Loss=-0.5569, G Loss (Comb)=-5.8822
Epoch 750/1000: D Loss=-0.5919, G Loss (Comb)=-5.7773
Epoch 800/1000: D Loss=-0.6405, G Loss (Comb)=-5.9680
Epoch 850/1000: D Loss=-0.6809, G Loss (Comb)=-6.1098
Epoch 900/1000: D Loss=-0.7443, G Loss (Comb)=-6.1479
Epoch 950/1000: D Loss=-0.7954, G Loss (Comb)=-6.1908
Epoch 999/1000: D Loss=-0.8102, G Loss (Comb)=-6.3593

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0787
    Run 5, Batch 2: ERP Similarity Score: -0.0814
    Run 5, Batch 3: ERP Similarity Score: -0.0785
    Run 5, Batch 4: ERP Similarity Score: -0.0794
    Run 5, Batch 5: ERP Similarity Score: -0.0834
    Run 5, Batch 6: ERP Similarity Score: -0.0924
    Run 5, Batch 7: ERP Similarity Score: -0.0827
    Run 5, Batch 8: ERP Similarity Score: -0.0858
    Run 5, Batch 9: ERP Similarity Score: -0.0829
    Run 5, Batch 10: ERP Similarity Score: -0.0841
    Run 5, Batch 11: ERP Similarity Score: -0.0856
    Run 5, Batch 12: ERP Similarity Score: -0.0782
    Run 5, Batch 13: ERP Similarity Score: -0.0793
    Run 5, Batch 14: ERP Similarity Score: -0.0812
    Run 5, Batch 15: ERP Similarity Score: -0.0769
    Run 5, Batch 16: ERP Similarity Score: -0.0754
    Run 5, Batch 17: ERP Similarity Score: -0.0786
    Run 5, Batch 18: ERP Similarity Score: -0.0745
    Run 5, Batch 19: ERP Similarity Score: -0.0761
    Run 5, Batch 20: ERP Similarity Score: -0.0768
    Run 5, Batch 21: ERP Similarity Score: -0.0850
    Run 5, Batch 22: ERP Similarity Score: -0.0855
    Run 5, Batch 23: ERP Similarity Score: -0.0847
    Run 5, Batch 24: ERP Similarity Score: -0.0815
    Run 5, Batch 25: ERP Similarity Score: -0.0806
    Run 5, Batch 26: ERP Similarity Score: -0.0856
    Run 5, Batch 27: ERP Similarity Score: -0.0782
    Run 5, Batch 28: ERP Similarity Score: -0.0785
    Run 5, Batch 29: ERP Similarity Score: -0.0851
    Run 5, Batch 30: ERP Similarity Score: -0.0794


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 4, Batch 7, Score: -0.0322
  Top 2: Run 4, Batch 21, Score: -0.0332
  Top 3: Run 4, Batch 22, Score: -0.0337
  Top 4: Run 4, Batch 17, Score: -0.0343
  Top 5: Run 4, Batch 8, Score: -0.0347
  Top 6: Run 1, Batch 28, Score: -0.0355
  Top 7: Run 4, Batch 15, Score: -0.0355
  Top 8: Run 4, Batch 19, Score: -0.0356
  Top 9: Run 4, Batch 23, Score: -0.0366
  Top 10: Run 4, Batch 14, Score: -0.0366

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 4, Batch 7, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 7, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 7, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 7, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 21, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 22, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 4, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 17, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 4, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 4, Batch 8, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 28, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 1, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 15, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 4, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 19, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 23, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 23, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 23, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 23, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 14, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 80.00%

Found 12 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 7, Ratio 0): Accuracy=100.00, ERP Score=-0.0322
  - Strategy (Run 4, Batch 7, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0322
  - Strategy (Run 4, Batch 7, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0322
  - Strategy (Run 4, Batch 21, Ratio 0): Accuracy=100.00, ERP Score=-0.0332
  - Strategy (Run 4, Batch 22, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0337
  - Strategy (Run 4, Batch 22, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0337
  - Strategy (Run 4, Batch 17, Ratio 0): Accuracy=100.00, ERP Score=-0.0343
  - Strategy (Run 4, Batch 17, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0343
  - Strategy (Run 4, Batch 8, Ratio 0): Accuracy=100.00, ERP Score=-0.0347
  - Strategy (Run 4, Batch 8, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0347
  - Strategy (Run 4, Batch 8, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0347
  - Strategy (Run 4, Batch 14, Ratio 0): Accuracy=100.00, ERP Score=-0.0366

Selected best strategy: Run 4, Batch 7, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 73.02%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 73.02%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H4_results/Subject_7-8_results/accuracy_comparison_S7-8.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 7-8) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H4_results/Subject_7-8_results/GA_ERP_Combined_S7-8_ChCz.png

--- Subject 7-8 processing finished successfully. ---
