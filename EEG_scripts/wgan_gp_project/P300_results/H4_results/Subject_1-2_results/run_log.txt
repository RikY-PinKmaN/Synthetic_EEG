Log for Subject Pair 1-2 from H4
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H4 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 269 clean Target and 537 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 581

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 37

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 70.27%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=64.3713, G Loss (Comb)=1.5930
Epoch 50/1000: D Loss=-1.3957, G Loss (Comb)=-1.9152
Epoch 100/1000: D Loss=-0.5341, G Loss (Comb)=-3.5527
Epoch 150/1000: D Loss=-0.4996, G Loss (Comb)=-3.3139
Epoch 200/1000: D Loss=-0.3630, G Loss (Comb)=-3.5533
Epoch 250/1000: D Loss=-0.4624, G Loss (Comb)=-3.5552
Epoch 300/1000: D Loss=-0.6034, G Loss (Comb)=-3.3560
Epoch 350/1000: D Loss=-0.6524, G Loss (Comb)=-3.0460
Epoch 400/1000: D Loss=-0.6654, G Loss (Comb)=-2.7195
Epoch 450/1000: D Loss=-0.8038, G Loss (Comb)=-2.4147
Epoch 500/1000: D Loss=-0.9778, G Loss (Comb)=-2.4612
Epoch 550/1000: D Loss=-0.9871, G Loss (Comb)=-2.1904
Epoch 600/1000: D Loss=-1.1405, G Loss (Comb)=-2.2554
Epoch 650/1000: D Loss=-1.1371, G Loss (Comb)=-1.9236
Epoch 700/1000: D Loss=-1.1435, G Loss (Comb)=-1.9199
Epoch 750/1000: D Loss=-1.2279, G Loss (Comb)=-1.7856
Epoch 800/1000: D Loss=-1.3106, G Loss (Comb)=-1.5097
Epoch 850/1000: D Loss=-1.3599, G Loss (Comb)=-1.5933
Epoch 900/1000: D Loss=-1.3881, G Loss (Comb)=-1.4450
Epoch 950/1000: D Loss=-1.3869, G Loss (Comb)=-1.2812
Epoch 999/1000: D Loss=-1.4383, G Loss (Comb)=-1.2536

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0647
    Run 1, Batch 2: ERP Similarity Score: -0.0624
    Run 1, Batch 3: ERP Similarity Score: -0.0698
    Run 1, Batch 4: ERP Similarity Score: -0.0593
    Run 1, Batch 5: ERP Similarity Score: -0.0475
    Run 1, Batch 6: ERP Similarity Score: -0.0555
    Run 1, Batch 7: ERP Similarity Score: -0.0595
    Run 1, Batch 8: ERP Similarity Score: -0.0571
    Run 1, Batch 9: ERP Similarity Score: -0.0565
    Run 1, Batch 10: ERP Similarity Score: -0.0647
    Run 1, Batch 11: ERP Similarity Score: -0.0599
    Run 1, Batch 12: ERP Similarity Score: -0.0631
    Run 1, Batch 13: ERP Similarity Score: -0.0716
    Run 1, Batch 14: ERP Similarity Score: -0.0599
    Run 1, Batch 15: ERP Similarity Score: -0.0657
    Run 1, Batch 16: ERP Similarity Score: -0.0590
    Run 1, Batch 17: ERP Similarity Score: -0.0598
    Run 1, Batch 18: ERP Similarity Score: -0.0552
    Run 1, Batch 19: ERP Similarity Score: -0.0596
    Run 1, Batch 20: ERP Similarity Score: -0.0590
    Run 1, Batch 21: ERP Similarity Score: -0.0608
    Run 1, Batch 22: ERP Similarity Score: -0.0643
    Run 1, Batch 23: ERP Similarity Score: -0.0652
    Run 1, Batch 24: ERP Similarity Score: -0.0629
    Run 1, Batch 25: ERP Similarity Score: -0.0657
    Run 1, Batch 26: ERP Similarity Score: -0.0589
    Run 1, Batch 27: ERP Similarity Score: -0.0527
    Run 1, Batch 28: ERP Similarity Score: -0.0608
    Run 1, Batch 29: ERP Similarity Score: -0.0532
    Run 1, Batch 30: ERP Similarity Score: -0.0635

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=59.0050, G Loss (Comb)=2.0946
Epoch 50/1000: D Loss=-1.2564, G Loss (Comb)=0.1726
Epoch 100/1000: D Loss=-0.4813, G Loss (Comb)=-1.6109
Epoch 150/1000: D Loss=-0.4350, G Loss (Comb)=-1.9358
Epoch 200/1000: D Loss=-0.4709, G Loss (Comb)=-1.8762
Epoch 250/1000: D Loss=-0.4988, G Loss (Comb)=-1.2841
Epoch 300/1000: D Loss=-0.4568, G Loss (Comb)=-1.7075
Epoch 350/1000: D Loss=-0.5739, G Loss (Comb)=-1.5104
Epoch 400/1000: D Loss=-0.7906, G Loss (Comb)=-1.3233
Epoch 450/1000: D Loss=-0.8146, G Loss (Comb)=-0.8253
Epoch 500/1000: D Loss=-0.8911, G Loss (Comb)=-0.6619
Epoch 550/1000: D Loss=-0.9012, G Loss (Comb)=-0.3741
Epoch 600/1000: D Loss=-1.0744, G Loss (Comb)=-0.3613
Epoch 650/1000: D Loss=-1.0929, G Loss (Comb)=-0.2077
Epoch 700/1000: D Loss=-1.1852, G Loss (Comb)=-0.1597
Epoch 750/1000: D Loss=-1.2332, G Loss (Comb)=-0.1465
Epoch 800/1000: D Loss=-1.3358, G Loss (Comb)=-0.0186
Epoch 850/1000: D Loss=-1.3873, G Loss (Comb)=-0.0170
Epoch 900/1000: D Loss=-1.3477, G Loss (Comb)=-0.0834
Epoch 950/1000: D Loss=-1.4412, G Loss (Comb)=0.0986
Epoch 999/1000: D Loss=-1.3914, G Loss (Comb)=0.1992

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0673
    Run 2, Batch 2: ERP Similarity Score: -0.0649
    Run 2, Batch 3: ERP Similarity Score: -0.0619
    Run 2, Batch 4: ERP Similarity Score: -0.0630
    Run 2, Batch 5: ERP Similarity Score: -0.0644
    Run 2, Batch 6: ERP Similarity Score: -0.0669
    Run 2, Batch 7: ERP Similarity Score: -0.0700
    Run 2, Batch 8: ERP Similarity Score: -0.0658
    Run 2, Batch 9: ERP Similarity Score: -0.0692
    Run 2, Batch 10: ERP Similarity Score: -0.0619
    Run 2, Batch 11: ERP Similarity Score: -0.0613
    Run 2, Batch 12: ERP Similarity Score: -0.0636
    Run 2, Batch 13: ERP Similarity Score: -0.0730
    Run 2, Batch 14: ERP Similarity Score: -0.0744
    Run 2, Batch 15: ERP Similarity Score: -0.0580
    Run 2, Batch 16: ERP Similarity Score: -0.0553
    Run 2, Batch 17: ERP Similarity Score: -0.0686
    Run 2, Batch 18: ERP Similarity Score: -0.0679
    Run 2, Batch 19: ERP Similarity Score: -0.0610
    Run 2, Batch 20: ERP Similarity Score: -0.0647
    Run 2, Batch 21: ERP Similarity Score: -0.0655
    Run 2, Batch 22: ERP Similarity Score: -0.0657
    Run 2, Batch 23: ERP Similarity Score: -0.0593
    Run 2, Batch 24: ERP Similarity Score: -0.0687
    Run 2, Batch 25: ERP Similarity Score: -0.0726
    Run 2, Batch 26: ERP Similarity Score: -0.0667
    Run 2, Batch 27: ERP Similarity Score: -0.0691
    Run 2, Batch 28: ERP Similarity Score: -0.0684
    Run 2, Batch 29: ERP Similarity Score: -0.0637
    Run 2, Batch 30: ERP Similarity Score: -0.0598

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=63.2884, G Loss (Comb)=1.7745
Epoch 50/1000: D Loss=-1.0971, G Loss (Comb)=-1.3068
Epoch 100/1000: D Loss=-0.4218, G Loss (Comb)=-2.6559
Epoch 150/1000: D Loss=-0.3210, G Loss (Comb)=-3.2245
Epoch 200/1000: D Loss=-0.5295, G Loss (Comb)=-2.6703
Epoch 250/1000: D Loss=-0.6280, G Loss (Comb)=-2.3407
Epoch 300/1000: D Loss=-0.5068, G Loss (Comb)=-2.1028
Epoch 350/1000: D Loss=-0.5747, G Loss (Comb)=-1.9769
Epoch 400/1000: D Loss=-0.7368, G Loss (Comb)=-1.4870
Epoch 450/1000: D Loss=-0.7864, G Loss (Comb)=-1.3153
Epoch 500/1000: D Loss=-0.9324, G Loss (Comb)=-1.0487
Epoch 550/1000: D Loss=-0.9148, G Loss (Comb)=-0.8648
Epoch 600/1000: D Loss=-1.1299, G Loss (Comb)=-0.6937
Epoch 650/1000: D Loss=-1.1000, G Loss (Comb)=-0.5201
Epoch 700/1000: D Loss=-1.2646, G Loss (Comb)=-0.5636
Epoch 750/1000: D Loss=-1.2587, G Loss (Comb)=-0.3539
Epoch 800/1000: D Loss=-1.3300, G Loss (Comb)=-0.3434
Epoch 850/1000: D Loss=-1.3161, G Loss (Comb)=-0.4073
Epoch 900/1000: D Loss=-1.3437, G Loss (Comb)=-0.1372
Epoch 950/1000: D Loss=-1.4000, G Loss (Comb)=-0.1171
Epoch 999/1000: D Loss=-1.4147, G Loss (Comb)=-0.1891

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0580
    Run 3, Batch 2: ERP Similarity Score: -0.0610
    Run 3, Batch 3: ERP Similarity Score: -0.0598
    Run 3, Batch 4: ERP Similarity Score: -0.0637
    Run 3, Batch 5: ERP Similarity Score: -0.0597
    Run 3, Batch 6: ERP Similarity Score: -0.0678
    Run 3, Batch 7: ERP Similarity Score: -0.0693
    Run 3, Batch 8: ERP Similarity Score: -0.0693
    Run 3, Batch 9: ERP Similarity Score: -0.0659
    Run 3, Batch 10: ERP Similarity Score: -0.0645
    Run 3, Batch 11: ERP Similarity Score: -0.0624
    Run 3, Batch 12: ERP Similarity Score: -0.0578
    Run 3, Batch 13: ERP Similarity Score: -0.0612
    Run 3, Batch 14: ERP Similarity Score: -0.0659
    Run 3, Batch 15: ERP Similarity Score: -0.0620
    Run 3, Batch 16: ERP Similarity Score: -0.0682
    Run 3, Batch 17: ERP Similarity Score: -0.0681
    Run 3, Batch 18: ERP Similarity Score: -0.0611
    Run 3, Batch 19: ERP Similarity Score: -0.0594
    Run 3, Batch 20: ERP Similarity Score: -0.0648
    Run 3, Batch 21: ERP Similarity Score: -0.0643
    Run 3, Batch 22: ERP Similarity Score: -0.0564
    Run 3, Batch 23: ERP Similarity Score: -0.0679
    Run 3, Batch 24: ERP Similarity Score: -0.0640
    Run 3, Batch 25: ERP Similarity Score: -0.0632
    Run 3, Batch 26: ERP Similarity Score: -0.0667
    Run 3, Batch 27: ERP Similarity Score: -0.0698
    Run 3, Batch 28: ERP Similarity Score: -0.0631
    Run 3, Batch 29: ERP Similarity Score: -0.0666
    Run 3, Batch 30: ERP Similarity Score: -0.0674

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=60.7789, G Loss (Comb)=0.9251
Epoch 50/1000: D Loss=-1.3806, G Loss (Comb)=-1.8890
Epoch 100/1000: D Loss=-0.6688, G Loss (Comb)=-4.3356
Epoch 150/1000: D Loss=-0.6083, G Loss (Comb)=-4.4748
Epoch 200/1000: D Loss=-0.5247, G Loss (Comb)=-4.7385
Epoch 250/1000: D Loss=-0.5115, G Loss (Comb)=-4.4408
Epoch 300/1000: D Loss=-0.5461, G Loss (Comb)=-4.5677
Epoch 350/1000: D Loss=-0.6340, G Loss (Comb)=-4.2204
Epoch 400/1000: D Loss=-0.5917, G Loss (Comb)=-3.8198
Epoch 450/1000: D Loss=-0.7011, G Loss (Comb)=-3.3544
Epoch 500/1000: D Loss=-0.7769, G Loss (Comb)=-3.3589
Epoch 550/1000: D Loss=-0.8989, G Loss (Comb)=-3.0654
Epoch 600/1000: D Loss=-1.0550, G Loss (Comb)=-2.8043
Epoch 650/1000: D Loss=-1.0649, G Loss (Comb)=-2.6725
Epoch 700/1000: D Loss=-1.1218, G Loss (Comb)=-2.6361
Epoch 750/1000: D Loss=-1.2060, G Loss (Comb)=-2.5038
Epoch 800/1000: D Loss=-1.2000, G Loss (Comb)=-2.5630
Epoch 850/1000: D Loss=-1.2178, G Loss (Comb)=-2.4028
Epoch 900/1000: D Loss=-1.3453, G Loss (Comb)=-2.2783
Epoch 950/1000: D Loss=-1.3450, G Loss (Comb)=-2.2092
Epoch 999/1000: D Loss=-1.4150, G Loss (Comb)=-2.2552

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0826
    Run 4, Batch 2: ERP Similarity Score: -0.0749
    Run 4, Batch 3: ERP Similarity Score: -0.0784
    Run 4, Batch 4: ERP Similarity Score: -0.0823
    Run 4, Batch 5: ERP Similarity Score: -0.0768
    Run 4, Batch 6: ERP Similarity Score: -0.0731
    Run 4, Batch 7: ERP Similarity Score: -0.0839
    Run 4, Batch 8: ERP Similarity Score: -0.0753
    Run 4, Batch 9: ERP Similarity Score: -0.0772
    Run 4, Batch 10: ERP Similarity Score: -0.0819
    Run 4, Batch 11: ERP Similarity Score: -0.0746
    Run 4, Batch 12: ERP Similarity Score: -0.0886
    Run 4, Batch 13: ERP Similarity Score: -0.0853
    Run 4, Batch 14: ERP Similarity Score: -0.0732
    Run 4, Batch 15: ERP Similarity Score: -0.0806
    Run 4, Batch 16: ERP Similarity Score: -0.0765
    Run 4, Batch 17: ERP Similarity Score: -0.0821
    Run 4, Batch 18: ERP Similarity Score: -0.0806
    Run 4, Batch 19: ERP Similarity Score: -0.0762
    Run 4, Batch 20: ERP Similarity Score: -0.0789
    Run 4, Batch 21: ERP Similarity Score: -0.0728
    Run 4, Batch 22: ERP Similarity Score: -0.0762
    Run 4, Batch 23: ERP Similarity Score: -0.0860
    Run 4, Batch 24: ERP Similarity Score: -0.0713
    Run 4, Batch 25: ERP Similarity Score: -0.0850
    Run 4, Batch 26: ERP Similarity Score: -0.0674
    Run 4, Batch 27: ERP Similarity Score: -0.0687
    Run 4, Batch 28: ERP Similarity Score: -0.0784
    Run 4, Batch 29: ERP Similarity Score: -0.0716
    Run 4, Batch 30: ERP Similarity Score: -0.0829

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=66.5184, G Loss (Comb)=2.0761
Epoch 50/1000: D Loss=-1.1456, G Loss (Comb)=-0.7358
Epoch 100/1000: D Loss=-0.6171, G Loss (Comb)=-3.1988
Epoch 150/1000: D Loss=-0.3446, G Loss (Comb)=-3.2462
Epoch 200/1000: D Loss=-0.5334, G Loss (Comb)=-3.1622
Epoch 250/1000: D Loss=-0.5699, G Loss (Comb)=-3.1359
Epoch 300/1000: D Loss=-0.6351, G Loss (Comb)=-3.4926
Epoch 350/1000: D Loss=-0.5542, G Loss (Comb)=-2.9729
Epoch 400/1000: D Loss=-0.7591, G Loss (Comb)=-2.5140
Epoch 450/1000: D Loss=-0.8471, G Loss (Comb)=-2.1314
Epoch 500/1000: D Loss=-0.9790, G Loss (Comb)=-1.8084
Epoch 550/1000: D Loss=-1.0818, G Loss (Comb)=-1.6536
Epoch 600/1000: D Loss=-1.0651, G Loss (Comb)=-1.3045
Epoch 650/1000: D Loss=-1.1505, G Loss (Comb)=-1.1080
Epoch 700/1000: D Loss=-1.1806, G Loss (Comb)=-1.0329
Epoch 750/1000: D Loss=-1.2696, G Loss (Comb)=-0.7635
Epoch 800/1000: D Loss=-1.3406, G Loss (Comb)=-0.7067
Epoch 850/1000: D Loss=-1.3641, G Loss (Comb)=-0.4896
Epoch 900/1000: D Loss=-1.4035, G Loss (Comb)=-0.4470
Epoch 950/1000: D Loss=-1.4427, G Loss (Comb)=-0.3054
Epoch 999/1000: D Loss=-1.4559, G Loss (Comb)=-0.2790

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0663
    Run 5, Batch 2: ERP Similarity Score: -0.0711
    Run 5, Batch 3: ERP Similarity Score: -0.0701
    Run 5, Batch 4: ERP Similarity Score: -0.0643
    Run 5, Batch 5: ERP Similarity Score: -0.0659
    Run 5, Batch 6: ERP Similarity Score: -0.0736
    Run 5, Batch 7: ERP Similarity Score: -0.0594
    Run 5, Batch 8: ERP Similarity Score: -0.0635
    Run 5, Batch 9: ERP Similarity Score: -0.0646
    Run 5, Batch 10: ERP Similarity Score: -0.0588
    Run 5, Batch 11: ERP Similarity Score: -0.0739
    Run 5, Batch 12: ERP Similarity Score: -0.0598
    Run 5, Batch 13: ERP Similarity Score: -0.0603
    Run 5, Batch 14: ERP Similarity Score: -0.0773
    Run 5, Batch 15: ERP Similarity Score: -0.0576
    Run 5, Batch 16: ERP Similarity Score: -0.0639
    Run 5, Batch 17: ERP Similarity Score: -0.0605
    Run 5, Batch 18: ERP Similarity Score: -0.0677
    Run 5, Batch 19: ERP Similarity Score: -0.0651
    Run 5, Batch 20: ERP Similarity Score: -0.0629
    Run 5, Batch 21: ERP Similarity Score: -0.0734
    Run 5, Batch 22: ERP Similarity Score: -0.0691
    Run 5, Batch 23: ERP Similarity Score: -0.0662
    Run 5, Batch 24: ERP Similarity Score: -0.0661
    Run 5, Batch 25: ERP Similarity Score: -0.0675
    Run 5, Batch 26: ERP Similarity Score: -0.0656
    Run 5, Batch 27: ERP Similarity Score: -0.0668
    Run 5, Batch 28: ERP Similarity Score: -0.0691
    Run 5, Batch 29: ERP Similarity Score: -0.0658
    Run 5, Batch 30: ERP Similarity Score: -0.0648


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 1, Batch 5, Score: -0.0475
  Top 2: Run 1, Batch 27, Score: -0.0527
  Top 3: Run 1, Batch 29, Score: -0.0532
  Top 4: Run 1, Batch 18, Score: -0.0552
  Top 5: Run 2, Batch 16, Score: -0.0553
  Top 6: Run 1, Batch 6, Score: -0.0555
  Top 7: Run 3, Batch 22, Score: -0.0564
  Top 8: Run 1, Batch 9, Score: -0.0565
  Top 9: Run 1, Batch 8, Score: -0.0571
  Top 10: Run 5, Batch 15, Score: -0.0576

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 1, Batch 5, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 29, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 1, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 18, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 16, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 1, Batch 6, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 22, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 3, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 9, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 8, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 15, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 33.33%

Found 4 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 1, Batch 5, Ratio 0): Accuracy=100.00, ERP Score=-0.0475
  - Strategy (Run 1, Batch 6, Ratio 0): Accuracy=100.00, ERP Score=-0.0555
  - Strategy (Run 1, Batch 6, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0555
  - Strategy (Run 1, Batch 8, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0571

Selected best strategy: Run 1, Batch 5, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 51.35%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 51.35%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H4_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H4_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
