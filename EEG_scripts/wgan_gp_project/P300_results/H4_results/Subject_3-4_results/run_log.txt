Log for Subject Pair 3-4 from H4
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H4 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 270 clean Target and 540 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 585

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 39

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 64.10%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=77.6836, G Loss (Comb)=1.6260
Epoch 50/1000: D Loss=-1.2831, G Loss (Comb)=-0.5921
Epoch 100/1000: D Loss=-0.5515, G Loss (Comb)=-2.9659
Epoch 150/1000: D Loss=-0.2523, G Loss (Comb)=-3.7864
Epoch 200/1000: D Loss=-0.3534, G Loss (Comb)=-3.2188
Epoch 250/1000: D Loss=-0.3423, G Loss (Comb)=-3.0317
Epoch 300/1000: D Loss=-0.2076, G Loss (Comb)=-2.9861
Epoch 350/1000: D Loss=-0.3689, G Loss (Comb)=-2.8276
Epoch 400/1000: D Loss=-0.3471, G Loss (Comb)=-3.4103
Epoch 450/1000: D Loss=-0.2914, G Loss (Comb)=-3.1251
Epoch 500/1000: D Loss=-0.4633, G Loss (Comb)=-2.7566
Epoch 550/1000: D Loss=-0.5812, G Loss (Comb)=-3.0105
Epoch 600/1000: D Loss=-0.6333, G Loss (Comb)=-3.2389
Epoch 650/1000: D Loss=-0.6122, G Loss (Comb)=-3.4605
Epoch 700/1000: D Loss=-0.8078, G Loss (Comb)=-3.2403
Epoch 750/1000: D Loss=-0.8968, G Loss (Comb)=-3.2075
Epoch 800/1000: D Loss=-0.9374, G Loss (Comb)=-3.0441
Epoch 850/1000: D Loss=-1.0206, G Loss (Comb)=-3.1649
Epoch 900/1000: D Loss=-1.0569, G Loss (Comb)=-3.1523
Epoch 950/1000: D Loss=-1.0967, G Loss (Comb)=-3.1064
Epoch 999/1000: D Loss=-1.1195, G Loss (Comb)=-3.2363

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0478
    Run 1, Batch 2: ERP Similarity Score: -0.0490
    Run 1, Batch 3: ERP Similarity Score: -0.0444
    Run 1, Batch 4: ERP Similarity Score: -0.0468
    Run 1, Batch 5: ERP Similarity Score: -0.0497
    Run 1, Batch 6: ERP Similarity Score: -0.0452
    Run 1, Batch 7: ERP Similarity Score: -0.0476
    Run 1, Batch 8: ERP Similarity Score: -0.0454
    Run 1, Batch 9: ERP Similarity Score: -0.0517
    Run 1, Batch 10: ERP Similarity Score: -0.0367
    Run 1, Batch 11: ERP Similarity Score: -0.0477
    Run 1, Batch 12: ERP Similarity Score: -0.0439
    Run 1, Batch 13: ERP Similarity Score: -0.0531
    Run 1, Batch 14: ERP Similarity Score: -0.0550
    Run 1, Batch 15: ERP Similarity Score: -0.0462
    Run 1, Batch 16: ERP Similarity Score: -0.0430
    Run 1, Batch 17: ERP Similarity Score: -0.0436
    Run 1, Batch 18: ERP Similarity Score: -0.0483
    Run 1, Batch 19: ERP Similarity Score: -0.0512
    Run 1, Batch 20: ERP Similarity Score: -0.0512
    Run 1, Batch 21: ERP Similarity Score: -0.0512
    Run 1, Batch 22: ERP Similarity Score: -0.0503
    Run 1, Batch 23: ERP Similarity Score: -0.0479
    Run 1, Batch 24: ERP Similarity Score: -0.0518
    Run 1, Batch 25: ERP Similarity Score: -0.0421
    Run 1, Batch 26: ERP Similarity Score: -0.0541
    Run 1, Batch 27: ERP Similarity Score: -0.0389
    Run 1, Batch 28: ERP Similarity Score: -0.0408
    Run 1, Batch 29: ERP Similarity Score: -0.0492
    Run 1, Batch 30: ERP Similarity Score: -0.0457

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=80.6966, G Loss (Comb)=-0.3352
Epoch 50/1000: D Loss=-1.2196, G Loss (Comb)=-2.5558
Epoch 100/1000: D Loss=-0.5272, G Loss (Comb)=-4.9260
Epoch 150/1000: D Loss=-0.4181, G Loss (Comb)=-5.4976
Epoch 200/1000: D Loss=-0.4494, G Loss (Comb)=-4.9504
Epoch 250/1000: D Loss=-0.3212, G Loss (Comb)=-5.5930
Epoch 300/1000: D Loss=-0.3973, G Loss (Comb)=-5.4981
Epoch 350/1000: D Loss=-0.4710, G Loss (Comb)=-5.4700
Epoch 400/1000: D Loss=-0.3779, G Loss (Comb)=-5.4131
Epoch 450/1000: D Loss=-0.6063, G Loss (Comb)=-5.2902
Epoch 500/1000: D Loss=-0.7392, G Loss (Comb)=-4.8928
Epoch 550/1000: D Loss=-0.6890, G Loss (Comb)=-4.4148
Epoch 600/1000: D Loss=-0.7438, G Loss (Comb)=-4.1788
Epoch 650/1000: D Loss=-0.8018, G Loss (Comb)=-4.1997
Epoch 700/1000: D Loss=-0.9001, G Loss (Comb)=-4.0569
Epoch 750/1000: D Loss=-1.0372, G Loss (Comb)=-4.3299
Epoch 800/1000: D Loss=-0.9852, G Loss (Comb)=-4.0064
Epoch 850/1000: D Loss=-1.1382, G Loss (Comb)=-3.9853
Epoch 900/1000: D Loss=-1.2147, G Loss (Comb)=-4.0997
Epoch 950/1000: D Loss=-1.2508, G Loss (Comb)=-3.8436
Epoch 999/1000: D Loss=-1.1983, G Loss (Comb)=-3.8284

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0488
    Run 2, Batch 2: ERP Similarity Score: -0.0441
    Run 2, Batch 3: ERP Similarity Score: -0.0487
    Run 2, Batch 4: ERP Similarity Score: -0.0463
    Run 2, Batch 5: ERP Similarity Score: -0.0435
    Run 2, Batch 6: ERP Similarity Score: -0.0464
    Run 2, Batch 7: ERP Similarity Score: -0.0423
    Run 2, Batch 8: ERP Similarity Score: -0.0404
    Run 2, Batch 9: ERP Similarity Score: -0.0478
    Run 2, Batch 10: ERP Similarity Score: -0.0412
    Run 2, Batch 11: ERP Similarity Score: -0.0411
    Run 2, Batch 12: ERP Similarity Score: -0.0451
    Run 2, Batch 13: ERP Similarity Score: -0.0431
    Run 2, Batch 14: ERP Similarity Score: -0.0483
    Run 2, Batch 15: ERP Similarity Score: -0.0486
    Run 2, Batch 16: ERP Similarity Score: -0.0452
    Run 2, Batch 17: ERP Similarity Score: -0.0488
    Run 2, Batch 18: ERP Similarity Score: -0.0439
    Run 2, Batch 19: ERP Similarity Score: -0.0405
    Run 2, Batch 20: ERP Similarity Score: -0.0481
    Run 2, Batch 21: ERP Similarity Score: -0.0427
    Run 2, Batch 22: ERP Similarity Score: -0.0478
    Run 2, Batch 23: ERP Similarity Score: -0.0436
    Run 2, Batch 24: ERP Similarity Score: -0.0391
    Run 2, Batch 25: ERP Similarity Score: -0.0425
    Run 2, Batch 26: ERP Similarity Score: -0.0413
    Run 2, Batch 27: ERP Similarity Score: -0.0453
    Run 2, Batch 28: ERP Similarity Score: -0.0443
    Run 2, Batch 29: ERP Similarity Score: -0.0448
    Run 2, Batch 30: ERP Similarity Score: -0.0453

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=64.4021, G Loss (Comb)=1.2741
Epoch 50/1000: D Loss=-1.3090, G Loss (Comb)=-0.9539
Epoch 100/1000: D Loss=-0.4682, G Loss (Comb)=-3.9964
Epoch 150/1000: D Loss=-0.3688, G Loss (Comb)=-3.6578
Epoch 200/1000: D Loss=-0.2621, G Loss (Comb)=-4.0102
Epoch 250/1000: D Loss=-0.4722, G Loss (Comb)=-3.9260
Epoch 300/1000: D Loss=-0.4973, G Loss (Comb)=-4.2826
Epoch 350/1000: D Loss=-0.3713, G Loss (Comb)=-4.4336
Epoch 400/1000: D Loss=-0.5123, G Loss (Comb)=-4.0024
Epoch 450/1000: D Loss=-0.6202, G Loss (Comb)=-3.6943
Epoch 500/1000: D Loss=-0.6478, G Loss (Comb)=-3.8015
Epoch 550/1000: D Loss=-0.7252, G Loss (Comb)=-3.3541
Epoch 600/1000: D Loss=-0.7459, G Loss (Comb)=-3.1867
Epoch 650/1000: D Loss=-0.8009, G Loss (Comb)=-3.1276
Epoch 700/1000: D Loss=-0.9581, G Loss (Comb)=-2.8838
Epoch 750/1000: D Loss=-0.9947, G Loss (Comb)=-2.7917
Epoch 800/1000: D Loss=-0.9766, G Loss (Comb)=-2.7321
Epoch 850/1000: D Loss=-1.0807, G Loss (Comb)=-2.6678
Epoch 900/1000: D Loss=-1.1105, G Loss (Comb)=-2.5336
Epoch 950/1000: D Loss=-1.1736, G Loss (Comb)=-2.5001
Epoch 999/1000: D Loss=-1.1678, G Loss (Comb)=-2.5796

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0428
    Run 3, Batch 2: ERP Similarity Score: -0.0487
    Run 3, Batch 3: ERP Similarity Score: -0.0466
    Run 3, Batch 4: ERP Similarity Score: -0.0527
    Run 3, Batch 5: ERP Similarity Score: -0.0445
    Run 3, Batch 6: ERP Similarity Score: -0.0498
    Run 3, Batch 7: ERP Similarity Score: -0.0433
    Run 3, Batch 8: ERP Similarity Score: -0.0449
    Run 3, Batch 9: ERP Similarity Score: -0.0451
    Run 3, Batch 10: ERP Similarity Score: -0.0441
    Run 3, Batch 11: ERP Similarity Score: -0.0505
    Run 3, Batch 12: ERP Similarity Score: -0.0473
    Run 3, Batch 13: ERP Similarity Score: -0.0453
    Run 3, Batch 14: ERP Similarity Score: -0.0453
    Run 3, Batch 15: ERP Similarity Score: -0.0488
    Run 3, Batch 16: ERP Similarity Score: -0.0461
    Run 3, Batch 17: ERP Similarity Score: -0.0450
    Run 3, Batch 18: ERP Similarity Score: -0.0457
    Run 3, Batch 19: ERP Similarity Score: -0.0437
    Run 3, Batch 20: ERP Similarity Score: -0.0517
    Run 3, Batch 21: ERP Similarity Score: -0.0471
    Run 3, Batch 22: ERP Similarity Score: -0.0425
    Run 3, Batch 23: ERP Similarity Score: -0.0421
    Run 3, Batch 24: ERP Similarity Score: -0.0479
    Run 3, Batch 25: ERP Similarity Score: -0.0468
    Run 3, Batch 26: ERP Similarity Score: -0.0464
    Run 3, Batch 27: ERP Similarity Score: -0.0462
    Run 3, Batch 28: ERP Similarity Score: -0.0511
    Run 3, Batch 29: ERP Similarity Score: -0.0475
    Run 3, Batch 30: ERP Similarity Score: -0.0474

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=62.8868, G Loss (Comb)=2.3509
Epoch 50/1000: D Loss=-1.1048, G Loss (Comb)=-0.4314
Epoch 100/1000: D Loss=-0.4864, G Loss (Comb)=-2.3885
Epoch 150/1000: D Loss=-0.5699, G Loss (Comb)=-2.3460
Epoch 200/1000: D Loss=-0.3056, G Loss (Comb)=-2.9143
Epoch 250/1000: D Loss=-0.3951, G Loss (Comb)=-2.9042
Epoch 300/1000: D Loss=-0.3307, G Loss (Comb)=-2.9748
Epoch 350/1000: D Loss=-0.3702, G Loss (Comb)=-2.9890
Epoch 400/1000: D Loss=-0.4297, G Loss (Comb)=-2.7612
Epoch 450/1000: D Loss=-0.5457, G Loss (Comb)=-2.6246
Epoch 500/1000: D Loss=-0.6140, G Loss (Comb)=-2.7143
Epoch 550/1000: D Loss=-0.7726, G Loss (Comb)=-2.4413
Epoch 600/1000: D Loss=-0.7836, G Loss (Comb)=-2.1903
Epoch 650/1000: D Loss=-0.8350, G Loss (Comb)=-1.8640
Epoch 700/1000: D Loss=-0.8835, G Loss (Comb)=-1.7991
Epoch 750/1000: D Loss=-1.0050, G Loss (Comb)=-1.9513
Epoch 800/1000: D Loss=-1.0020, G Loss (Comb)=-1.9858
Epoch 850/1000: D Loss=-1.0255, G Loss (Comb)=-1.9069
Epoch 900/1000: D Loss=-1.1432, G Loss (Comb)=-1.8710
Epoch 950/1000: D Loss=-1.2104, G Loss (Comb)=-1.9658
Epoch 999/1000: D Loss=-1.1685, G Loss (Comb)=-2.0117

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0422
    Run 4, Batch 2: ERP Similarity Score: -0.0462
    Run 4, Batch 3: ERP Similarity Score: -0.0394
    Run 4, Batch 4: ERP Similarity Score: -0.0439
    Run 4, Batch 5: ERP Similarity Score: -0.0408
    Run 4, Batch 6: ERP Similarity Score: -0.0437
    Run 4, Batch 7: ERP Similarity Score: -0.0414
    Run 4, Batch 8: ERP Similarity Score: -0.0442
    Run 4, Batch 9: ERP Similarity Score: -0.0401
    Run 4, Batch 10: ERP Similarity Score: -0.0416
    Run 4, Batch 11: ERP Similarity Score: -0.0394
    Run 4, Batch 12: ERP Similarity Score: -0.0432
    Run 4, Batch 13: ERP Similarity Score: -0.0462
    Run 4, Batch 14: ERP Similarity Score: -0.0423
    Run 4, Batch 15: ERP Similarity Score: -0.0404
    Run 4, Batch 16: ERP Similarity Score: -0.0438
    Run 4, Batch 17: ERP Similarity Score: -0.0391
    Run 4, Batch 18: ERP Similarity Score: -0.0406
    Run 4, Batch 19: ERP Similarity Score: -0.0421
    Run 4, Batch 20: ERP Similarity Score: -0.0430
    Run 4, Batch 21: ERP Similarity Score: -0.0403
    Run 4, Batch 22: ERP Similarity Score: -0.0438
    Run 4, Batch 23: ERP Similarity Score: -0.0394
    Run 4, Batch 24: ERP Similarity Score: -0.0423
    Run 4, Batch 25: ERP Similarity Score: -0.0367
    Run 4, Batch 26: ERP Similarity Score: -0.0444
    Run 4, Batch 27: ERP Similarity Score: -0.0379
    Run 4, Batch 28: ERP Similarity Score: -0.0444
    Run 4, Batch 29: ERP Similarity Score: -0.0446
    Run 4, Batch 30: ERP Similarity Score: -0.0426

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=60.4623, G Loss (Comb)=0.8118
Epoch 50/1000: D Loss=-1.1187, G Loss (Comb)=-0.5906
Epoch 100/1000: D Loss=-0.5432, G Loss (Comb)=-1.7511
Epoch 150/1000: D Loss=-0.4364, G Loss (Comb)=-2.2248
Epoch 200/1000: D Loss=-0.3459, G Loss (Comb)=-3.0563
Epoch 250/1000: D Loss=-0.2234, G Loss (Comb)=-2.9426
Epoch 300/1000: D Loss=-0.4197, G Loss (Comb)=-2.5952
Epoch 350/1000: D Loss=-0.4672, G Loss (Comb)=-3.0566
Epoch 400/1000: D Loss=-0.6261, G Loss (Comb)=-2.8460
Epoch 450/1000: D Loss=-0.6297, G Loss (Comb)=-2.6295
Epoch 500/1000: D Loss=-0.6782, G Loss (Comb)=-2.5880
Epoch 550/1000: D Loss=-0.6697, G Loss (Comb)=-2.4716
Epoch 600/1000: D Loss=-0.8297, G Loss (Comb)=-2.4825
Epoch 650/1000: D Loss=-0.7822, G Loss (Comb)=-2.5078
Epoch 700/1000: D Loss=-0.9200, G Loss (Comb)=-2.2274
Epoch 750/1000: D Loss=-0.9909, G Loss (Comb)=-2.1097
Epoch 800/1000: D Loss=-1.1652, G Loss (Comb)=-2.3845
Epoch 850/1000: D Loss=-1.0336, G Loss (Comb)=-2.3702
Epoch 900/1000: D Loss=-1.1001, G Loss (Comb)=-2.3015
Epoch 950/1000: D Loss=-1.2234, G Loss (Comb)=-2.3331
Epoch 999/1000: D Loss=-1.2446, G Loss (Comb)=-2.4803

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0406
    Run 5, Batch 2: ERP Similarity Score: -0.0449
    Run 5, Batch 3: ERP Similarity Score: -0.0434
    Run 5, Batch 4: ERP Similarity Score: -0.0494
    Run 5, Batch 5: ERP Similarity Score: -0.0443
    Run 5, Batch 6: ERP Similarity Score: -0.0384
    Run 5, Batch 7: ERP Similarity Score: -0.0420
    Run 5, Batch 8: ERP Similarity Score: -0.0465
    Run 5, Batch 9: ERP Similarity Score: -0.0440
    Run 5, Batch 10: ERP Similarity Score: -0.0416
    Run 5, Batch 11: ERP Similarity Score: -0.0456
    Run 5, Batch 12: ERP Similarity Score: -0.0386
    Run 5, Batch 13: ERP Similarity Score: -0.0417
    Run 5, Batch 14: ERP Similarity Score: -0.0472
    Run 5, Batch 15: ERP Similarity Score: -0.0414
    Run 5, Batch 16: ERP Similarity Score: -0.0432
    Run 5, Batch 17: ERP Similarity Score: -0.0381
    Run 5, Batch 18: ERP Similarity Score: -0.0444
    Run 5, Batch 19: ERP Similarity Score: -0.0473
    Run 5, Batch 20: ERP Similarity Score: -0.0406
    Run 5, Batch 21: ERP Similarity Score: -0.0403
    Run 5, Batch 22: ERP Similarity Score: -0.0457
    Run 5, Batch 23: ERP Similarity Score: -0.0410
    Run 5, Batch 24: ERP Similarity Score: -0.0463
    Run 5, Batch 25: ERP Similarity Score: -0.0431
    Run 5, Batch 26: ERP Similarity Score: -0.0409
    Run 5, Batch 27: ERP Similarity Score: -0.0403
    Run 5, Batch 28: ERP Similarity Score: -0.0461
    Run 5, Batch 29: ERP Similarity Score: -0.0503
    Run 5, Batch 30: ERP Similarity Score: -0.0483


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 4, Batch 25, Score: -0.0367
  Top 2: Run 1, Batch 10, Score: -0.0367
  Top 3: Run 4, Batch 27, Score: -0.0379
  Top 4: Run 5, Batch 17, Score: -0.0381
  Top 5: Run 5, Batch 6, Score: -0.0384
  Top 6: Run 5, Batch 12, Score: -0.0386
  Top 7: Run 1, Batch 27, Score: -0.0389
  Top 8: Run 4, Batch 17, Score: -0.0391
  Top 9: Run 2, Batch 24, Score: -0.0391
  Top 10: Run 4, Batch 11, Score: -0.0394

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 4, Batch 25, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 10, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 27, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 17, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 6, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 5, Batch 12, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 12, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 12, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 12, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 17, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 24, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 11, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 7 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 25, Ratio 0): Accuracy=100.00, ERP Score=-0.0367
  - Strategy (Run 4, Batch 25, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0367
  - Strategy (Run 1, Batch 10, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0367
  - Strategy (Run 4, Batch 27, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0379
  - Strategy (Run 2, Batch 24, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0391
  - Strategy (Run 4, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0394
  - Strategy (Run 4, Batch 11, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0394

Selected best strategy: Run 4, Batch 25, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 38.46%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 38.46%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H4_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H4_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
