Log for Subject Pair 3-4 from H6
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H6 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 262 clean Target and 521 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 558

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 36

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 66.67%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=63.3546, G Loss (Comb)=0.6683
Epoch 50/1000: D Loss=-1.4626, G Loss (Comb)=-1.0688
Epoch 100/1000: D Loss=-0.6053, G Loss (Comb)=-3.9513
Epoch 150/1000: D Loss=-0.4548, G Loss (Comb)=-3.6838
Epoch 200/1000: D Loss=-0.2447, G Loss (Comb)=-4.0643
Epoch 250/1000: D Loss=-0.4401, G Loss (Comb)=-3.9728
Epoch 300/1000: D Loss=-0.4781, G Loss (Comb)=-3.7975
Epoch 350/1000: D Loss=-0.3838, G Loss (Comb)=-3.6449
Epoch 400/1000: D Loss=-0.5409, G Loss (Comb)=-3.8084
Epoch 450/1000: D Loss=-0.6151, G Loss (Comb)=-3.0966
Epoch 500/1000: D Loss=-0.6249, G Loss (Comb)=-2.7182
Epoch 550/1000: D Loss=-0.8419, G Loss (Comb)=-2.5892
Epoch 600/1000: D Loss=-0.8317, G Loss (Comb)=-2.4222
Epoch 650/1000: D Loss=-0.8418, G Loss (Comb)=-2.6165
Epoch 700/1000: D Loss=-0.9498, G Loss (Comb)=-2.5612
Epoch 750/1000: D Loss=-1.0627, G Loss (Comb)=-2.5872
Epoch 800/1000: D Loss=-1.0169, G Loss (Comb)=-2.4291
Epoch 850/1000: D Loss=-1.1576, G Loss (Comb)=-2.4883
Epoch 900/1000: D Loss=-1.1240, G Loss (Comb)=-2.5527
Epoch 950/1000: D Loss=-1.2171, G Loss (Comb)=-2.3928
Epoch 999/1000: D Loss=-1.3121, G Loss (Comb)=-2.3024

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0443
    Run 1, Batch 2: ERP Similarity Score: -0.0413
    Run 1, Batch 3: ERP Similarity Score: -0.0417
    Run 1, Batch 4: ERP Similarity Score: -0.0441
    Run 1, Batch 5: ERP Similarity Score: -0.0440
    Run 1, Batch 6: ERP Similarity Score: -0.0433
    Run 1, Batch 7: ERP Similarity Score: -0.0417
    Run 1, Batch 8: ERP Similarity Score: -0.0405
    Run 1, Batch 9: ERP Similarity Score: -0.0458
    Run 1, Batch 10: ERP Similarity Score: -0.0450
    Run 1, Batch 11: ERP Similarity Score: -0.0496
    Run 1, Batch 12: ERP Similarity Score: -0.0458
    Run 1, Batch 13: ERP Similarity Score: -0.0404
    Run 1, Batch 14: ERP Similarity Score: -0.0450
    Run 1, Batch 15: ERP Similarity Score: -0.0442
    Run 1, Batch 16: ERP Similarity Score: -0.0462
    Run 1, Batch 17: ERP Similarity Score: -0.0411
    Run 1, Batch 18: ERP Similarity Score: -0.0457
    Run 1, Batch 19: ERP Similarity Score: -0.0462
    Run 1, Batch 20: ERP Similarity Score: -0.0516
    Run 1, Batch 21: ERP Similarity Score: -0.0407
    Run 1, Batch 22: ERP Similarity Score: -0.0478
    Run 1, Batch 23: ERP Similarity Score: -0.0413
    Run 1, Batch 24: ERP Similarity Score: -0.0426
    Run 1, Batch 25: ERP Similarity Score: -0.0440
    Run 1, Batch 26: ERP Similarity Score: -0.0420
    Run 1, Batch 27: ERP Similarity Score: -0.0401
    Run 1, Batch 28: ERP Similarity Score: -0.0448
    Run 1, Batch 29: ERP Similarity Score: -0.0462
    Run 1, Batch 30: ERP Similarity Score: -0.0453

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=68.6786, G Loss (Comb)=1.8376
Epoch 50/1000: D Loss=-1.1139, G Loss (Comb)=0.1781
Epoch 100/1000: D Loss=-0.6072, G Loss (Comb)=-1.6316
Epoch 150/1000: D Loss=-0.3210, G Loss (Comb)=-1.9649
Epoch 200/1000: D Loss=-0.4358, G Loss (Comb)=-1.7692
Epoch 250/1000: D Loss=-0.3748, G Loss (Comb)=-1.7302
Epoch 300/1000: D Loss=-0.4322, G Loss (Comb)=-1.7070
Epoch 350/1000: D Loss=-0.4055, G Loss (Comb)=-1.3032
Epoch 400/1000: D Loss=-0.6569, G Loss (Comb)=-1.3228
Epoch 450/1000: D Loss=-0.6567, G Loss (Comb)=-1.0182
Epoch 500/1000: D Loss=-0.6070, G Loss (Comb)=-1.3804
Epoch 550/1000: D Loss=-0.8138, G Loss (Comb)=-1.0880
Epoch 600/1000: D Loss=-0.6904, G Loss (Comb)=-0.8150
Epoch 650/1000: D Loss=-0.9421, G Loss (Comb)=-0.9169
Epoch 700/1000: D Loss=-1.0230, G Loss (Comb)=-0.7969
Epoch 750/1000: D Loss=-1.0241, G Loss (Comb)=-1.0675
Epoch 800/1000: D Loss=-1.1818, G Loss (Comb)=-1.1176
Epoch 850/1000: D Loss=-1.0945, G Loss (Comb)=-1.3228
Epoch 900/1000: D Loss=-1.1193, G Loss (Comb)=-1.5703
Epoch 950/1000: D Loss=-1.1319, G Loss (Comb)=-1.5844
Epoch 999/1000: D Loss=-1.2941, G Loss (Comb)=-1.4675

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0472
    Run 2, Batch 2: ERP Similarity Score: -0.0422
    Run 2, Batch 3: ERP Similarity Score: -0.0430
    Run 2, Batch 4: ERP Similarity Score: -0.0497
    Run 2, Batch 5: ERP Similarity Score: -0.0460
    Run 2, Batch 6: ERP Similarity Score: -0.0418
    Run 2, Batch 7: ERP Similarity Score: -0.0413
    Run 2, Batch 8: ERP Similarity Score: -0.0464
    Run 2, Batch 9: ERP Similarity Score: -0.0346
    Run 2, Batch 10: ERP Similarity Score: -0.0503
    Run 2, Batch 11: ERP Similarity Score: -0.0483
    Run 2, Batch 12: ERP Similarity Score: -0.0441
    Run 2, Batch 13: ERP Similarity Score: -0.0431
    Run 2, Batch 14: ERP Similarity Score: -0.0471
    Run 2, Batch 15: ERP Similarity Score: -0.0479
    Run 2, Batch 16: ERP Similarity Score: -0.0491
    Run 2, Batch 17: ERP Similarity Score: -0.0470
    Run 2, Batch 18: ERP Similarity Score: -0.0431
    Run 2, Batch 19: ERP Similarity Score: -0.0419
    Run 2, Batch 20: ERP Similarity Score: -0.0361
    Run 2, Batch 21: ERP Similarity Score: -0.0414
    Run 2, Batch 22: ERP Similarity Score: -0.0437
    Run 2, Batch 23: ERP Similarity Score: -0.0417
    Run 2, Batch 24: ERP Similarity Score: -0.0483
    Run 2, Batch 25: ERP Similarity Score: -0.0573
    Run 2, Batch 26: ERP Similarity Score: -0.0429
    Run 2, Batch 27: ERP Similarity Score: -0.0441
    Run 2, Batch 28: ERP Similarity Score: -0.0447
    Run 2, Batch 29: ERP Similarity Score: -0.0473
    Run 2, Batch 30: ERP Similarity Score: -0.0391

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=49.4370, G Loss (Comb)=3.1986
Epoch 50/1000: D Loss=-1.4529, G Loss (Comb)=-0.1421
Epoch 100/1000: D Loss=-0.6652, G Loss (Comb)=-2.4981
Epoch 150/1000: D Loss=-0.5532, G Loss (Comb)=-2.9221
Epoch 200/1000: D Loss=-0.2594, G Loss (Comb)=-2.9978
Epoch 250/1000: D Loss=-0.4554, G Loss (Comb)=-2.9512
Epoch 300/1000: D Loss=-0.4009, G Loss (Comb)=-2.5181
Epoch 350/1000: D Loss=-0.5121, G Loss (Comb)=-2.4456
Epoch 400/1000: D Loss=-0.5826, G Loss (Comb)=-1.9318
Epoch 450/1000: D Loss=-0.6840, G Loss (Comb)=-1.7579
Epoch 500/1000: D Loss=-0.6911, G Loss (Comb)=-1.5616
Epoch 550/1000: D Loss=-0.7674, G Loss (Comb)=-1.3770
Epoch 600/1000: D Loss=-0.9494, G Loss (Comb)=-1.3669
Epoch 650/1000: D Loss=-0.8986, G Loss (Comb)=-1.2623
Epoch 700/1000: D Loss=-0.9616, G Loss (Comb)=-1.2986
Epoch 750/1000: D Loss=-1.1194, G Loss (Comb)=-1.2686
Epoch 800/1000: D Loss=-1.0675, G Loss (Comb)=-1.4524
Epoch 850/1000: D Loss=-1.1095, G Loss (Comb)=-1.4112
Epoch 900/1000: D Loss=-1.1685, G Loss (Comb)=-1.3042
Epoch 950/1000: D Loss=-1.3384, G Loss (Comb)=-1.4007
Epoch 999/1000: D Loss=-1.2688, G Loss (Comb)=-1.4590

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0510
    Run 3, Batch 2: ERP Similarity Score: -0.0487
    Run 3, Batch 3: ERP Similarity Score: -0.0436
    Run 3, Batch 4: ERP Similarity Score: -0.0487
    Run 3, Batch 5: ERP Similarity Score: -0.0512
    Run 3, Batch 6: ERP Similarity Score: -0.0524
    Run 3, Batch 7: ERP Similarity Score: -0.0475
    Run 3, Batch 8: ERP Similarity Score: -0.0429
    Run 3, Batch 9: ERP Similarity Score: -0.0581
    Run 3, Batch 10: ERP Similarity Score: -0.0468
    Run 3, Batch 11: ERP Similarity Score: -0.0474
    Run 3, Batch 12: ERP Similarity Score: -0.0530
    Run 3, Batch 13: ERP Similarity Score: -0.0510
    Run 3, Batch 14: ERP Similarity Score: -0.0501
    Run 3, Batch 15: ERP Similarity Score: -0.0503
    Run 3, Batch 16: ERP Similarity Score: -0.0468
    Run 3, Batch 17: ERP Similarity Score: -0.0549
    Run 3, Batch 18: ERP Similarity Score: -0.0509
    Run 3, Batch 19: ERP Similarity Score: -0.0520
    Run 3, Batch 20: ERP Similarity Score: -0.0531
    Run 3, Batch 21: ERP Similarity Score: -0.0590
    Run 3, Batch 22: ERP Similarity Score: -0.0477
    Run 3, Batch 23: ERP Similarity Score: -0.0522
    Run 3, Batch 24: ERP Similarity Score: -0.0471
    Run 3, Batch 25: ERP Similarity Score: -0.0425
    Run 3, Batch 26: ERP Similarity Score: -0.0469
    Run 3, Batch 27: ERP Similarity Score: -0.0446
    Run 3, Batch 28: ERP Similarity Score: -0.0421
    Run 3, Batch 29: ERP Similarity Score: -0.0446
    Run 3, Batch 30: ERP Similarity Score: -0.0433

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=68.3709, G Loss (Comb)=1.5691
Epoch 50/1000: D Loss=-1.2810, G Loss (Comb)=-1.1041
Epoch 100/1000: D Loss=-0.7033, G Loss (Comb)=-3.9388
Epoch 150/1000: D Loss=-0.5312, G Loss (Comb)=-3.7495
Epoch 200/1000: D Loss=-0.2732, G Loss (Comb)=-4.0459
Epoch 250/1000: D Loss=-0.4803, G Loss (Comb)=-4.0442
Epoch 300/1000: D Loss=-0.4553, G Loss (Comb)=-3.8002
Epoch 350/1000: D Loss=-0.4133, G Loss (Comb)=-3.0755
Epoch 400/1000: D Loss=-0.4653, G Loss (Comb)=-2.9842
Epoch 450/1000: D Loss=-0.5640, G Loss (Comb)=-2.8974
Epoch 500/1000: D Loss=-0.7505, G Loss (Comb)=-2.5352
Epoch 550/1000: D Loss=-0.7943, G Loss (Comb)=-2.2824
Epoch 600/1000: D Loss=-0.7360, G Loss (Comb)=-2.7495
Epoch 650/1000: D Loss=-0.8627, G Loss (Comb)=-2.5081
Epoch 700/1000: D Loss=-0.9305, G Loss (Comb)=-2.5455
Epoch 750/1000: D Loss=-1.0589, G Loss (Comb)=-2.4682
Epoch 800/1000: D Loss=-1.0462, G Loss (Comb)=-2.9057
Epoch 850/1000: D Loss=-1.1101, G Loss (Comb)=-2.8977
Epoch 900/1000: D Loss=-1.1270, G Loss (Comb)=-2.6898
Epoch 950/1000: D Loss=-1.1867, G Loss (Comb)=-2.7398
Epoch 999/1000: D Loss=-1.2866, G Loss (Comb)=-2.7943

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0453
    Run 4, Batch 2: ERP Similarity Score: -0.0472
    Run 4, Batch 3: ERP Similarity Score: -0.0456
    Run 4, Batch 4: ERP Similarity Score: -0.0369
    Run 4, Batch 5: ERP Similarity Score: -0.0431
    Run 4, Batch 6: ERP Similarity Score: -0.0491
    Run 4, Batch 7: ERP Similarity Score: -0.0459
    Run 4, Batch 8: ERP Similarity Score: -0.0549
    Run 4, Batch 9: ERP Similarity Score: -0.0453
    Run 4, Batch 10: ERP Similarity Score: -0.0524
    Run 4, Batch 11: ERP Similarity Score: -0.0426
    Run 4, Batch 12: ERP Similarity Score: -0.0444
    Run 4, Batch 13: ERP Similarity Score: -0.0429
    Run 4, Batch 14: ERP Similarity Score: -0.0454
    Run 4, Batch 15: ERP Similarity Score: -0.0444
    Run 4, Batch 16: ERP Similarity Score: -0.0358
    Run 4, Batch 17: ERP Similarity Score: -0.0444
    Run 4, Batch 18: ERP Similarity Score: -0.0382
    Run 4, Batch 19: ERP Similarity Score: -0.0500
    Run 4, Batch 20: ERP Similarity Score: -0.0420
    Run 4, Batch 21: ERP Similarity Score: -0.0461
    Run 4, Batch 22: ERP Similarity Score: -0.0415
    Run 4, Batch 23: ERP Similarity Score: -0.0479
    Run 4, Batch 24: ERP Similarity Score: -0.0442
    Run 4, Batch 25: ERP Similarity Score: -0.0389
    Run 4, Batch 26: ERP Similarity Score: -0.0511
    Run 4, Batch 27: ERP Similarity Score: -0.0437
    Run 4, Batch 28: ERP Similarity Score: -0.0459
    Run 4, Batch 29: ERP Similarity Score: -0.0367
    Run 4, Batch 30: ERP Similarity Score: -0.0425

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=59.3100, G Loss (Comb)=0.6241
Epoch 50/1000: D Loss=-1.2778, G Loss (Comb)=-1.0543
Epoch 100/1000: D Loss=-0.6240, G Loss (Comb)=-2.9075
Epoch 150/1000: D Loss=-0.6087, G Loss (Comb)=-3.0876
Epoch 200/1000: D Loss=-0.3246, G Loss (Comb)=-3.6330
Epoch 250/1000: D Loss=-0.4543, G Loss (Comb)=-3.2163
Epoch 300/1000: D Loss=-0.4755, G Loss (Comb)=-3.4028
Epoch 350/1000: D Loss=-0.4896, G Loss (Comb)=-2.8303
Epoch 400/1000: D Loss=-0.5524, G Loss (Comb)=-2.3155
Epoch 450/1000: D Loss=-0.6340, G Loss (Comb)=-2.3616
Epoch 500/1000: D Loss=-0.7367, G Loss (Comb)=-1.6768
Epoch 550/1000: D Loss=-0.7543, G Loss (Comb)=-1.5466
Epoch 600/1000: D Loss=-0.8471, G Loss (Comb)=-1.3596
Epoch 650/1000: D Loss=-0.8958, G Loss (Comb)=-1.4812
Epoch 700/1000: D Loss=-0.9739, G Loss (Comb)=-1.4630
Epoch 750/1000: D Loss=-0.9232, G Loss (Comb)=-1.4847
Epoch 800/1000: D Loss=-1.0531, G Loss (Comb)=-1.4062
Epoch 850/1000: D Loss=-1.1185, G Loss (Comb)=-1.4123
Epoch 900/1000: D Loss=-1.1625, G Loss (Comb)=-1.5109
Epoch 950/1000: D Loss=-1.1510, G Loss (Comb)=-1.5524
Epoch 999/1000: D Loss=-1.1871, G Loss (Comb)=-1.5677

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0429
    Run 5, Batch 2: ERP Similarity Score: -0.0476
    Run 5, Batch 3: ERP Similarity Score: -0.0417
    Run 5, Batch 4: ERP Similarity Score: -0.0489
    Run 5, Batch 5: ERP Similarity Score: -0.0449
    Run 5, Batch 6: ERP Similarity Score: -0.0493
    Run 5, Batch 7: ERP Similarity Score: -0.0564
    Run 5, Batch 8: ERP Similarity Score: -0.0430
    Run 5, Batch 9: ERP Similarity Score: -0.0409
    Run 5, Batch 10: ERP Similarity Score: -0.0468
    Run 5, Batch 11: ERP Similarity Score: -0.0405
    Run 5, Batch 12: ERP Similarity Score: -0.0508
    Run 5, Batch 13: ERP Similarity Score: -0.0492
    Run 5, Batch 14: ERP Similarity Score: -0.0436
    Run 5, Batch 15: ERP Similarity Score: -0.0418
    Run 5, Batch 16: ERP Similarity Score: -0.0475
    Run 5, Batch 17: ERP Similarity Score: -0.0493
    Run 5, Batch 18: ERP Similarity Score: -0.0460
    Run 5, Batch 19: ERP Similarity Score: -0.0436
    Run 5, Batch 20: ERP Similarity Score: -0.0461
    Run 5, Batch 21: ERP Similarity Score: -0.0459
    Run 5, Batch 22: ERP Similarity Score: -0.0404
    Run 5, Batch 23: ERP Similarity Score: -0.0406
    Run 5, Batch 24: ERP Similarity Score: -0.0442
    Run 5, Batch 25: ERP Similarity Score: -0.0504
    Run 5, Batch 26: ERP Similarity Score: -0.0427
    Run 5, Batch 27: ERP Similarity Score: -0.0462
    Run 5, Batch 28: ERP Similarity Score: -0.0592
    Run 5, Batch 29: ERP Similarity Score: -0.0467
    Run 5, Batch 30: ERP Similarity Score: -0.0517


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 2, Batch 9, Score: -0.0346
  Top 2: Run 4, Batch 16, Score: -0.0358
  Top 3: Run 2, Batch 20, Score: -0.0361
  Top 4: Run 4, Batch 29, Score: -0.0367
  Top 5: Run 4, Batch 4, Score: -0.0369
  Top 6: Run 4, Batch 18, Score: -0.0382
  Top 7: Run 4, Batch 25, Score: -0.0389
  Top 8: Run 2, Batch 30, Score: -0.0391
  Top 9: Run 1, Batch 27, Score: -0.0401
  Top 10: Run 5, Batch 22, Score: -0.0404

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 2, Batch 9, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 16, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 20, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 2, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 29, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 4, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 18, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 0.00%
    Run 4, Batch 25, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 30, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 27, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 22, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 12 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 2, Batch 9, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0346
  - Strategy (Run 4, Batch 16, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0358
  - Strategy (Run 4, Batch 16, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0358
  - Strategy (Run 4, Batch 29, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0367
  - Strategy (Run 4, Batch 4, Ratio 0): Accuracy=100.00, ERP Score=-0.0369
  - Strategy (Run 4, Batch 4, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0369
  - Strategy (Run 4, Batch 4, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0369
  - Strategy (Run 4, Batch 25, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0389
  - Strategy (Run 4, Batch 25, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0389
  - Strategy (Run 4, Batch 25, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0389
  - Strategy (Run 2, Batch 30, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0391
  - Strategy (Run 5, Batch 22, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0404

Selected best strategy: Run 2, Batch 9, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 55.56%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 80.56%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H6_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H6_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
