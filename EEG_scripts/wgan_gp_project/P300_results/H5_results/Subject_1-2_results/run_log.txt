Log for Subject Pair 1-2 from H5
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H5 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 265 clean Target and 524 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 564

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 36

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 86.11%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=73.6210, G Loss (Comb)=2.1427
Epoch 50/1000: D Loss=-1.3600, G Loss (Comb)=0.5217
Epoch 100/1000: D Loss=-0.4623, G Loss (Comb)=-1.9339
Epoch 150/1000: D Loss=-0.3803, G Loss (Comb)=-1.9852
Epoch 200/1000: D Loss=-0.4479, G Loss (Comb)=-1.9676
Epoch 250/1000: D Loss=-0.5780, G Loss (Comb)=-2.0432
Epoch 300/1000: D Loss=-0.3781, G Loss (Comb)=-2.3311
Epoch 350/1000: D Loss=-0.4835, G Loss (Comb)=-2.2523
Epoch 400/1000: D Loss=-0.5321, G Loss (Comb)=-2.2447
Epoch 450/1000: D Loss=-0.5736, G Loss (Comb)=-2.2812
Epoch 500/1000: D Loss=-0.6487, G Loss (Comb)=-2.1544
Epoch 550/1000: D Loss=-0.8062, G Loss (Comb)=-1.8720
Epoch 600/1000: D Loss=-0.7298, G Loss (Comb)=-1.9218
Epoch 650/1000: D Loss=-0.8250, G Loss (Comb)=-1.7342
Epoch 700/1000: D Loss=-0.7567, G Loss (Comb)=-1.5422
Epoch 750/1000: D Loss=-0.8438, G Loss (Comb)=-1.3345
Epoch 800/1000: D Loss=-0.8743, G Loss (Comb)=-1.3343
Epoch 850/1000: D Loss=-0.9577, G Loss (Comb)=-1.4501
Epoch 900/1000: D Loss=-0.9671, G Loss (Comb)=-1.2173
Epoch 950/1000: D Loss=-0.9935, G Loss (Comb)=-1.0609
Epoch 999/1000: D Loss=-0.9977, G Loss (Comb)=-1.1461

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0336
    Run 1, Batch 2: ERP Similarity Score: -0.0350
    Run 1, Batch 3: ERP Similarity Score: -0.0344
    Run 1, Batch 4: ERP Similarity Score: -0.0341
    Run 1, Batch 5: ERP Similarity Score: -0.0440
    Run 1, Batch 6: ERP Similarity Score: -0.0407
    Run 1, Batch 7: ERP Similarity Score: -0.0422
    Run 1, Batch 8: ERP Similarity Score: -0.0365
    Run 1, Batch 9: ERP Similarity Score: -0.0368
    Run 1, Batch 10: ERP Similarity Score: -0.0410
    Run 1, Batch 11: ERP Similarity Score: -0.0368
    Run 1, Batch 12: ERP Similarity Score: -0.0345
    Run 1, Batch 13: ERP Similarity Score: -0.0340
    Run 1, Batch 14: ERP Similarity Score: -0.0368
    Run 1, Batch 15: ERP Similarity Score: -0.0367
    Run 1, Batch 16: ERP Similarity Score: -0.0354
    Run 1, Batch 17: ERP Similarity Score: -0.0378
    Run 1, Batch 18: ERP Similarity Score: -0.0403
    Run 1, Batch 19: ERP Similarity Score: -0.0361
    Run 1, Batch 20: ERP Similarity Score: -0.0368
    Run 1, Batch 21: ERP Similarity Score: -0.0421
    Run 1, Batch 22: ERP Similarity Score: -0.0385
    Run 1, Batch 23: ERP Similarity Score: -0.0375
    Run 1, Batch 24: ERP Similarity Score: -0.0386
    Run 1, Batch 25: ERP Similarity Score: -0.0358
    Run 1, Batch 26: ERP Similarity Score: -0.0411
    Run 1, Batch 27: ERP Similarity Score: -0.0329
    Run 1, Batch 28: ERP Similarity Score: -0.0373
    Run 1, Batch 29: ERP Similarity Score: -0.0445
    Run 1, Batch 30: ERP Similarity Score: -0.0335

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=75.9286, G Loss (Comb)=1.3329
Epoch 50/1000: D Loss=-1.3893, G Loss (Comb)=-1.1683
Epoch 100/1000: D Loss=-0.5423, G Loss (Comb)=-3.2862
Epoch 150/1000: D Loss=-0.6029, G Loss (Comb)=-3.2945
Epoch 200/1000: D Loss=-0.3588, G Loss (Comb)=-3.0467
Epoch 250/1000: D Loss=-0.6554, G Loss (Comb)=-2.7625
Epoch 300/1000: D Loss=-0.3737, G Loss (Comb)=-2.9880
Epoch 350/1000: D Loss=-0.6032, G Loss (Comb)=-2.6398
Epoch 400/1000: D Loss=-0.5960, G Loss (Comb)=-2.3326
Epoch 450/1000: D Loss=-0.5847, G Loss (Comb)=-2.4122
Epoch 500/1000: D Loss=-0.6746, G Loss (Comb)=-2.1528
Epoch 550/1000: D Loss=-0.6922, G Loss (Comb)=-1.9784
Epoch 600/1000: D Loss=-0.7317, G Loss (Comb)=-2.2000
Epoch 650/1000: D Loss=-0.8475, G Loss (Comb)=-1.9782
Epoch 700/1000: D Loss=-0.8284, G Loss (Comb)=-1.9762
Epoch 750/1000: D Loss=-0.7917, G Loss (Comb)=-1.8568
Epoch 800/1000: D Loss=-0.9062, G Loss (Comb)=-2.0204
Epoch 850/1000: D Loss=-0.9630, G Loss (Comb)=-1.8155
Epoch 900/1000: D Loss=-0.9633, G Loss (Comb)=-1.7626
Epoch 950/1000: D Loss=-0.9432, G Loss (Comb)=-1.7868
Epoch 999/1000: D Loss=-1.0619, G Loss (Comb)=-1.6833

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0346
    Run 2, Batch 2: ERP Similarity Score: -0.0369
    Run 2, Batch 3: ERP Similarity Score: -0.0353
    Run 2, Batch 4: ERP Similarity Score: -0.0330
    Run 2, Batch 5: ERP Similarity Score: -0.0309
    Run 2, Batch 6: ERP Similarity Score: -0.0352
    Run 2, Batch 7: ERP Similarity Score: -0.0343
    Run 2, Batch 8: ERP Similarity Score: -0.0350
    Run 2, Batch 9: ERP Similarity Score: -0.0376
    Run 2, Batch 10: ERP Similarity Score: -0.0334
    Run 2, Batch 11: ERP Similarity Score: -0.0315
    Run 2, Batch 12: ERP Similarity Score: -0.0352
    Run 2, Batch 13: ERP Similarity Score: -0.0337
    Run 2, Batch 14: ERP Similarity Score: -0.0362
    Run 2, Batch 15: ERP Similarity Score: -0.0362
    Run 2, Batch 16: ERP Similarity Score: -0.0358
    Run 2, Batch 17: ERP Similarity Score: -0.0334
    Run 2, Batch 18: ERP Similarity Score: -0.0303
    Run 2, Batch 19: ERP Similarity Score: -0.0399
    Run 2, Batch 20: ERP Similarity Score: -0.0348
    Run 2, Batch 21: ERP Similarity Score: -0.0342
    Run 2, Batch 22: ERP Similarity Score: -0.0327
    Run 2, Batch 23: ERP Similarity Score: -0.0367
    Run 2, Batch 24: ERP Similarity Score: -0.0374
    Run 2, Batch 25: ERP Similarity Score: -0.0321
    Run 2, Batch 26: ERP Similarity Score: -0.0348
    Run 2, Batch 27: ERP Similarity Score: -0.0370
    Run 2, Batch 28: ERP Similarity Score: -0.0337
    Run 2, Batch 29: ERP Similarity Score: -0.0377
    Run 2, Batch 30: ERP Similarity Score: -0.0364

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=84.1859, G Loss (Comb)=1.0536
Epoch 50/1000: D Loss=-1.5113, G Loss (Comb)=-0.4949
Epoch 100/1000: D Loss=-0.3543, G Loss (Comb)=-2.8036
Epoch 150/1000: D Loss=-0.4921, G Loss (Comb)=-2.3690
Epoch 200/1000: D Loss=-0.5100, G Loss (Comb)=-2.1802
Epoch 250/1000: D Loss=-0.5043, G Loss (Comb)=-2.4158
Epoch 300/1000: D Loss=-0.4805, G Loss (Comb)=-2.5737
Epoch 350/1000: D Loss=-0.4258, G Loss (Comb)=-2.7454
Epoch 400/1000: D Loss=-0.5479, G Loss (Comb)=-2.6169
Epoch 450/1000: D Loss=-0.5538, G Loss (Comb)=-2.4310
Epoch 500/1000: D Loss=-0.6898, G Loss (Comb)=-2.1473
Epoch 550/1000: D Loss=-0.6965, G Loss (Comb)=-1.9788
Epoch 600/1000: D Loss=-0.7296, G Loss (Comb)=-2.0187
Epoch 650/1000: D Loss=-0.8077, G Loss (Comb)=-2.0023
Epoch 700/1000: D Loss=-0.9040, G Loss (Comb)=-1.8108
Epoch 750/1000: D Loss=-0.8960, G Loss (Comb)=-1.4963
Epoch 800/1000: D Loss=-0.8590, G Loss (Comb)=-1.5116
Epoch 850/1000: D Loss=-0.9621, G Loss (Comb)=-1.4486
Epoch 900/1000: D Loss=-1.0359, G Loss (Comb)=-1.4751
Epoch 950/1000: D Loss=-1.0327, G Loss (Comb)=-1.3591
Epoch 999/1000: D Loss=-1.0692, G Loss (Comb)=-1.3624

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0369
    Run 3, Batch 2: ERP Similarity Score: -0.0382
    Run 3, Batch 3: ERP Similarity Score: -0.0354
    Run 3, Batch 4: ERP Similarity Score: -0.0371
    Run 3, Batch 5: ERP Similarity Score: -0.0359
    Run 3, Batch 6: ERP Similarity Score: -0.0315
    Run 3, Batch 7: ERP Similarity Score: -0.0329
    Run 3, Batch 8: ERP Similarity Score: -0.0413
    Run 3, Batch 9: ERP Similarity Score: -0.0281
    Run 3, Batch 10: ERP Similarity Score: -0.0326
    Run 3, Batch 11: ERP Similarity Score: -0.0394
    Run 3, Batch 12: ERP Similarity Score: -0.0388
    Run 3, Batch 13: ERP Similarity Score: -0.0368
    Run 3, Batch 14: ERP Similarity Score: -0.0372
    Run 3, Batch 15: ERP Similarity Score: -0.0357
    Run 3, Batch 16: ERP Similarity Score: -0.0376
    Run 3, Batch 17: ERP Similarity Score: -0.0324
    Run 3, Batch 18: ERP Similarity Score: -0.0361
    Run 3, Batch 19: ERP Similarity Score: -0.0381
    Run 3, Batch 20: ERP Similarity Score: -0.0401
    Run 3, Batch 21: ERP Similarity Score: -0.0357
    Run 3, Batch 22: ERP Similarity Score: -0.0391
    Run 3, Batch 23: ERP Similarity Score: -0.0368
    Run 3, Batch 24: ERP Similarity Score: -0.0327
    Run 3, Batch 25: ERP Similarity Score: -0.0324
    Run 3, Batch 26: ERP Similarity Score: -0.0367
    Run 3, Batch 27: ERP Similarity Score: -0.0381
    Run 3, Batch 28: ERP Similarity Score: -0.0415
    Run 3, Batch 29: ERP Similarity Score: -0.0367
    Run 3, Batch 30: ERP Similarity Score: -0.0329

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=95.1364, G Loss (Comb)=1.0592
Epoch 50/1000: D Loss=-1.5019, G Loss (Comb)=-1.4765
Epoch 100/1000: D Loss=-0.5258, G Loss (Comb)=-5.1564
Epoch 150/1000: D Loss=-0.5043, G Loss (Comb)=-4.8670
Epoch 200/1000: D Loss=-0.4851, G Loss (Comb)=-4.7972
Epoch 250/1000: D Loss=-0.5354, G Loss (Comb)=-5.0095
Epoch 300/1000: D Loss=-0.5011, G Loss (Comb)=-4.5938
Epoch 350/1000: D Loss=-0.5542, G Loss (Comb)=-4.5199
Epoch 400/1000: D Loss=-0.5280, G Loss (Comb)=-4.6727
Epoch 450/1000: D Loss=-0.6600, G Loss (Comb)=-4.2034
Epoch 500/1000: D Loss=-0.6319, G Loss (Comb)=-3.7745
Epoch 550/1000: D Loss=-0.7859, G Loss (Comb)=-3.5254
Epoch 600/1000: D Loss=-0.7525, G Loss (Comb)=-3.5784
Epoch 650/1000: D Loss=-0.8222, G Loss (Comb)=-3.4269
Epoch 700/1000: D Loss=-0.7989, G Loss (Comb)=-3.3510
Epoch 750/1000: D Loss=-0.9163, G Loss (Comb)=-3.0827
Epoch 800/1000: D Loss=-0.9912, G Loss (Comb)=-2.9507
Epoch 850/1000: D Loss=-0.8894, G Loss (Comb)=-2.9881
Epoch 900/1000: D Loss=-0.9459, G Loss (Comb)=-2.8057
Epoch 950/1000: D Loss=-1.0240, G Loss (Comb)=-2.5357
Epoch 999/1000: D Loss=-1.0404, G Loss (Comb)=-2.4219

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0493
    Run 4, Batch 2: ERP Similarity Score: -0.0391
    Run 4, Batch 3: ERP Similarity Score: -0.0480
    Run 4, Batch 4: ERP Similarity Score: -0.0391
    Run 4, Batch 5: ERP Similarity Score: -0.0452
    Run 4, Batch 6: ERP Similarity Score: -0.0459
    Run 4, Batch 7: ERP Similarity Score: -0.0413
    Run 4, Batch 8: ERP Similarity Score: -0.0439
    Run 4, Batch 9: ERP Similarity Score: -0.0482
    Run 4, Batch 10: ERP Similarity Score: -0.0450
    Run 4, Batch 11: ERP Similarity Score: -0.0403
    Run 4, Batch 12: ERP Similarity Score: -0.0446
    Run 4, Batch 13: ERP Similarity Score: -0.0507
    Run 4, Batch 14: ERP Similarity Score: -0.0511
    Run 4, Batch 15: ERP Similarity Score: -0.0462
    Run 4, Batch 16: ERP Similarity Score: -0.0412
    Run 4, Batch 17: ERP Similarity Score: -0.0513
    Run 4, Batch 18: ERP Similarity Score: -0.0461
    Run 4, Batch 19: ERP Similarity Score: -0.0441
    Run 4, Batch 20: ERP Similarity Score: -0.0433
    Run 4, Batch 21: ERP Similarity Score: -0.0403
    Run 4, Batch 22: ERP Similarity Score: -0.0390
    Run 4, Batch 23: ERP Similarity Score: -0.0406
    Run 4, Batch 24: ERP Similarity Score: -0.0386
    Run 4, Batch 25: ERP Similarity Score: -0.0486
    Run 4, Batch 26: ERP Similarity Score: -0.0422
    Run 4, Batch 27: ERP Similarity Score: -0.0437
    Run 4, Batch 28: ERP Similarity Score: -0.0411
    Run 4, Batch 29: ERP Similarity Score: -0.0484
    Run 4, Batch 30: ERP Similarity Score: -0.0435

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=96.3429, G Loss (Comb)=0.6000
Epoch 50/1000: D Loss=-1.3763, G Loss (Comb)=-1.3657
Epoch 100/1000: D Loss=-0.5002, G Loss (Comb)=-3.8139
Epoch 150/1000: D Loss=-0.4960, G Loss (Comb)=-3.8225
Epoch 200/1000: D Loss=-0.5208, G Loss (Comb)=-4.0295
Epoch 250/1000: D Loss=-0.5483, G Loss (Comb)=-4.2705
Epoch 300/1000: D Loss=-0.5482, G Loss (Comb)=-4.1526
Epoch 350/1000: D Loss=-0.5262, G Loss (Comb)=-4.1682
Epoch 400/1000: D Loss=-0.5673, G Loss (Comb)=-4.0951
Epoch 450/1000: D Loss=-0.5756, G Loss (Comb)=-3.7986
Epoch 500/1000: D Loss=-0.6855, G Loss (Comb)=-3.5092
Epoch 550/1000: D Loss=-0.7145, G Loss (Comb)=-3.4447
Epoch 600/1000: D Loss=-0.7411, G Loss (Comb)=-3.2718
Epoch 650/1000: D Loss=-0.7753, G Loss (Comb)=-3.2385
Epoch 700/1000: D Loss=-0.8326, G Loss (Comb)=-3.0994
Epoch 750/1000: D Loss=-0.8903, G Loss (Comb)=-3.0710
Epoch 800/1000: D Loss=-0.9306, G Loss (Comb)=-2.9819
Epoch 850/1000: D Loss=-0.9928, G Loss (Comb)=-2.9265
Epoch 900/1000: D Loss=-0.9813, G Loss (Comb)=-2.8569
Epoch 950/1000: D Loss=-1.0388, G Loss (Comb)=-2.9056
Epoch 999/1000: D Loss=-1.0394, G Loss (Comb)=-2.8387

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0356
    Run 5, Batch 2: ERP Similarity Score: -0.0367
    Run 5, Batch 3: ERP Similarity Score: -0.0349
    Run 5, Batch 4: ERP Similarity Score: -0.0372
    Run 5, Batch 5: ERP Similarity Score: -0.0329
    Run 5, Batch 6: ERP Similarity Score: -0.0363
    Run 5, Batch 7: ERP Similarity Score: -0.0337
    Run 5, Batch 8: ERP Similarity Score: -0.0357
    Run 5, Batch 9: ERP Similarity Score: -0.0345
    Run 5, Batch 10: ERP Similarity Score: -0.0421
    Run 5, Batch 11: ERP Similarity Score: -0.0423
    Run 5, Batch 12: ERP Similarity Score: -0.0363
    Run 5, Batch 13: ERP Similarity Score: -0.0364
    Run 5, Batch 14: ERP Similarity Score: -0.0349
    Run 5, Batch 15: ERP Similarity Score: -0.0350
    Run 5, Batch 16: ERP Similarity Score: -0.0351
    Run 5, Batch 17: ERP Similarity Score: -0.0373
    Run 5, Batch 18: ERP Similarity Score: -0.0388
    Run 5, Batch 19: ERP Similarity Score: -0.0402
    Run 5, Batch 20: ERP Similarity Score: -0.0377
    Run 5, Batch 21: ERP Similarity Score: -0.0336
    Run 5, Batch 22: ERP Similarity Score: -0.0328
    Run 5, Batch 23: ERP Similarity Score: -0.0383
    Run 5, Batch 24: ERP Similarity Score: -0.0336
    Run 5, Batch 25: ERP Similarity Score: -0.0381
    Run 5, Batch 26: ERP Similarity Score: -0.0380
    Run 5, Batch 27: ERP Similarity Score: -0.0333
    Run 5, Batch 28: ERP Similarity Score: -0.0359
    Run 5, Batch 29: ERP Similarity Score: -0.0342
    Run 5, Batch 30: ERP Similarity Score: -0.0336


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 9, Score: -0.0281
  Top 2: Run 2, Batch 18, Score: -0.0303
  Top 3: Run 2, Batch 5, Score: -0.0309
  Top 4: Run 3, Batch 6, Score: -0.0315
  Top 5: Run 2, Batch 11, Score: -0.0315
  Top 6: Run 2, Batch 25, Score: -0.0321
  Top 7: Run 3, Batch 17, Score: -0.0324
  Top 8: Run 3, Batch 25, Score: -0.0324
  Top 9: Run 3, Batch 10, Score: -0.0326
  Top 10: Run 2, Batch 22, Score: -0.0327

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 9, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 3, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 18, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 5, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 2, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 2, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 6, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 2, Batch 11, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 25, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 10, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 3, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 3, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 22, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 2, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 0.00%

Found 11 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 9, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0281
  - Strategy (Run 3, Batch 9, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0281
  - Strategy (Run 2, Batch 18, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0303
  - Strategy (Run 2, Batch 18, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0303
  - Strategy (Run 2, Batch 5, Ratio 0): Accuracy=100.00, ERP Score=-0.0309
  - Strategy (Run 2, Batch 5, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0309
  - Strategy (Run 3, Batch 6, Ratio 0): Accuracy=100.00, ERP Score=-0.0315
  - Strategy (Run 3, Batch 17, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0324
  - Strategy (Run 3, Batch 25, Ratio 0): Accuracy=100.00, ERP Score=-0.0324
  - Strategy (Run 3, Batch 25, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0324
  - Strategy (Run 3, Batch 25, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0324

Selected best strategy: Run 3, Batch 9, Strategy: Augmented (50%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 61.11%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (50%), Val Acc: 100.00%) -> REAL test accuracy: 75.00%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H5_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H5_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
