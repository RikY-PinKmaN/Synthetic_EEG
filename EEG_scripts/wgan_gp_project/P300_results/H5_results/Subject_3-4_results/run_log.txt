Log for Subject Pair 3-4 from H5
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H5 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 259 clean Target and 509 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 543

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 35

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 60.00%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=97.2964, G Loss (Comb)=1.0554
Epoch 50/1000: D Loss=-1.7196, G Loss (Comb)=0.0762
Epoch 100/1000: D Loss=-0.4391, G Loss (Comb)=-2.3418
Epoch 150/1000: D Loss=-0.3534, G Loss (Comb)=-2.6773
Epoch 200/1000: D Loss=-0.4066, G Loss (Comb)=-1.6291
Epoch 250/1000: D Loss=-0.4188, G Loss (Comb)=-1.6056
Epoch 300/1000: D Loss=-0.2539, G Loss (Comb)=-1.4861
Epoch 350/1000: D Loss=-0.3140, G Loss (Comb)=-1.8339
Epoch 400/1000: D Loss=-0.2987, G Loss (Comb)=-1.7019
Epoch 450/1000: D Loss=-0.4480, G Loss (Comb)=-1.7685
Epoch 500/1000: D Loss=-0.3508, G Loss (Comb)=-1.5006
Epoch 550/1000: D Loss=-0.3615, G Loss (Comb)=-1.9669
Epoch 600/1000: D Loss=-0.5231, G Loss (Comb)=-1.9913
Epoch 650/1000: D Loss=-0.5466, G Loss (Comb)=-2.1995
Epoch 700/1000: D Loss=-0.4959, G Loss (Comb)=-2.5288
Epoch 750/1000: D Loss=-0.5115, G Loss (Comb)=-2.4583
Epoch 800/1000: D Loss=-0.5842, G Loss (Comb)=-2.4310
Epoch 850/1000: D Loss=-0.6184, G Loss (Comb)=-2.6837
Epoch 900/1000: D Loss=-0.6904, G Loss (Comb)=-2.6429
Epoch 950/1000: D Loss=-0.6920, G Loss (Comb)=-2.6262
Epoch 999/1000: D Loss=-0.8041, G Loss (Comb)=-2.4602

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0295
    Run 1, Batch 2: ERP Similarity Score: -0.0352
    Run 1, Batch 3: ERP Similarity Score: -0.0357
    Run 1, Batch 4: ERP Similarity Score: -0.0350
    Run 1, Batch 5: ERP Similarity Score: -0.0296
    Run 1, Batch 6: ERP Similarity Score: -0.0348
    Run 1, Batch 7: ERP Similarity Score: -0.0333
    Run 1, Batch 8: ERP Similarity Score: -0.0337
    Run 1, Batch 9: ERP Similarity Score: -0.0361
    Run 1, Batch 10: ERP Similarity Score: -0.0440
    Run 1, Batch 11: ERP Similarity Score: -0.0372
    Run 1, Batch 12: ERP Similarity Score: -0.0322
    Run 1, Batch 13: ERP Similarity Score: -0.0330
    Run 1, Batch 14: ERP Similarity Score: -0.0386
    Run 1, Batch 15: ERP Similarity Score: -0.0305
    Run 1, Batch 16: ERP Similarity Score: -0.0348
    Run 1, Batch 17: ERP Similarity Score: -0.0365
    Run 1, Batch 18: ERP Similarity Score: -0.0347
    Run 1, Batch 19: ERP Similarity Score: -0.0389
    Run 1, Batch 20: ERP Similarity Score: -0.0397
    Run 1, Batch 21: ERP Similarity Score: -0.0354
    Run 1, Batch 22: ERP Similarity Score: -0.0351
    Run 1, Batch 23: ERP Similarity Score: -0.0269
    Run 1, Batch 24: ERP Similarity Score: -0.0312
    Run 1, Batch 25: ERP Similarity Score: -0.0323
    Run 1, Batch 26: ERP Similarity Score: -0.0353
    Run 1, Batch 27: ERP Similarity Score: -0.0340
    Run 1, Batch 28: ERP Similarity Score: -0.0319
    Run 1, Batch 29: ERP Similarity Score: -0.0308
    Run 1, Batch 30: ERP Similarity Score: -0.0380

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=86.1047, G Loss (Comb)=1.2669
Epoch 50/1000: D Loss=-1.5238, G Loss (Comb)=-1.3759
Epoch 100/1000: D Loss=-0.4507, G Loss (Comb)=-3.2734
Epoch 150/1000: D Loss=-0.3872, G Loss (Comb)=-3.1928
Epoch 200/1000: D Loss=-0.3654, G Loss (Comb)=-3.4236
Epoch 250/1000: D Loss=-0.4032, G Loss (Comb)=-2.7230
Epoch 300/1000: D Loss=-0.2644, G Loss (Comb)=-3.0315
Epoch 350/1000: D Loss=-0.3808, G Loss (Comb)=-3.1054
Epoch 400/1000: D Loss=-0.3297, G Loss (Comb)=-3.7331
Epoch 450/1000: D Loss=-0.3828, G Loss (Comb)=-3.6179
Epoch 500/1000: D Loss=-0.3195, G Loss (Comb)=-3.4122
Epoch 550/1000: D Loss=-0.4401, G Loss (Comb)=-3.5611
Epoch 600/1000: D Loss=-0.4340, G Loss (Comb)=-4.1663
Epoch 650/1000: D Loss=-0.4981, G Loss (Comb)=-4.1516
Epoch 700/1000: D Loss=-0.5548, G Loss (Comb)=-3.9424
Epoch 750/1000: D Loss=-0.5862, G Loss (Comb)=-3.9098
Epoch 800/1000: D Loss=-0.6597, G Loss (Comb)=-4.0746
Epoch 850/1000: D Loss=-0.6446, G Loss (Comb)=-3.9940
Epoch 900/1000: D Loss=-0.6933, G Loss (Comb)=-4.0705
Epoch 950/1000: D Loss=-0.7146, G Loss (Comb)=-4.0156
Epoch 999/1000: D Loss=-0.7600, G Loss (Comb)=-3.9433

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0252
    Run 2, Batch 2: ERP Similarity Score: -0.0308
    Run 2, Batch 3: ERP Similarity Score: -0.0302
    Run 2, Batch 4: ERP Similarity Score: -0.0303
    Run 2, Batch 5: ERP Similarity Score: -0.0336
    Run 2, Batch 6: ERP Similarity Score: -0.0268
    Run 2, Batch 7: ERP Similarity Score: -0.0271
    Run 2, Batch 8: ERP Similarity Score: -0.0272
    Run 2, Batch 9: ERP Similarity Score: -0.0277
    Run 2, Batch 10: ERP Similarity Score: -0.0303
    Run 2, Batch 11: ERP Similarity Score: -0.0288
    Run 2, Batch 12: ERP Similarity Score: -0.0268
    Run 2, Batch 13: ERP Similarity Score: -0.0290
    Run 2, Batch 14: ERP Similarity Score: -0.0268
    Run 2, Batch 15: ERP Similarity Score: -0.0285
    Run 2, Batch 16: ERP Similarity Score: -0.0312
    Run 2, Batch 17: ERP Similarity Score: -0.0267
    Run 2, Batch 18: ERP Similarity Score: -0.0270
    Run 2, Batch 19: ERP Similarity Score: -0.0274
    Run 2, Batch 20: ERP Similarity Score: -0.0320
    Run 2, Batch 21: ERP Similarity Score: -0.0266
    Run 2, Batch 22: ERP Similarity Score: -0.0286
    Run 2, Batch 23: ERP Similarity Score: -0.0273
    Run 2, Batch 24: ERP Similarity Score: -0.0314
    Run 2, Batch 25: ERP Similarity Score: -0.0263
    Run 2, Batch 26: ERP Similarity Score: -0.0371
    Run 2, Batch 27: ERP Similarity Score: -0.0269
    Run 2, Batch 28: ERP Similarity Score: -0.0304
    Run 2, Batch 29: ERP Similarity Score: -0.0309
    Run 2, Batch 30: ERP Similarity Score: -0.0312

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=82.4584, G Loss (Comb)=1.8772
Epoch 50/1000: D Loss=-1.7544, G Loss (Comb)=-0.8015
Epoch 100/1000: D Loss=-0.4257, G Loss (Comb)=-3.5458
Epoch 150/1000: D Loss=-0.2263, G Loss (Comb)=-3.2834
Epoch 200/1000: D Loss=-0.3145, G Loss (Comb)=-2.9693
Epoch 250/1000: D Loss=-0.3728, G Loss (Comb)=-3.1250
Epoch 300/1000: D Loss=-0.4639, G Loss (Comb)=-3.3531
Epoch 350/1000: D Loss=-0.3149, G Loss (Comb)=-3.2429
Epoch 400/1000: D Loss=-0.3398, G Loss (Comb)=-3.1517
Epoch 450/1000: D Loss=-0.4390, G Loss (Comb)=-3.4155
Epoch 500/1000: D Loss=-0.5230, G Loss (Comb)=-2.9540
Epoch 550/1000: D Loss=-0.3733, G Loss (Comb)=-3.3989
Epoch 600/1000: D Loss=-0.6078, G Loss (Comb)=-2.5869
Epoch 650/1000: D Loss=-0.5696, G Loss (Comb)=-2.8794
Epoch 700/1000: D Loss=-0.5227, G Loss (Comb)=-2.9744
Epoch 750/1000: D Loss=-0.6573, G Loss (Comb)=-2.9047
Epoch 800/1000: D Loss=-0.6135, G Loss (Comb)=-3.0175
Epoch 850/1000: D Loss=-0.7733, G Loss (Comb)=-2.7163
Epoch 900/1000: D Loss=-0.7006, G Loss (Comb)=-2.8826
Epoch 950/1000: D Loss=-0.7740, G Loss (Comb)=-2.8038
Epoch 999/1000: D Loss=-0.8215, G Loss (Comb)=-2.7004

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0293
    Run 3, Batch 2: ERP Similarity Score: -0.0307
    Run 3, Batch 3: ERP Similarity Score: -0.0281
    Run 3, Batch 4: ERP Similarity Score: -0.0285
    Run 3, Batch 5: ERP Similarity Score: -0.0262
    Run 3, Batch 6: ERP Similarity Score: -0.0305
    Run 3, Batch 7: ERP Similarity Score: -0.0285
    Run 3, Batch 8: ERP Similarity Score: -0.0290
    Run 3, Batch 9: ERP Similarity Score: -0.0303
    Run 3, Batch 10: ERP Similarity Score: -0.0293
    Run 3, Batch 11: ERP Similarity Score: -0.0323
    Run 3, Batch 12: ERP Similarity Score: -0.0303
    Run 3, Batch 13: ERP Similarity Score: -0.0259
    Run 3, Batch 14: ERP Similarity Score: -0.0295
    Run 3, Batch 15: ERP Similarity Score: -0.0265
    Run 3, Batch 16: ERP Similarity Score: -0.0274
    Run 3, Batch 17: ERP Similarity Score: -0.0308
    Run 3, Batch 18: ERP Similarity Score: -0.0279
    Run 3, Batch 19: ERP Similarity Score: -0.0266
    Run 3, Batch 20: ERP Similarity Score: -0.0274
    Run 3, Batch 21: ERP Similarity Score: -0.0349
    Run 3, Batch 22: ERP Similarity Score: -0.0256
    Run 3, Batch 23: ERP Similarity Score: -0.0279
    Run 3, Batch 24: ERP Similarity Score: -0.0278
    Run 3, Batch 25: ERP Similarity Score: -0.0293
    Run 3, Batch 26: ERP Similarity Score: -0.0281
    Run 3, Batch 27: ERP Similarity Score: -0.0295
    Run 3, Batch 28: ERP Similarity Score: -0.0287
    Run 3, Batch 29: ERP Similarity Score: -0.0289
    Run 3, Batch 30: ERP Similarity Score: -0.0273

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=102.4868, G Loss (Comb)=0.7564
Epoch 50/1000: D Loss=-1.6321, G Loss (Comb)=-1.4640
Epoch 100/1000: D Loss=-0.3795, G Loss (Comb)=-4.4254
Epoch 150/1000: D Loss=-0.3493, G Loss (Comb)=-4.5375
Epoch 200/1000: D Loss=-0.3456, G Loss (Comb)=-4.8803
Epoch 250/1000: D Loss=-0.3027, G Loss (Comb)=-4.3995
Epoch 300/1000: D Loss=-0.4019, G Loss (Comb)=-4.7494
Epoch 350/1000: D Loss=-0.1551, G Loss (Comb)=-5.0071
Epoch 400/1000: D Loss=-0.4073, G Loss (Comb)=-4.9135
Epoch 450/1000: D Loss=-0.3610, G Loss (Comb)=-5.0092
Epoch 500/1000: D Loss=-0.2877, G Loss (Comb)=-5.2281
Epoch 550/1000: D Loss=-0.4220, G Loss (Comb)=-4.9977
Epoch 600/1000: D Loss=-0.4164, G Loss (Comb)=-5.1373
Epoch 650/1000: D Loss=-0.5240, G Loss (Comb)=-5.0888
Epoch 700/1000: D Loss=-0.5169, G Loss (Comb)=-4.9091
Epoch 750/1000: D Loss=-0.5607, G Loss (Comb)=-4.5339
Epoch 800/1000: D Loss=-0.6495, G Loss (Comb)=-4.8043
Epoch 850/1000: D Loss=-0.6696, G Loss (Comb)=-4.7452
Epoch 900/1000: D Loss=-0.7145, G Loss (Comb)=-4.6260
Epoch 950/1000: D Loss=-0.7333, G Loss (Comb)=-4.8383
Epoch 999/1000: D Loss=-0.7493, G Loss (Comb)=-4.5566

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0358
    Run 4, Batch 2: ERP Similarity Score: -0.0316
    Run 4, Batch 3: ERP Similarity Score: -0.0318
    Run 4, Batch 4: ERP Similarity Score: -0.0318
    Run 4, Batch 5: ERP Similarity Score: -0.0374
    Run 4, Batch 6: ERP Similarity Score: -0.0347
    Run 4, Batch 7: ERP Similarity Score: -0.0364
    Run 4, Batch 8: ERP Similarity Score: -0.0334
    Run 4, Batch 9: ERP Similarity Score: -0.0299
    Run 4, Batch 10: ERP Similarity Score: -0.0327
    Run 4, Batch 11: ERP Similarity Score: -0.0311
    Run 4, Batch 12: ERP Similarity Score: -0.0363
    Run 4, Batch 13: ERP Similarity Score: -0.0336
    Run 4, Batch 14: ERP Similarity Score: -0.0317
    Run 4, Batch 15: ERP Similarity Score: -0.0340
    Run 4, Batch 16: ERP Similarity Score: -0.0357
    Run 4, Batch 17: ERP Similarity Score: -0.0337
    Run 4, Batch 18: ERP Similarity Score: -0.0307
    Run 4, Batch 19: ERP Similarity Score: -0.0338
    Run 4, Batch 20: ERP Similarity Score: -0.0332
    Run 4, Batch 21: ERP Similarity Score: -0.0308
    Run 4, Batch 22: ERP Similarity Score: -0.0388
    Run 4, Batch 23: ERP Similarity Score: -0.0313
    Run 4, Batch 24: ERP Similarity Score: -0.0319
    Run 4, Batch 25: ERP Similarity Score: -0.0334
    Run 4, Batch 26: ERP Similarity Score: -0.0348
    Run 4, Batch 27: ERP Similarity Score: -0.0353
    Run 4, Batch 28: ERP Similarity Score: -0.0343
    Run 4, Batch 29: ERP Similarity Score: -0.0335
    Run 4, Batch 30: ERP Similarity Score: -0.0400

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=100.4587, G Loss (Comb)=0.9509
Epoch 50/1000: D Loss=-1.6707, G Loss (Comb)=-1.8657
Epoch 100/1000: D Loss=-0.3584, G Loss (Comb)=-4.4393
Epoch 150/1000: D Loss=-0.5367, G Loss (Comb)=-4.0918
Epoch 200/1000: D Loss=-0.3708, G Loss (Comb)=-3.9284
Epoch 250/1000: D Loss=-0.3440, G Loss (Comb)=-4.2733
Epoch 300/1000: D Loss=-0.3991, G Loss (Comb)=-3.9621
Epoch 350/1000: D Loss=-0.3497, G Loss (Comb)=-4.1273
Epoch 400/1000: D Loss=-0.3102, G Loss (Comb)=-4.3648
Epoch 450/1000: D Loss=-0.3086, G Loss (Comb)=-4.2537
Epoch 500/1000: D Loss=-0.5112, G Loss (Comb)=-4.0919
Epoch 550/1000: D Loss=-0.5139, G Loss (Comb)=-3.8547
Epoch 600/1000: D Loss=-0.5351, G Loss (Comb)=-3.8570
Epoch 650/1000: D Loss=-0.5856, G Loss (Comb)=-3.8014
Epoch 700/1000: D Loss=-0.5710, G Loss (Comb)=-3.9338
Epoch 750/1000: D Loss=-0.6901, G Loss (Comb)=-3.8302
Epoch 800/1000: D Loss=-0.6901, G Loss (Comb)=-3.7366
Epoch 850/1000: D Loss=-0.8025, G Loss (Comb)=-3.8834
Epoch 900/1000: D Loss=-0.8187, G Loss (Comb)=-3.7795
Epoch 950/1000: D Loss=-0.7991, G Loss (Comb)=-3.8925
Epoch 999/1000: D Loss=-0.8469, G Loss (Comb)=-3.8706

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0298
    Run 5, Batch 2: ERP Similarity Score: -0.0299
    Run 5, Batch 3: ERP Similarity Score: -0.0298
    Run 5, Batch 4: ERP Similarity Score: -0.0310
    Run 5, Batch 5: ERP Similarity Score: -0.0348
    Run 5, Batch 6: ERP Similarity Score: -0.0328
    Run 5, Batch 7: ERP Similarity Score: -0.0387
    Run 5, Batch 8: ERP Similarity Score: -0.0300
    Run 5, Batch 9: ERP Similarity Score: -0.0319
    Run 5, Batch 10: ERP Similarity Score: -0.0302
    Run 5, Batch 11: ERP Similarity Score: -0.0321
    Run 5, Batch 12: ERP Similarity Score: -0.0309
    Run 5, Batch 13: ERP Similarity Score: -0.0339
    Run 5, Batch 14: ERP Similarity Score: -0.0317
    Run 5, Batch 15: ERP Similarity Score: -0.0280
    Run 5, Batch 16: ERP Similarity Score: -0.0312
    Run 5, Batch 17: ERP Similarity Score: -0.0331
    Run 5, Batch 18: ERP Similarity Score: -0.0298
    Run 5, Batch 19: ERP Similarity Score: -0.0303
    Run 5, Batch 20: ERP Similarity Score: -0.0301
    Run 5, Batch 21: ERP Similarity Score: -0.0333
    Run 5, Batch 22: ERP Similarity Score: -0.0302
    Run 5, Batch 23: ERP Similarity Score: -0.0303
    Run 5, Batch 24: ERP Similarity Score: -0.0310
    Run 5, Batch 25: ERP Similarity Score: -0.0286
    Run 5, Batch 26: ERP Similarity Score: -0.0277
    Run 5, Batch 27: ERP Similarity Score: -0.0300
    Run 5, Batch 28: ERP Similarity Score: -0.0271
    Run 5, Batch 29: ERP Similarity Score: -0.0303
    Run 5, Batch 30: ERP Similarity Score: -0.0304


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 2, Batch 1, Score: -0.0252
  Top 2: Run 3, Batch 22, Score: -0.0256
  Top 3: Run 3, Batch 13, Score: -0.0259
  Top 4: Run 3, Batch 5, Score: -0.0262
  Top 5: Run 2, Batch 25, Score: -0.0263
  Top 6: Run 3, Batch 15, Score: -0.0265
  Top 7: Run 3, Batch 19, Score: -0.0266
  Top 8: Run 2, Batch 21, Score: -0.0266
  Top 9: Run 2, Batch 17, Score: -0.0267
  Top 10: Run 2, Batch 12, Score: -0.0268

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 2, Batch 1, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 22, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 13, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 5, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 2, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 15, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 21, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 2, Batch 17, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 12, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 2, Batch 12, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 12, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 12, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 7 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 2, Batch 1, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0252
  - Strategy (Run 3, Batch 22, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0256
  - Strategy (Run 3, Batch 13, Ratio 0): Accuracy=100.00, ERP Score=-0.0259
  - Strategy (Run 3, Batch 5, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0262
  - Strategy (Run 2, Batch 25, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0263
  - Strategy (Run 2, Batch 21, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0266
  - Strategy (Run 2, Batch 12, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0268

Selected best strategy: Run 2, Batch 1, Strategy: Augmented (50%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 48.57%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (50%), Val Acc: 100.00%) -> REAL test accuracy: 54.29%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H5_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H5_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
