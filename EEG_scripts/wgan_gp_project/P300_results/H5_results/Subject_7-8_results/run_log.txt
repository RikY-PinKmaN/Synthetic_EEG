Log for Subject Pair 7-8 from H5
========================================


========================= PROCESSING SUBJECT PAIR: 7-8 from H5 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 256 clean Target and 991 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 872

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 58

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 72.41%

--- Training cWGAN-GP for Subject 7-8, Run 1 ---
Epoch 0/1000: D Loss=76.4798, G Loss (Comb)=1.2919
Epoch 50/1000: D Loss=-0.3246, G Loss (Comb)=-4.2377
Epoch 100/1000: D Loss=-0.3132, G Loss (Comb)=-3.9937
Epoch 150/1000: D Loss=-0.2985, G Loss (Comb)=-3.0796
Epoch 200/1000: D Loss=-0.2382, G Loss (Comb)=-3.4541
Epoch 250/1000: D Loss=-0.1993, G Loss (Comb)=-3.5328
Epoch 300/1000: D Loss=-0.2387, G Loss (Comb)=-4.0009
Epoch 350/1000: D Loss=-0.3305, G Loss (Comb)=-4.2729
Epoch 400/1000: D Loss=-0.3169, G Loss (Comb)=-4.5752
Epoch 450/1000: D Loss=-0.3908, G Loss (Comb)=-4.4518
Epoch 500/1000: D Loss=-0.4148, G Loss (Comb)=-4.5283
Epoch 550/1000: D Loss=-0.5056, G Loss (Comb)=-4.5416
Epoch 600/1000: D Loss=-0.5734, G Loss (Comb)=-4.8258
Epoch 650/1000: D Loss=-0.6352, G Loss (Comb)=-4.7458
Epoch 700/1000: D Loss=-0.5943, G Loss (Comb)=-5.0556
Epoch 750/1000: D Loss=-0.6578, G Loss (Comb)=-4.9071
Epoch 800/1000: D Loss=-0.8015, G Loss (Comb)=-4.9282
Epoch 850/1000: D Loss=-0.7804, G Loss (Comb)=-5.1456
Epoch 900/1000: D Loss=-0.7983, G Loss (Comb)=-5.2133
Epoch 950/1000: D Loss=-0.8645, G Loss (Comb)=-5.1165
Epoch 999/1000: D Loss=-0.8565, G Loss (Comb)=-5.0461

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0281
    Run 1, Batch 2: ERP Similarity Score: -0.0285
    Run 1, Batch 3: ERP Similarity Score: -0.0308
    Run 1, Batch 4: ERP Similarity Score: -0.0319
    Run 1, Batch 5: ERP Similarity Score: -0.0281
    Run 1, Batch 6: ERP Similarity Score: -0.0297
    Run 1, Batch 7: ERP Similarity Score: -0.0281
    Run 1, Batch 8: ERP Similarity Score: -0.0280
    Run 1, Batch 9: ERP Similarity Score: -0.0289
    Run 1, Batch 10: ERP Similarity Score: -0.0318
    Run 1, Batch 11: ERP Similarity Score: -0.0309
    Run 1, Batch 12: ERP Similarity Score: -0.0318
    Run 1, Batch 13: ERP Similarity Score: -0.0306
    Run 1, Batch 14: ERP Similarity Score: -0.0279
    Run 1, Batch 15: ERP Similarity Score: -0.0285
    Run 1, Batch 16: ERP Similarity Score: -0.0276
    Run 1, Batch 17: ERP Similarity Score: -0.0307
    Run 1, Batch 18: ERP Similarity Score: -0.0281
    Run 1, Batch 19: ERP Similarity Score: -0.0290
    Run 1, Batch 20: ERP Similarity Score: -0.0303
    Run 1, Batch 21: ERP Similarity Score: -0.0317
    Run 1, Batch 22: ERP Similarity Score: -0.0289
    Run 1, Batch 23: ERP Similarity Score: -0.0286
    Run 1, Batch 24: ERP Similarity Score: -0.0300
    Run 1, Batch 25: ERP Similarity Score: -0.0339
    Run 1, Batch 26: ERP Similarity Score: -0.0296
    Run 1, Batch 27: ERP Similarity Score: -0.0291
    Run 1, Batch 28: ERP Similarity Score: -0.0279
    Run 1, Batch 29: ERP Similarity Score: -0.0299
    Run 1, Batch 30: ERP Similarity Score: -0.0286

--- Training cWGAN-GP for Subject 7-8, Run 2 ---
Epoch 0/1000: D Loss=90.9978, G Loss (Comb)=2.1264
Epoch 50/1000: D Loss=-0.4954, G Loss (Comb)=-2.8795
Epoch 100/1000: D Loss=-0.3259, G Loss (Comb)=-2.7399
Epoch 150/1000: D Loss=-0.2737, G Loss (Comb)=-2.6404
Epoch 200/1000: D Loss=-0.1722, G Loss (Comb)=-2.0452
Epoch 250/1000: D Loss=-0.2715, G Loss (Comb)=-2.0705
Epoch 300/1000: D Loss=-0.3923, G Loss (Comb)=-2.4724
Epoch 350/1000: D Loss=-0.2175, G Loss (Comb)=-2.5844
Epoch 400/1000: D Loss=-0.2784, G Loss (Comb)=-2.7026
Epoch 450/1000: D Loss=-0.3793, G Loss (Comb)=-2.8721
Epoch 500/1000: D Loss=-0.4497, G Loss (Comb)=-2.8792
Epoch 550/1000: D Loss=-0.5057, G Loss (Comb)=-3.0328
Epoch 600/1000: D Loss=-0.5127, G Loss (Comb)=-3.0239
Epoch 650/1000: D Loss=-0.6134, G Loss (Comb)=-3.0630
Epoch 700/1000: D Loss=-0.6091, G Loss (Comb)=-3.5278
Epoch 750/1000: D Loss=-0.6367, G Loss (Comb)=-3.5576
Epoch 800/1000: D Loss=-0.6944, G Loss (Comb)=-3.8637
Epoch 850/1000: D Loss=-0.6926, G Loss (Comb)=-4.0065
Epoch 900/1000: D Loss=-0.7520, G Loss (Comb)=-3.9897
Epoch 950/1000: D Loss=-0.7842, G Loss (Comb)=-4.1543
Epoch 999/1000: D Loss=-0.8192, G Loss (Comb)=-4.1900

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0270
    Run 2, Batch 2: ERP Similarity Score: -0.0291
    Run 2, Batch 3: ERP Similarity Score: -0.0289
    Run 2, Batch 4: ERP Similarity Score: -0.0249
    Run 2, Batch 5: ERP Similarity Score: -0.0287
    Run 2, Batch 6: ERP Similarity Score: -0.0244
    Run 2, Batch 7: ERP Similarity Score: -0.0260
    Run 2, Batch 8: ERP Similarity Score: -0.0252
    Run 2, Batch 9: ERP Similarity Score: -0.0262
    Run 2, Batch 10: ERP Similarity Score: -0.0278
    Run 2, Batch 11: ERP Similarity Score: -0.0246
    Run 2, Batch 12: ERP Similarity Score: -0.0276
    Run 2, Batch 13: ERP Similarity Score: -0.0237
    Run 2, Batch 14: ERP Similarity Score: -0.0259
    Run 2, Batch 15: ERP Similarity Score: -0.0271
    Run 2, Batch 16: ERP Similarity Score: -0.0273
    Run 2, Batch 17: ERP Similarity Score: -0.0254
    Run 2, Batch 18: ERP Similarity Score: -0.0257
    Run 2, Batch 19: ERP Similarity Score: -0.0290
    Run 2, Batch 20: ERP Similarity Score: -0.0254
    Run 2, Batch 21: ERP Similarity Score: -0.0288
    Run 2, Batch 22: ERP Similarity Score: -0.0268
    Run 2, Batch 23: ERP Similarity Score: -0.0248
    Run 2, Batch 24: ERP Similarity Score: -0.0295
    Run 2, Batch 25: ERP Similarity Score: -0.0252
    Run 2, Batch 26: ERP Similarity Score: -0.0252
    Run 2, Batch 27: ERP Similarity Score: -0.0266
    Run 2, Batch 28: ERP Similarity Score: -0.0281
    Run 2, Batch 29: ERP Similarity Score: -0.0275
    Run 2, Batch 30: ERP Similarity Score: -0.0282

--- Training cWGAN-GP for Subject 7-8, Run 3 ---
Epoch 0/1000: D Loss=91.9563, G Loss (Comb)=-0.2621
Epoch 50/1000: D Loss=-0.5333, G Loss (Comb)=-5.1197
Epoch 100/1000: D Loss=-0.4856, G Loss (Comb)=-4.8030
Epoch 150/1000: D Loss=-0.1514, G Loss (Comb)=-5.3056
Epoch 200/1000: D Loss=-0.2523, G Loss (Comb)=-4.8210
Epoch 250/1000: D Loss=-0.1352, G Loss (Comb)=-4.5084
Epoch 300/1000: D Loss=-0.2848, G Loss (Comb)=-4.9271
Epoch 350/1000: D Loss=-0.3485, G Loss (Comb)=-4.9395
Epoch 400/1000: D Loss=-0.3497, G Loss (Comb)=-5.0819
Epoch 450/1000: D Loss=-0.4893, G Loss (Comb)=-5.0089
Epoch 500/1000: D Loss=-0.4654, G Loss (Comb)=-5.1125
Epoch 550/1000: D Loss=-0.4355, G Loss (Comb)=-5.2730
Epoch 600/1000: D Loss=-0.3972, G Loss (Comb)=-5.2937
Epoch 650/1000: D Loss=-0.5165, G Loss (Comb)=-5.2665
Epoch 700/1000: D Loss=-0.6552, G Loss (Comb)=-5.4060
Epoch 750/1000: D Loss=-0.5990, G Loss (Comb)=-5.3997
Epoch 800/1000: D Loss=-0.6651, G Loss (Comb)=-5.6470
Epoch 850/1000: D Loss=-0.7059, G Loss (Comb)=-5.8359
Epoch 900/1000: D Loss=-0.7359, G Loss (Comb)=-5.8892
Epoch 950/1000: D Loss=-0.7571, G Loss (Comb)=-5.8744
Epoch 999/1000: D Loss=-0.7846, G Loss (Comb)=-5.9788

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0281
    Run 3, Batch 2: ERP Similarity Score: -0.0302
    Run 3, Batch 3: ERP Similarity Score: -0.0298
    Run 3, Batch 4: ERP Similarity Score: -0.0305
    Run 3, Batch 5: ERP Similarity Score: -0.0316
    Run 3, Batch 6: ERP Similarity Score: -0.0290
    Run 3, Batch 7: ERP Similarity Score: -0.0288
    Run 3, Batch 8: ERP Similarity Score: -0.0294
    Run 3, Batch 9: ERP Similarity Score: -0.0323
    Run 3, Batch 10: ERP Similarity Score: -0.0284
    Run 3, Batch 11: ERP Similarity Score: -0.0294
    Run 3, Batch 12: ERP Similarity Score: -0.0304
    Run 3, Batch 13: ERP Similarity Score: -0.0287
    Run 3, Batch 14: ERP Similarity Score: -0.0297
    Run 3, Batch 15: ERP Similarity Score: -0.0316
    Run 3, Batch 16: ERP Similarity Score: -0.0340
    Run 3, Batch 17: ERP Similarity Score: -0.0279
    Run 3, Batch 18: ERP Similarity Score: -0.0327
    Run 3, Batch 19: ERP Similarity Score: -0.0306
    Run 3, Batch 20: ERP Similarity Score: -0.0290
    Run 3, Batch 21: ERP Similarity Score: -0.0292
    Run 3, Batch 22: ERP Similarity Score: -0.0293
    Run 3, Batch 23: ERP Similarity Score: -0.0278
    Run 3, Batch 24: ERP Similarity Score: -0.0320
    Run 3, Batch 25: ERP Similarity Score: -0.0303
    Run 3, Batch 26: ERP Similarity Score: -0.0288
    Run 3, Batch 27: ERP Similarity Score: -0.0298
    Run 3, Batch 28: ERP Similarity Score: -0.0290
    Run 3, Batch 29: ERP Similarity Score: -0.0296
    Run 3, Batch 30: ERP Similarity Score: -0.0294

--- Training cWGAN-GP for Subject 7-8, Run 4 ---
Epoch 0/1000: D Loss=83.3938, G Loss (Comb)=1.0793
Epoch 50/1000: D Loss=-0.4605, G Loss (Comb)=-3.8672
Epoch 100/1000: D Loss=-0.3278, G Loss (Comb)=-3.2477
Epoch 150/1000: D Loss=-0.1421, G Loss (Comb)=-3.3756
Epoch 200/1000: D Loss=-0.2756, G Loss (Comb)=-3.0000
Epoch 250/1000: D Loss=-0.2222, G Loss (Comb)=-2.8803
Epoch 300/1000: D Loss=-0.3209, G Loss (Comb)=-3.4901
Epoch 350/1000: D Loss=-0.2476, G Loss (Comb)=-3.3567
Epoch 400/1000: D Loss=-0.3313, G Loss (Comb)=-3.3589
Epoch 450/1000: D Loss=-0.3492, G Loss (Comb)=-3.5621
Epoch 500/1000: D Loss=-0.4679, G Loss (Comb)=-3.6008
Epoch 550/1000: D Loss=-0.4176, G Loss (Comb)=-3.7761
Epoch 600/1000: D Loss=-0.5537, G Loss (Comb)=-3.8544
Epoch 650/1000: D Loss=-0.5666, G Loss (Comb)=-3.9583
Epoch 700/1000: D Loss=-0.6107, G Loss (Comb)=-4.2655
Epoch 750/1000: D Loss=-0.6837, G Loss (Comb)=-4.2928
Epoch 800/1000: D Loss=-0.6742, G Loss (Comb)=-4.4019
Epoch 850/1000: D Loss=-0.7266, G Loss (Comb)=-4.5717
Epoch 900/1000: D Loss=-0.7839, G Loss (Comb)=-4.5647
Epoch 950/1000: D Loss=-0.7954, G Loss (Comb)=-4.6154
Epoch 999/1000: D Loss=-0.8379, G Loss (Comb)=-4.7705

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0300
    Run 4, Batch 2: ERP Similarity Score: -0.0279
    Run 4, Batch 3: ERP Similarity Score: -0.0268
    Run 4, Batch 4: ERP Similarity Score: -0.0280
    Run 4, Batch 5: ERP Similarity Score: -0.0296
    Run 4, Batch 6: ERP Similarity Score: -0.0278
    Run 4, Batch 7: ERP Similarity Score: -0.0276
    Run 4, Batch 8: ERP Similarity Score: -0.0279
    Run 4, Batch 9: ERP Similarity Score: -0.0281
    Run 4, Batch 10: ERP Similarity Score: -0.0292
    Run 4, Batch 11: ERP Similarity Score: -0.0266
    Run 4, Batch 12: ERP Similarity Score: -0.0278
    Run 4, Batch 13: ERP Similarity Score: -0.0286
    Run 4, Batch 14: ERP Similarity Score: -0.0296
    Run 4, Batch 15: ERP Similarity Score: -0.0299
    Run 4, Batch 16: ERP Similarity Score: -0.0277
    Run 4, Batch 17: ERP Similarity Score: -0.0304
    Run 4, Batch 18: ERP Similarity Score: -0.0277
    Run 4, Batch 19: ERP Similarity Score: -0.0277
    Run 4, Batch 20: ERP Similarity Score: -0.0267
    Run 4, Batch 21: ERP Similarity Score: -0.0271
    Run 4, Batch 22: ERP Similarity Score: -0.0261
    Run 4, Batch 23: ERP Similarity Score: -0.0267
    Run 4, Batch 24: ERP Similarity Score: -0.0284
    Run 4, Batch 25: ERP Similarity Score: -0.0260
    Run 4, Batch 26: ERP Similarity Score: -0.0269
    Run 4, Batch 27: ERP Similarity Score: -0.0274
    Run 4, Batch 28: ERP Similarity Score: -0.0289
    Run 4, Batch 29: ERP Similarity Score: -0.0287
    Run 4, Batch 30: ERP Similarity Score: -0.0296

--- Training cWGAN-GP for Subject 7-8, Run 5 ---
Epoch 0/1000: D Loss=90.1448, G Loss (Comb)=0.9854
Epoch 50/1000: D Loss=-0.4951, G Loss (Comb)=-4.3697
Epoch 100/1000: D Loss=-0.2139, G Loss (Comb)=-4.3158
Epoch 150/1000: D Loss=-0.3240, G Loss (Comb)=-4.3710
Epoch 200/1000: D Loss=-0.3254, G Loss (Comb)=-3.8398
Epoch 250/1000: D Loss=-0.2603, G Loss (Comb)=-4.4245
Epoch 300/1000: D Loss=-0.1651, G Loss (Comb)=-4.5139
Epoch 350/1000: D Loss=-0.3278, G Loss (Comb)=-5.0607
Epoch 400/1000: D Loss=-0.3227, G Loss (Comb)=-5.0004
Epoch 450/1000: D Loss=-0.2745, G Loss (Comb)=-5.2150
Epoch 500/1000: D Loss=-0.4104, G Loss (Comb)=-5.2046
Epoch 550/1000: D Loss=-0.4032, G Loss (Comb)=-5.4969
Epoch 600/1000: D Loss=-0.4491, G Loss (Comb)=-5.5135
Epoch 650/1000: D Loss=-0.5585, G Loss (Comb)=-5.5288
Epoch 700/1000: D Loss=-0.5466, G Loss (Comb)=-5.7775
Epoch 750/1000: D Loss=-0.5221, G Loss (Comb)=-5.7272
Epoch 800/1000: D Loss=-0.6410, G Loss (Comb)=-5.8270
Epoch 850/1000: D Loss=-0.6620, G Loss (Comb)=-5.8571
Epoch 900/1000: D Loss=-0.7109, G Loss (Comb)=-5.9748
Epoch 950/1000: D Loss=-0.7118, G Loss (Comb)=-5.9850
Epoch 999/1000: D Loss=-0.8155, G Loss (Comb)=-5.8879

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0256
    Run 5, Batch 2: ERP Similarity Score: -0.0260
    Run 5, Batch 3: ERP Similarity Score: -0.0269
    Run 5, Batch 4: ERP Similarity Score: -0.0256
    Run 5, Batch 5: ERP Similarity Score: -0.0247
    Run 5, Batch 6: ERP Similarity Score: -0.0274
    Run 5, Batch 7: ERP Similarity Score: -0.0259
    Run 5, Batch 8: ERP Similarity Score: -0.0259
    Run 5, Batch 9: ERP Similarity Score: -0.0343
    Run 5, Batch 10: ERP Similarity Score: -0.0263
    Run 5, Batch 11: ERP Similarity Score: -0.0268
    Run 5, Batch 12: ERP Similarity Score: -0.0270
    Run 5, Batch 13: ERP Similarity Score: -0.0228
    Run 5, Batch 14: ERP Similarity Score: -0.0247
    Run 5, Batch 15: ERP Similarity Score: -0.0280
    Run 5, Batch 16: ERP Similarity Score: -0.0236
    Run 5, Batch 17: ERP Similarity Score: -0.0292
    Run 5, Batch 18: ERP Similarity Score: -0.0277
    Run 5, Batch 19: ERP Similarity Score: -0.0264
    Run 5, Batch 20: ERP Similarity Score: -0.0271
    Run 5, Batch 21: ERP Similarity Score: -0.0278
    Run 5, Batch 22: ERP Similarity Score: -0.0278
    Run 5, Batch 23: ERP Similarity Score: -0.0253
    Run 5, Batch 24: ERP Similarity Score: -0.0246
    Run 5, Batch 25: ERP Similarity Score: -0.0274
    Run 5, Batch 26: ERP Similarity Score: -0.0301
    Run 5, Batch 27: ERP Similarity Score: -0.0269
    Run 5, Batch 28: ERP Similarity Score: -0.0268
    Run 5, Batch 29: ERP Similarity Score: -0.0241
    Run 5, Batch 30: ERP Similarity Score: -0.0266


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 5, Batch 13, Score: -0.0228
  Top 2: Run 5, Batch 16, Score: -0.0236
  Top 3: Run 2, Batch 13, Score: -0.0237
  Top 4: Run 5, Batch 29, Score: -0.0241
  Top 5: Run 2, Batch 6, Score: -0.0244
  Top 6: Run 2, Batch 11, Score: -0.0246
  Top 7: Run 5, Batch 24, Score: -0.0246
  Top 8: Run 5, Batch 5, Score: -0.0247
  Top 9: Run 5, Batch 14, Score: -0.0247
  Top 10: Run 2, Batch 23, Score: -0.0248

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 5, Batch 13, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 5, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 5, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 5, Batch 16, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 5, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 5, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 2, Batch 13, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 2, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 2, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 2, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 29, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 5, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 5, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 2, Batch 6, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 2, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 2, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 2, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 11, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 2, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 2, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 5, Batch 24, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 5, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 5, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 5, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 5, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 5, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 14, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 5, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 2, Batch 23, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 2, Batch 23, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 2, Batch 23, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 23, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 15 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 5, Batch 13, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0228
  - Strategy (Run 5, Batch 16, Ratio 0): Accuracy=100.00, ERP Score=-0.0236
  - Strategy (Run 5, Batch 16, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0236
  - Strategy (Run 2, Batch 13, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0237
  - Strategy (Run 5, Batch 29, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0241
  - Strategy (Run 2, Batch 6, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0244
  - Strategy (Run 2, Batch 11, Ratio 0): Accuracy=100.00, ERP Score=-0.0246
  - Strategy (Run 2, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0246
  - Strategy (Run 5, Batch 24, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0246
  - Strategy (Run 5, Batch 5, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0247
  - Strategy (Run 5, Batch 5, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0247
  - Strategy (Run 5, Batch 5, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0247
  - Strategy (Run 5, Batch 14, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0247
  - Strategy (Run 2, Batch 23, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0248
  - Strategy (Run 2, Batch 23, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0248

Selected best strategy: Run 5, Batch 13, Strategy: Augmented (25%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 79.31%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (25%), Val Acc: 100.00%) -> REAL test accuracy: 62.07%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H5_results/Subject_7-8_results/accuracy_comparison_S7-8.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 7-8) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H5_results/Subject_7-8_results/GA_ERP_Combined_S7-8_ChCz.png

--- Subject 7-8 processing finished successfully. ---
