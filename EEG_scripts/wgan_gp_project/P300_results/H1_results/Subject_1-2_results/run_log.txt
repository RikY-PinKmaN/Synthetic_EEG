Log for Subject Pair 1-2 from H1
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H1 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 261 clean Target and 524 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 560

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 36

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 61.11%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=78.8558, G Loss (Comb)=2.5358
Epoch 50/1000: D Loss=-1.7408, G Loss (Comb)=0.4618
Epoch 100/1000: D Loss=-0.4620, G Loss (Comb)=-1.8164
Epoch 150/1000: D Loss=-0.4929, G Loss (Comb)=-1.1210
Epoch 200/1000: D Loss=-0.3579, G Loss (Comb)=-0.3695
Epoch 250/1000: D Loss=-0.3741, G Loss (Comb)=0.3157
Epoch 300/1000: D Loss=-0.4229, G Loss (Comb)=0.2726
Epoch 350/1000: D Loss=-0.4013, G Loss (Comb)=0.5497
Epoch 400/1000: D Loss=-0.2661, G Loss (Comb)=1.1299
Epoch 450/1000: D Loss=-0.3604, G Loss (Comb)=1.6092
Epoch 500/1000: D Loss=-0.5040, G Loss (Comb)=1.4074
Epoch 550/1000: D Loss=-0.4154, G Loss (Comb)=1.5914
Epoch 600/1000: D Loss=-0.4147, G Loss (Comb)=1.4214
Epoch 650/1000: D Loss=-0.4791, G Loss (Comb)=1.5207
Epoch 700/1000: D Loss=-0.5479, G Loss (Comb)=1.1842
Epoch 750/1000: D Loss=-0.5519, G Loss (Comb)=1.1241
Epoch 800/1000: D Loss=-0.5782, G Loss (Comb)=0.9106
Epoch 850/1000: D Loss=-0.6644, G Loss (Comb)=0.8717
Epoch 900/1000: D Loss=-0.6427, G Loss (Comb)=0.6262
Epoch 950/1000: D Loss=-0.6573, G Loss (Comb)=0.3966
Epoch 999/1000: D Loss=-0.6777, G Loss (Comb)=0.3627

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0589
    Run 1, Batch 2: ERP Similarity Score: -0.0634
    Run 1, Batch 3: ERP Similarity Score: -0.0531
    Run 1, Batch 4: ERP Similarity Score: -0.0495
    Run 1, Batch 5: ERP Similarity Score: -0.0530
    Run 1, Batch 6: ERP Similarity Score: -0.0507
    Run 1, Batch 7: ERP Similarity Score: -0.0571
    Run 1, Batch 8: ERP Similarity Score: -0.0532
    Run 1, Batch 9: ERP Similarity Score: -0.0416
    Run 1, Batch 10: ERP Similarity Score: -0.0449
    Run 1, Batch 11: ERP Similarity Score: -0.0488
    Run 1, Batch 12: ERP Similarity Score: -0.0532
    Run 1, Batch 13: ERP Similarity Score: -0.0529
    Run 1, Batch 14: ERP Similarity Score: -0.0529
    Run 1, Batch 15: ERP Similarity Score: -0.0625
    Run 1, Batch 16: ERP Similarity Score: -0.0528
    Run 1, Batch 17: ERP Similarity Score: -0.0516
    Run 1, Batch 18: ERP Similarity Score: -0.0601
    Run 1, Batch 19: ERP Similarity Score: -0.0526
    Run 1, Batch 20: ERP Similarity Score: -0.0542
    Run 1, Batch 21: ERP Similarity Score: -0.0496
    Run 1, Batch 22: ERP Similarity Score: -0.0510
    Run 1, Batch 23: ERP Similarity Score: -0.0582
    Run 1, Batch 24: ERP Similarity Score: -0.0566
    Run 1, Batch 25: ERP Similarity Score: -0.0450
    Run 1, Batch 26: ERP Similarity Score: -0.0599
    Run 1, Batch 27: ERP Similarity Score: -0.0546
    Run 1, Batch 28: ERP Similarity Score: -0.0602
    Run 1, Batch 29: ERP Similarity Score: -0.0498
    Run 1, Batch 30: ERP Similarity Score: -0.0474

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=82.7240, G Loss (Comb)=0.6993
Epoch 50/1000: D Loss=-1.5661, G Loss (Comb)=-1.9225
Epoch 100/1000: D Loss=-0.4701, G Loss (Comb)=-3.5864
Epoch 150/1000: D Loss=-0.4510, G Loss (Comb)=-2.7047
Epoch 200/1000: D Loss=-0.4126, G Loss (Comb)=-3.0035
Epoch 250/1000: D Loss=-0.4670, G Loss (Comb)=-2.3618
Epoch 300/1000: D Loss=-0.3888, G Loss (Comb)=-1.9270
Epoch 350/1000: D Loss=-0.3999, G Loss (Comb)=-1.8292
Epoch 400/1000: D Loss=-0.4405, G Loss (Comb)=-1.3905
Epoch 450/1000: D Loss=-0.3644, G Loss (Comb)=-1.4016
Epoch 500/1000: D Loss=-0.3586, G Loss (Comb)=-1.0911
Epoch 550/1000: D Loss=-0.4412, G Loss (Comb)=-0.7711
Epoch 600/1000: D Loss=-0.4123, G Loss (Comb)=-0.6046
Epoch 650/1000: D Loss=-0.4650, G Loss (Comb)=-0.8109
Epoch 700/1000: D Loss=-0.5493, G Loss (Comb)=-0.9515
Epoch 750/1000: D Loss=-0.5654, G Loss (Comb)=-1.1351
Epoch 800/1000: D Loss=-0.6785, G Loss (Comb)=-1.1942
Epoch 850/1000: D Loss=-0.5829, G Loss (Comb)=-1.3455
Epoch 900/1000: D Loss=-0.5689, G Loss (Comb)=-1.3093
Epoch 950/1000: D Loss=-0.6010, G Loss (Comb)=-1.4794
Epoch 999/1000: D Loss=-0.7026, G Loss (Comb)=-1.8439

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0448
    Run 2, Batch 2: ERP Similarity Score: -0.0538
    Run 2, Batch 3: ERP Similarity Score: -0.0452
    Run 2, Batch 4: ERP Similarity Score: -0.0610
    Run 2, Batch 5: ERP Similarity Score: -0.0491
    Run 2, Batch 6: ERP Similarity Score: -0.0521
    Run 2, Batch 7: ERP Similarity Score: -0.0533
    Run 2, Batch 8: ERP Similarity Score: -0.0446
    Run 2, Batch 9: ERP Similarity Score: -0.0551
    Run 2, Batch 10: ERP Similarity Score: -0.0502
    Run 2, Batch 11: ERP Similarity Score: -0.0495
    Run 2, Batch 12: ERP Similarity Score: -0.0538
    Run 2, Batch 13: ERP Similarity Score: -0.0497
    Run 2, Batch 14: ERP Similarity Score: -0.0522
    Run 2, Batch 15: ERP Similarity Score: -0.0465
    Run 2, Batch 16: ERP Similarity Score: -0.0604
    Run 2, Batch 17: ERP Similarity Score: -0.0521
    Run 2, Batch 18: ERP Similarity Score: -0.0454
    Run 2, Batch 19: ERP Similarity Score: -0.0492
    Run 2, Batch 20: ERP Similarity Score: -0.0529
    Run 2, Batch 21: ERP Similarity Score: -0.0473
    Run 2, Batch 22: ERP Similarity Score: -0.0458
    Run 2, Batch 23: ERP Similarity Score: -0.0494
    Run 2, Batch 24: ERP Similarity Score: -0.0475
    Run 2, Batch 25: ERP Similarity Score: -0.0489
    Run 2, Batch 26: ERP Similarity Score: -0.0538
    Run 2, Batch 27: ERP Similarity Score: -0.0538
    Run 2, Batch 28: ERP Similarity Score: -0.0468
    Run 2, Batch 29: ERP Similarity Score: -0.0557
    Run 2, Batch 30: ERP Similarity Score: -0.0538

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=100.8442, G Loss (Comb)=0.8562
Epoch 50/1000: D Loss=-1.3281, G Loss (Comb)=-1.5964
Epoch 100/1000: D Loss=-0.5472, G Loss (Comb)=-4.0105
Epoch 150/1000: D Loss=-0.3014, G Loss (Comb)=-3.7282
Epoch 200/1000: D Loss=-0.3746, G Loss (Comb)=-2.9612
Epoch 250/1000: D Loss=-0.2151, G Loss (Comb)=-2.7084
Epoch 300/1000: D Loss=-0.4131, G Loss (Comb)=-3.6224
Epoch 350/1000: D Loss=-0.3897, G Loss (Comb)=-2.5597
Epoch 400/1000: D Loss=-0.2727, G Loss (Comb)=-2.9878
Epoch 450/1000: D Loss=-0.3613, G Loss (Comb)=-2.3224
Epoch 500/1000: D Loss=-0.3559, G Loss (Comb)=-1.6378
Epoch 550/1000: D Loss=-0.4847, G Loss (Comb)=-1.8985
Epoch 600/1000: D Loss=-0.4262, G Loss (Comb)=-1.5163
Epoch 650/1000: D Loss=-0.4822, G Loss (Comb)=-1.1506
Epoch 700/1000: D Loss=-0.4333, G Loss (Comb)=-1.5702
Epoch 750/1000: D Loss=-0.5470, G Loss (Comb)=-1.3942
Epoch 800/1000: D Loss=-0.5700, G Loss (Comb)=-1.5394
Epoch 850/1000: D Loss=-0.5270, G Loss (Comb)=-1.5749
Epoch 900/1000: D Loss=-0.5089, G Loss (Comb)=-1.7500
Epoch 950/1000: D Loss=-0.5871, G Loss (Comb)=-1.9944
Epoch 999/1000: D Loss=-0.6306, G Loss (Comb)=-2.2752

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0498
    Run 3, Batch 2: ERP Similarity Score: -0.0430
    Run 3, Batch 3: ERP Similarity Score: -0.0418
    Run 3, Batch 4: ERP Similarity Score: -0.0562
    Run 3, Batch 5: ERP Similarity Score: -0.0486
    Run 3, Batch 6: ERP Similarity Score: -0.0556
    Run 3, Batch 7: ERP Similarity Score: -0.0527
    Run 3, Batch 8: ERP Similarity Score: -0.0532
    Run 3, Batch 9: ERP Similarity Score: -0.0495
    Run 3, Batch 10: ERP Similarity Score: -0.0420
    Run 3, Batch 11: ERP Similarity Score: -0.0497
    Run 3, Batch 12: ERP Similarity Score: -0.0466
    Run 3, Batch 13: ERP Similarity Score: -0.0454
    Run 3, Batch 14: ERP Similarity Score: -0.0476
    Run 3, Batch 15: ERP Similarity Score: -0.0438
    Run 3, Batch 16: ERP Similarity Score: -0.0527
    Run 3, Batch 17: ERP Similarity Score: -0.0483
    Run 3, Batch 18: ERP Similarity Score: -0.0470
    Run 3, Batch 19: ERP Similarity Score: -0.0459
    Run 3, Batch 20: ERP Similarity Score: -0.0446
    Run 3, Batch 21: ERP Similarity Score: -0.0468
    Run 3, Batch 22: ERP Similarity Score: -0.0410
    Run 3, Batch 23: ERP Similarity Score: -0.0458
    Run 3, Batch 24: ERP Similarity Score: -0.0480
    Run 3, Batch 25: ERP Similarity Score: -0.0421
    Run 3, Batch 26: ERP Similarity Score: -0.0634
    Run 3, Batch 27: ERP Similarity Score: -0.0548
    Run 3, Batch 28: ERP Similarity Score: -0.0569
    Run 3, Batch 29: ERP Similarity Score: -0.0470
    Run 3, Batch 30: ERP Similarity Score: -0.0491

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=96.5294, G Loss (Comb)=2.3969
Epoch 50/1000: D Loss=-1.6011, G Loss (Comb)=-1.2004
Epoch 100/1000: D Loss=-0.3874, G Loss (Comb)=-3.6580
Epoch 150/1000: D Loss=-0.4160, G Loss (Comb)=-3.0712
Epoch 200/1000: D Loss=-0.5974, G Loss (Comb)=-3.0355
Epoch 250/1000: D Loss=-0.2775, G Loss (Comb)=-2.5897
Epoch 300/1000: D Loss=-0.2359, G Loss (Comb)=-2.1492
Epoch 350/1000: D Loss=-0.5209, G Loss (Comb)=-1.6798
Epoch 400/1000: D Loss=-0.4756, G Loss (Comb)=-1.2708
Epoch 450/1000: D Loss=-0.4361, G Loss (Comb)=-0.5200
Epoch 500/1000: D Loss=-0.4140, G Loss (Comb)=-0.3078
Epoch 550/1000: D Loss=-0.4874, G Loss (Comb)=-0.1071
Epoch 600/1000: D Loss=-0.5483, G Loss (Comb)=-0.1895
Epoch 650/1000: D Loss=-0.5675, G Loss (Comb)=-0.4705
Epoch 700/1000: D Loss=-0.4906, G Loss (Comb)=-0.4622
Epoch 750/1000: D Loss=-0.6091, G Loss (Comb)=-0.8648
Epoch 800/1000: D Loss=-0.4827, G Loss (Comb)=-0.9942
Epoch 850/1000: D Loss=-0.6228, G Loss (Comb)=-0.9970
Epoch 900/1000: D Loss=-0.7369, G Loss (Comb)=-1.2562
Epoch 950/1000: D Loss=-0.6574, G Loss (Comb)=-1.4586
Epoch 999/1000: D Loss=-0.7206, G Loss (Comb)=-1.5338

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0514
    Run 4, Batch 2: ERP Similarity Score: -0.0526
    Run 4, Batch 3: ERP Similarity Score: -0.0518
    Run 4, Batch 4: ERP Similarity Score: -0.0541
    Run 4, Batch 5: ERP Similarity Score: -0.0463
    Run 4, Batch 6: ERP Similarity Score: -0.0428
    Run 4, Batch 7: ERP Similarity Score: -0.0433
    Run 4, Batch 8: ERP Similarity Score: -0.0459
    Run 4, Batch 9: ERP Similarity Score: -0.0493
    Run 4, Batch 10: ERP Similarity Score: -0.0466
    Run 4, Batch 11: ERP Similarity Score: -0.0400
    Run 4, Batch 12: ERP Similarity Score: -0.0450
    Run 4, Batch 13: ERP Similarity Score: -0.0465
    Run 4, Batch 14: ERP Similarity Score: -0.0445
    Run 4, Batch 15: ERP Similarity Score: -0.0442
    Run 4, Batch 16: ERP Similarity Score: -0.0515
    Run 4, Batch 17: ERP Similarity Score: -0.0538
    Run 4, Batch 18: ERP Similarity Score: -0.0524
    Run 4, Batch 19: ERP Similarity Score: -0.0523
    Run 4, Batch 20: ERP Similarity Score: -0.0411
    Run 4, Batch 21: ERP Similarity Score: -0.0375
    Run 4, Batch 22: ERP Similarity Score: -0.0435
    Run 4, Batch 23: ERP Similarity Score: -0.0486
    Run 4, Batch 24: ERP Similarity Score: -0.0404
    Run 4, Batch 25: ERP Similarity Score: -0.0407
    Run 4, Batch 26: ERP Similarity Score: -0.0389
    Run 4, Batch 27: ERP Similarity Score: -0.0582
    Run 4, Batch 28: ERP Similarity Score: -0.0499
    Run 4, Batch 29: ERP Similarity Score: -0.0521
    Run 4, Batch 30: ERP Similarity Score: -0.0435

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=72.7357, G Loss (Comb)=2.1010
Epoch 50/1000: D Loss=-1.6061, G Loss (Comb)=-1.7634
Epoch 100/1000: D Loss=-0.4295, G Loss (Comb)=-4.4927
Epoch 150/1000: D Loss=-0.4428, G Loss (Comb)=-3.7744
Epoch 200/1000: D Loss=-0.5023, G Loss (Comb)=-3.6409
Epoch 250/1000: D Loss=-0.3937, G Loss (Comb)=-3.3547
Epoch 300/1000: D Loss=-0.3180, G Loss (Comb)=-2.4281
Epoch 350/1000: D Loss=-0.3051, G Loss (Comb)=-2.1596
Epoch 400/1000: D Loss=-0.3963, G Loss (Comb)=-2.2307
Epoch 450/1000: D Loss=-0.4516, G Loss (Comb)=-1.7921
Epoch 500/1000: D Loss=-0.4022, G Loss (Comb)=-2.2398
Epoch 550/1000: D Loss=-0.4435, G Loss (Comb)=-1.8970
Epoch 600/1000: D Loss=-0.5575, G Loss (Comb)=-1.9811
Epoch 650/1000: D Loss=-0.5369, G Loss (Comb)=-1.7696
Epoch 700/1000: D Loss=-0.5380, G Loss (Comb)=-1.6519
Epoch 750/1000: D Loss=-0.5649, G Loss (Comb)=-2.1359
Epoch 800/1000: D Loss=-0.6222, G Loss (Comb)=-1.7257
Epoch 850/1000: D Loss=-0.6576, G Loss (Comb)=-2.1755
Epoch 900/1000: D Loss=-0.5710, G Loss (Comb)=-2.2839
Epoch 950/1000: D Loss=-0.7812, G Loss (Comb)=-2.1807
Epoch 999/1000: D Loss=-0.7305, G Loss (Comb)=-2.1106

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0502
    Run 5, Batch 2: ERP Similarity Score: -0.0466
    Run 5, Batch 3: ERP Similarity Score: -0.0422
    Run 5, Batch 4: ERP Similarity Score: -0.0441
    Run 5, Batch 5: ERP Similarity Score: -0.0444
    Run 5, Batch 6: ERP Similarity Score: -0.0505
    Run 5, Batch 7: ERP Similarity Score: -0.0425
    Run 5, Batch 8: ERP Similarity Score: -0.0523
    Run 5, Batch 9: ERP Similarity Score: -0.0443
    Run 5, Batch 10: ERP Similarity Score: -0.0397
    Run 5, Batch 11: ERP Similarity Score: -0.0455
    Run 5, Batch 12: ERP Similarity Score: -0.0533
    Run 5, Batch 13: ERP Similarity Score: -0.0388
    Run 5, Batch 14: ERP Similarity Score: -0.0415
    Run 5, Batch 15: ERP Similarity Score: -0.0505
    Run 5, Batch 16: ERP Similarity Score: -0.0391
    Run 5, Batch 17: ERP Similarity Score: -0.0491
    Run 5, Batch 18: ERP Similarity Score: -0.0488
    Run 5, Batch 19: ERP Similarity Score: -0.0448
    Run 5, Batch 20: ERP Similarity Score: -0.0471
    Run 5, Batch 21: ERP Similarity Score: -0.0497
    Run 5, Batch 22: ERP Similarity Score: -0.0462
    Run 5, Batch 23: ERP Similarity Score: -0.0504
    Run 5, Batch 24: ERP Similarity Score: -0.0464
    Run 5, Batch 25: ERP Similarity Score: -0.0440
    Run 5, Batch 26: ERP Similarity Score: -0.0446
    Run 5, Batch 27: ERP Similarity Score: -0.0427
    Run 5, Batch 28: ERP Similarity Score: -0.0399
    Run 5, Batch 29: ERP Similarity Score: -0.0403
    Run 5, Batch 30: ERP Similarity Score: -0.0549


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 4, Batch 21, Score: -0.0375
  Top 2: Run 5, Batch 13, Score: -0.0388
  Top 3: Run 4, Batch 26, Score: -0.0389
  Top 4: Run 5, Batch 16, Score: -0.0391
  Top 5: Run 5, Batch 10, Score: -0.0397
  Top 6: Run 5, Batch 28, Score: -0.0399
  Top 7: Run 4, Batch 11, Score: -0.0400
  Top 8: Run 5, Batch 29, Score: -0.0403
  Top 9: Run 4, Batch 24, Score: -0.0404
  Top 10: Run 4, Batch 25, Score: -0.0407

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 4, Batch 21, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 5, Batch 13, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 5, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 26, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 16, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 10, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 28, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 11, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 29, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 5, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 24, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 13 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 26, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0389
  - Strategy (Run 5, Batch 16, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0391
  - Strategy (Run 5, Batch 10, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0397
  - Strategy (Run 5, Batch 10, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0397
  - Strategy (Run 5, Batch 28, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0399
  - Strategy (Run 5, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0399
  - Strategy (Run 4, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0400
  - Strategy (Run 4, Batch 11, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0400
  - Strategy (Run 5, Batch 29, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0403
  - Strategy (Run 5, Batch 29, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0403
  - Strategy (Run 4, Batch 24, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0404
  - Strategy (Run 4, Batch 24, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0404
  - Strategy (Run 4, Batch 25, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0407

Selected best strategy: Run 4, Batch 26, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 66.67%) -> REAL test accuracy: 66.67%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 75.00%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H1_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H1_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
