Log for Subject Pair 1-2 from H11
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H11 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 171 clean Target and 407 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 353

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 23

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 69.57%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=59.6309, G Loss (Comb)=-0.6305
Epoch 50/1000: D Loss=-1.6952, G Loss (Comb)=-2.1111
Epoch 100/1000: D Loss=-0.6393, G Loss (Comb)=-4.7481
Epoch 150/1000: D Loss=-0.6128, G Loss (Comb)=-4.6571
Epoch 200/1000: D Loss=-0.4395, G Loss (Comb)=-4.7779
Epoch 250/1000: D Loss=-0.3151, G Loss (Comb)=-4.3732
Epoch 300/1000: D Loss=-0.4456, G Loss (Comb)=-3.8096
Epoch 350/1000: D Loss=-0.3413, G Loss (Comb)=-3.8056
Epoch 400/1000: D Loss=-0.5964, G Loss (Comb)=-3.2156
Epoch 450/1000: D Loss=-0.6272, G Loss (Comb)=-3.3164
Epoch 500/1000: D Loss=-0.7475, G Loss (Comb)=-3.3389
Epoch 550/1000: D Loss=-0.8756, G Loss (Comb)=-3.2098
Epoch 600/1000: D Loss=-0.8936, G Loss (Comb)=-3.0816
Epoch 650/1000: D Loss=-1.0849, G Loss (Comb)=-2.9903
Epoch 700/1000: D Loss=-1.1243, G Loss (Comb)=-2.7921
Epoch 750/1000: D Loss=-1.1283, G Loss (Comb)=-3.0996
Epoch 800/1000: D Loss=-1.3073, G Loss (Comb)=-3.0532
Epoch 850/1000: D Loss=-1.3400, G Loss (Comb)=-2.9672
Epoch 900/1000: D Loss=-1.3763, G Loss (Comb)=-2.8642
Epoch 950/1000: D Loss=-1.5188, G Loss (Comb)=-2.8983
Epoch 999/1000: D Loss=-1.5056, G Loss (Comb)=-2.7044

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0543
    Run 1, Batch 2: ERP Similarity Score: -0.0532
    Run 1, Batch 3: ERP Similarity Score: -0.0593
    Run 1, Batch 4: ERP Similarity Score: -0.0559
    Run 1, Batch 5: ERP Similarity Score: -0.0591
    Run 1, Batch 6: ERP Similarity Score: -0.0577
    Run 1, Batch 7: ERP Similarity Score: -0.0582
    Run 1, Batch 8: ERP Similarity Score: -0.0548
    Run 1, Batch 9: ERP Similarity Score: -0.0541
    Run 1, Batch 10: ERP Similarity Score: -0.0545
    Run 1, Batch 11: ERP Similarity Score: -0.0607
    Run 1, Batch 12: ERP Similarity Score: -0.0564
    Run 1, Batch 13: ERP Similarity Score: -0.0565
    Run 1, Batch 14: ERP Similarity Score: -0.0593
    Run 1, Batch 15: ERP Similarity Score: -0.0544
    Run 1, Batch 16: ERP Similarity Score: -0.0529
    Run 1, Batch 17: ERP Similarity Score: -0.0564
    Run 1, Batch 18: ERP Similarity Score: -0.0594
    Run 1, Batch 19: ERP Similarity Score: -0.0528
    Run 1, Batch 20: ERP Similarity Score: -0.0575
    Run 1, Batch 21: ERP Similarity Score: -0.0499
    Run 1, Batch 22: ERP Similarity Score: -0.0572
    Run 1, Batch 23: ERP Similarity Score: -0.0598
    Run 1, Batch 24: ERP Similarity Score: -0.0618
    Run 1, Batch 25: ERP Similarity Score: -0.0498
    Run 1, Batch 26: ERP Similarity Score: -0.0499
    Run 1, Batch 27: ERP Similarity Score: -0.0536
    Run 1, Batch 28: ERP Similarity Score: -0.0573
    Run 1, Batch 29: ERP Similarity Score: -0.0515
    Run 1, Batch 30: ERP Similarity Score: -0.0538

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=65.8130, G Loss (Comb)=1.0947
Epoch 50/1000: D Loss=-1.2867, G Loss (Comb)=-0.6752
Epoch 100/1000: D Loss=-0.6662, G Loss (Comb)=-2.0697
Epoch 150/1000: D Loss=-0.5375, G Loss (Comb)=-1.8474
Epoch 200/1000: D Loss=-0.4567, G Loss (Comb)=-1.5231
Epoch 250/1000: D Loss=-0.4677, G Loss (Comb)=-1.4012
Epoch 300/1000: D Loss=-0.5220, G Loss (Comb)=-0.7868
Epoch 350/1000: D Loss=-0.5262, G Loss (Comb)=-0.9161
Epoch 400/1000: D Loss=-0.6423, G Loss (Comb)=-0.7051
Epoch 450/1000: D Loss=-0.6439, G Loss (Comb)=-0.9562
Epoch 500/1000: D Loss=-0.8172, G Loss (Comb)=-0.5325
Epoch 550/1000: D Loss=-0.9391, G Loss (Comb)=-0.4253
Epoch 600/1000: D Loss=-1.0350, G Loss (Comb)=-0.6019
Epoch 650/1000: D Loss=-1.1374, G Loss (Comb)=-0.5408
Epoch 700/1000: D Loss=-1.2131, G Loss (Comb)=-0.6704
Epoch 750/1000: D Loss=-1.2232, G Loss (Comb)=-0.8903
Epoch 800/1000: D Loss=-1.3350, G Loss (Comb)=-0.7616
Epoch 850/1000: D Loss=-1.3958, G Loss (Comb)=-0.9738
Epoch 900/1000: D Loss=-1.3443, G Loss (Comb)=-0.7593
Epoch 950/1000: D Loss=-1.5220, G Loss (Comb)=-0.9519
Epoch 999/1000: D Loss=-1.5046, G Loss (Comb)=-0.8500

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0722
    Run 2, Batch 2: ERP Similarity Score: -0.0636
    Run 2, Batch 3: ERP Similarity Score: -0.0688
    Run 2, Batch 4: ERP Similarity Score: -0.0743
    Run 2, Batch 5: ERP Similarity Score: -0.0671
    Run 2, Batch 6: ERP Similarity Score: -0.0704
    Run 2, Batch 7: ERP Similarity Score: -0.0695
    Run 2, Batch 8: ERP Similarity Score: -0.0693
    Run 2, Batch 9: ERP Similarity Score: -0.0686
    Run 2, Batch 10: ERP Similarity Score: -0.0680
    Run 2, Batch 11: ERP Similarity Score: -0.0648
    Run 2, Batch 12: ERP Similarity Score: -0.0743
    Run 2, Batch 13: ERP Similarity Score: -0.0715
    Run 2, Batch 14: ERP Similarity Score: -0.0649
    Run 2, Batch 15: ERP Similarity Score: -0.0754
    Run 2, Batch 16: ERP Similarity Score: -0.0684
    Run 2, Batch 17: ERP Similarity Score: -0.0815
    Run 2, Batch 18: ERP Similarity Score: -0.0703
    Run 2, Batch 19: ERP Similarity Score: -0.0667
    Run 2, Batch 20: ERP Similarity Score: -0.0695
    Run 2, Batch 21: ERP Similarity Score: -0.0766
    Run 2, Batch 22: ERP Similarity Score: -0.0713
    Run 2, Batch 23: ERP Similarity Score: -0.0640
    Run 2, Batch 24: ERP Similarity Score: -0.0730
    Run 2, Batch 25: ERP Similarity Score: -0.0695
    Run 2, Batch 26: ERP Similarity Score: -0.0901
    Run 2, Batch 27: ERP Similarity Score: -0.0710
    Run 2, Batch 28: ERP Similarity Score: -0.0647
    Run 2, Batch 29: ERP Similarity Score: -0.0639
    Run 2, Batch 30: ERP Similarity Score: -0.0701

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=61.0146, G Loss (Comb)=0.5308
Epoch 50/1000: D Loss=-1.4090, G Loss (Comb)=-2.3211
Epoch 100/1000: D Loss=-0.7903, G Loss (Comb)=-4.0474
Epoch 150/1000: D Loss=-0.4551, G Loss (Comb)=-3.8460
Epoch 200/1000: D Loss=-0.3922, G Loss (Comb)=-4.0253
Epoch 250/1000: D Loss=-0.4543, G Loss (Comb)=-3.5888
Epoch 300/1000: D Loss=-0.5032, G Loss (Comb)=-3.5696
Epoch 350/1000: D Loss=-0.5296, G Loss (Comb)=-3.3615
Epoch 400/1000: D Loss=-0.5456, G Loss (Comb)=-3.1754
Epoch 450/1000: D Loss=-0.6110, G Loss (Comb)=-2.8949
Epoch 500/1000: D Loss=-0.7573, G Loss (Comb)=-2.6275
Epoch 550/1000: D Loss=-0.8163, G Loss (Comb)=-2.6228
Epoch 600/1000: D Loss=-0.9487, G Loss (Comb)=-2.4684
Epoch 650/1000: D Loss=-1.1269, G Loss (Comb)=-2.4674
Epoch 700/1000: D Loss=-0.9877, G Loss (Comb)=-2.3842
Epoch 750/1000: D Loss=-1.1757, G Loss (Comb)=-2.2698
Epoch 800/1000: D Loss=-1.2121, G Loss (Comb)=-2.1785
Epoch 850/1000: D Loss=-1.3794, G Loss (Comb)=-2.1610
Epoch 900/1000: D Loss=-1.3448, G Loss (Comb)=-1.8615
Epoch 950/1000: D Loss=-1.4086, G Loss (Comb)=-1.7321
Epoch 999/1000: D Loss=-1.4257, G Loss (Comb)=-1.6794

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0614
    Run 3, Batch 2: ERP Similarity Score: -0.0452
    Run 3, Batch 3: ERP Similarity Score: -0.0576
    Run 3, Batch 4: ERP Similarity Score: -0.0507
    Run 3, Batch 5: ERP Similarity Score: -0.0495
    Run 3, Batch 6: ERP Similarity Score: -0.0513
    Run 3, Batch 7: ERP Similarity Score: -0.0528
    Run 3, Batch 8: ERP Similarity Score: -0.0544
    Run 3, Batch 9: ERP Similarity Score: -0.0505
    Run 3, Batch 10: ERP Similarity Score: -0.0512
    Run 3, Batch 11: ERP Similarity Score: -0.0570
    Run 3, Batch 12: ERP Similarity Score: -0.0551
    Run 3, Batch 13: ERP Similarity Score: -0.0548
    Run 3, Batch 14: ERP Similarity Score: -0.0534
    Run 3, Batch 15: ERP Similarity Score: -0.0522
    Run 3, Batch 16: ERP Similarity Score: -0.0525
    Run 3, Batch 17: ERP Similarity Score: -0.0456
    Run 3, Batch 18: ERP Similarity Score: -0.0511
    Run 3, Batch 19: ERP Similarity Score: -0.0552
    Run 3, Batch 20: ERP Similarity Score: -0.0537
    Run 3, Batch 21: ERP Similarity Score: -0.0526
    Run 3, Batch 22: ERP Similarity Score: -0.0555
    Run 3, Batch 23: ERP Similarity Score: -0.0596
    Run 3, Batch 24: ERP Similarity Score: -0.0542
    Run 3, Batch 25: ERP Similarity Score: -0.0540
    Run 3, Batch 26: ERP Similarity Score: -0.0443
    Run 3, Batch 27: ERP Similarity Score: -0.0534
    Run 3, Batch 28: ERP Similarity Score: -0.0537
    Run 3, Batch 29: ERP Similarity Score: -0.0532
    Run 3, Batch 30: ERP Similarity Score: -0.0502

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=62.9937, G Loss (Comb)=1.5886
Epoch 50/1000: D Loss=-1.4458, G Loss (Comb)=-1.9293
Epoch 100/1000: D Loss=-0.6673, G Loss (Comb)=-4.0029
Epoch 150/1000: D Loss=-0.6496, G Loss (Comb)=-3.5498
Epoch 200/1000: D Loss=-0.5735, G Loss (Comb)=-3.2780
Epoch 250/1000: D Loss=-0.3652, G Loss (Comb)=-2.1544
Epoch 300/1000: D Loss=-0.4794, G Loss (Comb)=-2.6000
Epoch 350/1000: D Loss=-0.5354, G Loss (Comb)=-1.9032
Epoch 400/1000: D Loss=-0.4648, G Loss (Comb)=-2.0224
Epoch 450/1000: D Loss=-0.4959, G Loss (Comb)=-1.6250
Epoch 500/1000: D Loss=-0.6560, G Loss (Comb)=-1.6468
Epoch 550/1000: D Loss=-0.7523, G Loss (Comb)=-1.5531
Epoch 600/1000: D Loss=-0.8608, G Loss (Comb)=-1.6468
Epoch 650/1000: D Loss=-0.8520, G Loss (Comb)=-1.6440
Epoch 700/1000: D Loss=-0.9680, G Loss (Comb)=-1.7137
Epoch 750/1000: D Loss=-1.0661, G Loss (Comb)=-1.7006
Epoch 800/1000: D Loss=-1.1879, G Loss (Comb)=-1.6578
Epoch 850/1000: D Loss=-1.1842, G Loss (Comb)=-2.1354
Epoch 900/1000: D Loss=-1.2116, G Loss (Comb)=-2.0012
Epoch 950/1000: D Loss=-1.3463, G Loss (Comb)=-1.8025
Epoch 999/1000: D Loss=-1.4072, G Loss (Comb)=-1.9704

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0551
    Run 4, Batch 2: ERP Similarity Score: -0.0581
    Run 4, Batch 3: ERP Similarity Score: -0.0618
    Run 4, Batch 4: ERP Similarity Score: -0.0523
    Run 4, Batch 5: ERP Similarity Score: -0.0590
    Run 4, Batch 6: ERP Similarity Score: -0.0584
    Run 4, Batch 7: ERP Similarity Score: -0.0558
    Run 4, Batch 8: ERP Similarity Score: -0.0582
    Run 4, Batch 9: ERP Similarity Score: -0.0560
    Run 4, Batch 10: ERP Similarity Score: -0.0577
    Run 4, Batch 11: ERP Similarity Score: -0.0539
    Run 4, Batch 12: ERP Similarity Score: -0.0616
    Run 4, Batch 13: ERP Similarity Score: -0.0549
    Run 4, Batch 14: ERP Similarity Score: -0.0548
    Run 4, Batch 15: ERP Similarity Score: -0.0572
    Run 4, Batch 16: ERP Similarity Score: -0.0561
    Run 4, Batch 17: ERP Similarity Score: -0.0530
    Run 4, Batch 18: ERP Similarity Score: -0.0552
    Run 4, Batch 19: ERP Similarity Score: -0.0549
    Run 4, Batch 20: ERP Similarity Score: -0.0648
    Run 4, Batch 21: ERP Similarity Score: -0.0613
    Run 4, Batch 22: ERP Similarity Score: -0.0563
    Run 4, Batch 23: ERP Similarity Score: -0.0517
    Run 4, Batch 24: ERP Similarity Score: -0.0480
    Run 4, Batch 25: ERP Similarity Score: -0.0533
    Run 4, Batch 26: ERP Similarity Score: -0.0582
    Run 4, Batch 27: ERP Similarity Score: -0.0578
    Run 4, Batch 28: ERP Similarity Score: -0.0487
    Run 4, Batch 29: ERP Similarity Score: -0.0581
    Run 4, Batch 30: ERP Similarity Score: -0.0497

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=64.6632, G Loss (Comb)=1.5055
Epoch 50/1000: D Loss=-1.4346, G Loss (Comb)=-0.4460
Epoch 100/1000: D Loss=-0.5226, G Loss (Comb)=-2.7733
Epoch 150/1000: D Loss=-0.5480, G Loss (Comb)=-3.0034
Epoch 200/1000: D Loss=-0.5261, G Loss (Comb)=-2.8437
Epoch 250/1000: D Loss=-0.5210, G Loss (Comb)=-2.0542
Epoch 300/1000: D Loss=-0.4083, G Loss (Comb)=-2.6655
Epoch 350/1000: D Loss=-0.4800, G Loss (Comb)=-2.0123
Epoch 400/1000: D Loss=-0.6236, G Loss (Comb)=-1.0486
Epoch 450/1000: D Loss=-0.7365, G Loss (Comb)=-1.2650
Epoch 500/1000: D Loss=-0.7191, G Loss (Comb)=-1.2380
Epoch 550/1000: D Loss=-0.7824, G Loss (Comb)=-0.9586
Epoch 600/1000: D Loss=-0.9133, G Loss (Comb)=-0.9891
Epoch 650/1000: D Loss=-1.1140, G Loss (Comb)=-0.8808
Epoch 700/1000: D Loss=-1.0785, G Loss (Comb)=-0.7582
Epoch 750/1000: D Loss=-1.2115, G Loss (Comb)=-0.9058
Epoch 800/1000: D Loss=-1.2285, G Loss (Comb)=-0.9065
Epoch 850/1000: D Loss=-1.2922, G Loss (Comb)=-0.8912
Epoch 900/1000: D Loss=-1.2833, G Loss (Comb)=-0.9365
Epoch 950/1000: D Loss=-1.3415, G Loss (Comb)=-0.8562
Epoch 999/1000: D Loss=-1.4391, G Loss (Comb)=-0.8263

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0589
    Run 5, Batch 2: ERP Similarity Score: -0.0618
    Run 5, Batch 3: ERP Similarity Score: -0.0562
    Run 5, Batch 4: ERP Similarity Score: -0.0528
    Run 5, Batch 5: ERP Similarity Score: -0.0545
    Run 5, Batch 6: ERP Similarity Score: -0.0626
    Run 5, Batch 7: ERP Similarity Score: -0.0571
    Run 5, Batch 8: ERP Similarity Score: -0.0576
    Run 5, Batch 9: ERP Similarity Score: -0.0638
    Run 5, Batch 10: ERP Similarity Score: -0.0608
    Run 5, Batch 11: ERP Similarity Score: -0.0717
    Run 5, Batch 12: ERP Similarity Score: -0.0588
    Run 5, Batch 13: ERP Similarity Score: -0.0507
    Run 5, Batch 14: ERP Similarity Score: -0.0541
    Run 5, Batch 15: ERP Similarity Score: -0.0488
    Run 5, Batch 16: ERP Similarity Score: -0.0527
    Run 5, Batch 17: ERP Similarity Score: -0.0653
    Run 5, Batch 18: ERP Similarity Score: -0.0504
    Run 5, Batch 19: ERP Similarity Score: -0.0547
    Run 5, Batch 20: ERP Similarity Score: -0.0478
    Run 5, Batch 21: ERP Similarity Score: -0.0513
    Run 5, Batch 22: ERP Similarity Score: -0.0563
    Run 5, Batch 23: ERP Similarity Score: -0.0546
    Run 5, Batch 24: ERP Similarity Score: -0.0523
    Run 5, Batch 25: ERP Similarity Score: -0.0581
    Run 5, Batch 26: ERP Similarity Score: -0.0537
    Run 5, Batch 27: ERP Similarity Score: -0.0612
    Run 5, Batch 28: ERP Similarity Score: -0.0556
    Run 5, Batch 29: ERP Similarity Score: -0.0563
    Run 5, Batch 30: ERP Similarity Score: -0.0522


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 26, Score: -0.0443
  Top 2: Run 3, Batch 2, Score: -0.0452
  Top 3: Run 3, Batch 17, Score: -0.0456
  Top 4: Run 5, Batch 20, Score: -0.0478
  Top 5: Run 4, Batch 24, Score: -0.0480
  Top 6: Run 4, Batch 28, Score: -0.0487
  Top 7: Run 5, Batch 15, Score: -0.0488
  Top 8: Run 3, Batch 5, Score: -0.0495
  Top 9: Run 4, Batch 30, Score: -0.0497
  Top 10: Run 1, Batch 25, Score: -0.0498

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 26, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 2, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 3, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 5, Batch 20, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 5, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 4, Batch 28, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 15, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 5, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 30, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 25, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 13 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 26, Ratio 0): Accuracy=100.00, ERP Score=-0.0443
  - Strategy (Run 3, Batch 26, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0443
  - Strategy (Run 3, Batch 26, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0443
  - Strategy (Run 3, Batch 26, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0443
  - Strategy (Run 3, Batch 2, Ratio 0): Accuracy=100.00, ERP Score=-0.0452
  - Strategy (Run 4, Batch 24, Ratio 0): Accuracy=100.00, ERP Score=-0.0480
  - Strategy (Run 4, Batch 24, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0480
  - Strategy (Run 4, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0487
  - Strategy (Run 5, Batch 15, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0488
  - Strategy (Run 3, Batch 5, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0495
  - Strategy (Run 4, Batch 30, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0497
  - Strategy (Run 4, Batch 30, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0497
  - Strategy (Run 1, Batch 25, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0498

Selected best strategy: Run 3, Batch 26, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 82.61%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 82.61%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H11_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H11_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
