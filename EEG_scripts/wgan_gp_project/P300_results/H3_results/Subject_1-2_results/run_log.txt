Log for Subject Pair 1-2 from H3
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H3 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 117 clean Target and 246 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 138

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 8

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 50.00%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=70.6139, G Loss (Comb)=1.7835
Epoch 50/1000: D Loss=-1.4800, G Loss (Comb)=0.1018
Epoch 100/1000: D Loss=-0.6741, G Loss (Comb)=-0.8264
Epoch 150/1000: D Loss=-0.5365, G Loss (Comb)=0.1342
Epoch 200/1000: D Loss=-0.4724, G Loss (Comb)=0.8067
Epoch 250/1000: D Loss=-0.5267, G Loss (Comb)=1.8320
Epoch 300/1000: D Loss=-0.7336, G Loss (Comb)=1.8373
Epoch 350/1000: D Loss=-0.5205, G Loss (Comb)=1.5645
Epoch 400/1000: D Loss=-0.6653, G Loss (Comb)=1.2603
Epoch 450/1000: D Loss=-0.7037, G Loss (Comb)=1.1076
Epoch 500/1000: D Loss=-0.7593, G Loss (Comb)=0.6754
Epoch 550/1000: D Loss=-0.6934, G Loss (Comb)=0.2869
Epoch 600/1000: D Loss=-0.7739, G Loss (Comb)=0.2176
Epoch 650/1000: D Loss=-0.8379, G Loss (Comb)=-0.0752
Epoch 700/1000: D Loss=-0.7813, G Loss (Comb)=-0.0427
Epoch 750/1000: D Loss=-0.9800, G Loss (Comb)=-0.2086
Epoch 800/1000: D Loss=-1.0157, G Loss (Comb)=-0.3651
Epoch 850/1000: D Loss=-0.9897, G Loss (Comb)=-0.6742
Epoch 900/1000: D Loss=-1.1232, G Loss (Comb)=-0.7334
Epoch 950/1000: D Loss=-1.0984, G Loss (Comb)=-0.7509
Epoch 999/1000: D Loss=-1.1283, G Loss (Comb)=-0.6400

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0389
    Run 1, Batch 2: ERP Similarity Score: -0.0402
    Run 1, Batch 3: ERP Similarity Score: -0.0368
    Run 1, Batch 4: ERP Similarity Score: -0.0403
    Run 1, Batch 5: ERP Similarity Score: -0.0381
    Run 1, Batch 6: ERP Similarity Score: -0.0366
    Run 1, Batch 7: ERP Similarity Score: -0.0359
    Run 1, Batch 8: ERP Similarity Score: -0.0415
    Run 1, Batch 9: ERP Similarity Score: -0.0371
    Run 1, Batch 10: ERP Similarity Score: -0.0391
    Run 1, Batch 11: ERP Similarity Score: -0.0414
    Run 1, Batch 12: ERP Similarity Score: -0.0414
    Run 1, Batch 13: ERP Similarity Score: -0.0373
    Run 1, Batch 14: ERP Similarity Score: -0.0392
    Run 1, Batch 15: ERP Similarity Score: -0.0386
    Run 1, Batch 16: ERP Similarity Score: -0.0361
    Run 1, Batch 17: ERP Similarity Score: -0.0373
    Run 1, Batch 18: ERP Similarity Score: -0.0403
    Run 1, Batch 19: ERP Similarity Score: -0.0381
    Run 1, Batch 20: ERP Similarity Score: -0.0405
    Run 1, Batch 21: ERP Similarity Score: -0.0428
    Run 1, Batch 22: ERP Similarity Score: -0.0372
    Run 1, Batch 23: ERP Similarity Score: -0.0410
    Run 1, Batch 24: ERP Similarity Score: -0.0397
    Run 1, Batch 25: ERP Similarity Score: -0.0382
    Run 1, Batch 26: ERP Similarity Score: -0.0411
    Run 1, Batch 27: ERP Similarity Score: -0.0399
    Run 1, Batch 28: ERP Similarity Score: -0.0355
    Run 1, Batch 29: ERP Similarity Score: -0.0352
    Run 1, Batch 30: ERP Similarity Score: -0.0361

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=79.7506, G Loss (Comb)=1.6524
Epoch 50/1000: D Loss=-1.6968, G Loss (Comb)=0.6027
Epoch 100/1000: D Loss=-0.6536, G Loss (Comb)=-1.1326
Epoch 150/1000: D Loss=-0.5886, G Loss (Comb)=-0.4302
Epoch 200/1000: D Loss=-0.6140, G Loss (Comb)=0.2311
Epoch 250/1000: D Loss=-0.4377, G Loss (Comb)=0.5831
Epoch 300/1000: D Loss=-0.5462, G Loss (Comb)=0.9121
Epoch 350/1000: D Loss=-0.6475, G Loss (Comb)=0.3931
Epoch 400/1000: D Loss=-0.4768, G Loss (Comb)=0.7117
Epoch 450/1000: D Loss=-0.6467, G Loss (Comb)=0.6331
Epoch 500/1000: D Loss=-0.7569, G Loss (Comb)=0.6343
Epoch 550/1000: D Loss=-0.6965, G Loss (Comb)=0.3700
Epoch 600/1000: D Loss=-0.8283, G Loss (Comb)=0.2243
Epoch 650/1000: D Loss=-0.7738, G Loss (Comb)=-0.0535
Epoch 700/1000: D Loss=-0.8825, G Loss (Comb)=-0.2408
Epoch 750/1000: D Loss=-0.9192, G Loss (Comb)=-0.2338
Epoch 800/1000: D Loss=-0.9497, G Loss (Comb)=-0.2577
Epoch 850/1000: D Loss=-0.9944, G Loss (Comb)=-0.4294
Epoch 900/1000: D Loss=-1.0503, G Loss (Comb)=-0.5424
Epoch 950/1000: D Loss=-1.0816, G Loss (Comb)=-0.4821
Epoch 999/1000: D Loss=-1.1435, G Loss (Comb)=-0.6768

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0371
    Run 2, Batch 2: ERP Similarity Score: -0.0418
    Run 2, Batch 3: ERP Similarity Score: -0.0376
    Run 2, Batch 4: ERP Similarity Score: -0.0334
    Run 2, Batch 5: ERP Similarity Score: -0.0417
    Run 2, Batch 6: ERP Similarity Score: -0.0374
    Run 2, Batch 7: ERP Similarity Score: -0.0420
    Run 2, Batch 8: ERP Similarity Score: -0.0409
    Run 2, Batch 9: ERP Similarity Score: -0.0454
    Run 2, Batch 10: ERP Similarity Score: -0.0383
    Run 2, Batch 11: ERP Similarity Score: -0.0412
    Run 2, Batch 12: ERP Similarity Score: -0.0369
    Run 2, Batch 13: ERP Similarity Score: -0.0412
    Run 2, Batch 14: ERP Similarity Score: -0.0399
    Run 2, Batch 15: ERP Similarity Score: -0.0413
    Run 2, Batch 16: ERP Similarity Score: -0.0384
    Run 2, Batch 17: ERP Similarity Score: -0.0376
    Run 2, Batch 18: ERP Similarity Score: -0.0429
    Run 2, Batch 19: ERP Similarity Score: -0.0374
    Run 2, Batch 20: ERP Similarity Score: -0.0438
    Run 2, Batch 21: ERP Similarity Score: -0.0373
    Run 2, Batch 22: ERP Similarity Score: -0.0326
    Run 2, Batch 23: ERP Similarity Score: -0.0396
    Run 2, Batch 24: ERP Similarity Score: -0.0390
    Run 2, Batch 25: ERP Similarity Score: -0.0362
    Run 2, Batch 26: ERP Similarity Score: -0.0385
    Run 2, Batch 27: ERP Similarity Score: -0.0419
    Run 2, Batch 28: ERP Similarity Score: -0.0395
    Run 2, Batch 29: ERP Similarity Score: -0.0363
    Run 2, Batch 30: ERP Similarity Score: -0.0354

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=69.8989, G Loss (Comb)=-0.0051
Epoch 50/1000: D Loss=-1.4671, G Loss (Comb)=-1.6927
Epoch 100/1000: D Loss=-0.7439, G Loss (Comb)=-3.6693
Epoch 150/1000: D Loss=-0.4596, G Loss (Comb)=-3.2218
Epoch 200/1000: D Loss=-0.5660, G Loss (Comb)=-2.4580
Epoch 250/1000: D Loss=-0.5541, G Loss (Comb)=-2.1395
Epoch 300/1000: D Loss=-0.4347, G Loss (Comb)=-1.7573
Epoch 350/1000: D Loss=-0.5923, G Loss (Comb)=-2.1005
Epoch 400/1000: D Loss=-0.5586, G Loss (Comb)=-2.2300
Epoch 450/1000: D Loss=-0.5644, G Loss (Comb)=-2.1593
Epoch 500/1000: D Loss=-0.6302, G Loss (Comb)=-2.2004
Epoch 550/1000: D Loss=-0.7039, G Loss (Comb)=-2.1076
Epoch 600/1000: D Loss=-0.7245, G Loss (Comb)=-2.4195
Epoch 650/1000: D Loss=-0.7600, G Loss (Comb)=-2.5928
Epoch 700/1000: D Loss=-0.7575, G Loss (Comb)=-2.4938
Epoch 750/1000: D Loss=-0.8754, G Loss (Comb)=-2.6516
Epoch 800/1000: D Loss=-0.9706, G Loss (Comb)=-2.5897
Epoch 850/1000: D Loss=-0.8822, G Loss (Comb)=-2.7611
Epoch 900/1000: D Loss=-0.9594, G Loss (Comb)=-2.8645
Epoch 950/1000: D Loss=-1.0107, G Loss (Comb)=-2.8787
Epoch 999/1000: D Loss=-1.1215, G Loss (Comb)=-3.0186

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0388
    Run 3, Batch 2: ERP Similarity Score: -0.0433
    Run 3, Batch 3: ERP Similarity Score: -0.0385
    Run 3, Batch 4: ERP Similarity Score: -0.0423
    Run 3, Batch 5: ERP Similarity Score: -0.0419
    Run 3, Batch 6: ERP Similarity Score: -0.0401
    Run 3, Batch 7: ERP Similarity Score: -0.0387
    Run 3, Batch 8: ERP Similarity Score: -0.0412
    Run 3, Batch 9: ERP Similarity Score: -0.0406
    Run 3, Batch 10: ERP Similarity Score: -0.0411
    Run 3, Batch 11: ERP Similarity Score: -0.0405
    Run 3, Batch 12: ERP Similarity Score: -0.0438
    Run 3, Batch 13: ERP Similarity Score: -0.0429
    Run 3, Batch 14: ERP Similarity Score: -0.0401
    Run 3, Batch 15: ERP Similarity Score: -0.0400
    Run 3, Batch 16: ERP Similarity Score: -0.0414
    Run 3, Batch 17: ERP Similarity Score: -0.0459
    Run 3, Batch 18: ERP Similarity Score: -0.0400
    Run 3, Batch 19: ERP Similarity Score: -0.0386
    Run 3, Batch 20: ERP Similarity Score: -0.0432
    Run 3, Batch 21: ERP Similarity Score: -0.0417
    Run 3, Batch 22: ERP Similarity Score: -0.0388
    Run 3, Batch 23: ERP Similarity Score: -0.0375
    Run 3, Batch 24: ERP Similarity Score: -0.0397
    Run 3, Batch 25: ERP Similarity Score: -0.0373
    Run 3, Batch 26: ERP Similarity Score: -0.0440
    Run 3, Batch 27: ERP Similarity Score: -0.0455
    Run 3, Batch 28: ERP Similarity Score: -0.0387
    Run 3, Batch 29: ERP Similarity Score: -0.0410
    Run 3, Batch 30: ERP Similarity Score: -0.0425

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=95.4131, G Loss (Comb)=1.6986
Epoch 50/1000: D Loss=-1.6943, G Loss (Comb)=-0.3726
Epoch 100/1000: D Loss=-0.5641, G Loss (Comb)=-3.9803
Epoch 150/1000: D Loss=-0.4815, G Loss (Comb)=-3.1608
Epoch 200/1000: D Loss=-0.5403, G Loss (Comb)=-2.7838
Epoch 250/1000: D Loss=-0.5936, G Loss (Comb)=-2.2477
Epoch 300/1000: D Loss=-0.5437, G Loss (Comb)=-1.6339
Epoch 350/1000: D Loss=-0.4556, G Loss (Comb)=-2.0142
Epoch 400/1000: D Loss=-0.5319, G Loss (Comb)=-1.6971
Epoch 450/1000: D Loss=-0.6039, G Loss (Comb)=-1.7647
Epoch 500/1000: D Loss=-0.5952, G Loss (Comb)=-1.3864
Epoch 550/1000: D Loss=-0.7158, G Loss (Comb)=-1.7760
Epoch 600/1000: D Loss=-0.8370, G Loss (Comb)=-1.9731
Epoch 650/1000: D Loss=-0.8205, G Loss (Comb)=-2.1587
Epoch 700/1000: D Loss=-0.8253, G Loss (Comb)=-2.2060
Epoch 750/1000: D Loss=-0.9369, G Loss (Comb)=-2.1918
Epoch 800/1000: D Loss=-0.8925, G Loss (Comb)=-2.3604
Epoch 850/1000: D Loss=-1.0115, G Loss (Comb)=-2.5681
Epoch 900/1000: D Loss=-0.9459, G Loss (Comb)=-2.5278
Epoch 950/1000: D Loss=-0.9740, G Loss (Comb)=-2.4028
Epoch 999/1000: D Loss=-1.0181, G Loss (Comb)=-2.5742

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0393
    Run 4, Batch 2: ERP Similarity Score: -0.0389
    Run 4, Batch 3: ERP Similarity Score: -0.0427
    Run 4, Batch 4: ERP Similarity Score: -0.0389
    Run 4, Batch 5: ERP Similarity Score: -0.0390
    Run 4, Batch 6: ERP Similarity Score: -0.0377
    Run 4, Batch 7: ERP Similarity Score: -0.0389
    Run 4, Batch 8: ERP Similarity Score: -0.0401
    Run 4, Batch 9: ERP Similarity Score: -0.0419
    Run 4, Batch 10: ERP Similarity Score: -0.0408
    Run 4, Batch 11: ERP Similarity Score: -0.0365
    Run 4, Batch 12: ERP Similarity Score: -0.0372
    Run 4, Batch 13: ERP Similarity Score: -0.0369
    Run 4, Batch 14: ERP Similarity Score: -0.0381
    Run 4, Batch 15: ERP Similarity Score: -0.0364
    Run 4, Batch 16: ERP Similarity Score: -0.0348
    Run 4, Batch 17: ERP Similarity Score: -0.0401
    Run 4, Batch 18: ERP Similarity Score: -0.0401
    Run 4, Batch 19: ERP Similarity Score: -0.0390
    Run 4, Batch 20: ERP Similarity Score: -0.0429
    Run 4, Batch 21: ERP Similarity Score: -0.0414
    Run 4, Batch 22: ERP Similarity Score: -0.0377
    Run 4, Batch 23: ERP Similarity Score: -0.0442
    Run 4, Batch 24: ERP Similarity Score: -0.0366
    Run 4, Batch 25: ERP Similarity Score: -0.0381
    Run 4, Batch 26: ERP Similarity Score: -0.0407
    Run 4, Batch 27: ERP Similarity Score: -0.0464
    Run 4, Batch 28: ERP Similarity Score: -0.0351
    Run 4, Batch 29: ERP Similarity Score: -0.0401
    Run 4, Batch 30: ERP Similarity Score: -0.0378

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=74.9817, G Loss (Comb)=-0.1607
Epoch 50/1000: D Loss=-1.4722, G Loss (Comb)=-1.6042
Epoch 100/1000: D Loss=-0.6598, G Loss (Comb)=-3.4949
Epoch 150/1000: D Loss=-0.3872, G Loss (Comb)=-3.6570
Epoch 200/1000: D Loss=-0.5709, G Loss (Comb)=-3.0765
Epoch 250/1000: D Loss=-0.5405, G Loss (Comb)=-2.3700
Epoch 300/1000: D Loss=-0.6865, G Loss (Comb)=-2.2980
Epoch 350/1000: D Loss=-0.5612, G Loss (Comb)=-2.6845
Epoch 400/1000: D Loss=-0.5647, G Loss (Comb)=-2.6495
Epoch 450/1000: D Loss=-0.6028, G Loss (Comb)=-2.6536
Epoch 500/1000: D Loss=-0.7185, G Loss (Comb)=-2.5769
Epoch 550/1000: D Loss=-0.7287, G Loss (Comb)=-2.8494
Epoch 600/1000: D Loss=-0.8569, G Loss (Comb)=-3.0119
Epoch 650/1000: D Loss=-0.8669, G Loss (Comb)=-3.1223
Epoch 700/1000: D Loss=-0.9383, G Loss (Comb)=-3.0155
Epoch 750/1000: D Loss=-0.9268, G Loss (Comb)=-2.9240
Epoch 800/1000: D Loss=-0.9895, G Loss (Comb)=-3.0472
Epoch 850/1000: D Loss=-1.0590, G Loss (Comb)=-2.9035
Epoch 900/1000: D Loss=-1.0197, G Loss (Comb)=-2.8883
Epoch 950/1000: D Loss=-1.0541, G Loss (Comb)=-2.8393
Epoch 999/1000: D Loss=-1.0504, G Loss (Comb)=-2.7530

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0365
    Run 5, Batch 2: ERP Similarity Score: -0.0403
    Run 5, Batch 3: ERP Similarity Score: -0.0367
    Run 5, Batch 4: ERP Similarity Score: -0.0410
    Run 5, Batch 5: ERP Similarity Score: -0.0412
    Run 5, Batch 6: ERP Similarity Score: -0.0416
    Run 5, Batch 7: ERP Similarity Score: -0.0385
    Run 5, Batch 8: ERP Similarity Score: -0.0350
    Run 5, Batch 9: ERP Similarity Score: -0.0391
    Run 5, Batch 10: ERP Similarity Score: -0.0343
    Run 5, Batch 11: ERP Similarity Score: -0.0351
    Run 5, Batch 12: ERP Similarity Score: -0.0377
    Run 5, Batch 13: ERP Similarity Score: -0.0394
    Run 5, Batch 14: ERP Similarity Score: -0.0389
    Run 5, Batch 15: ERP Similarity Score: -0.0426
    Run 5, Batch 16: ERP Similarity Score: -0.0403
    Run 5, Batch 17: ERP Similarity Score: -0.0404
    Run 5, Batch 18: ERP Similarity Score: -0.0358
    Run 5, Batch 19: ERP Similarity Score: -0.0370
    Run 5, Batch 20: ERP Similarity Score: -0.0357
    Run 5, Batch 21: ERP Similarity Score: -0.0365
    Run 5, Batch 22: ERP Similarity Score: -0.0402
    Run 5, Batch 23: ERP Similarity Score: -0.0418
    Run 5, Batch 24: ERP Similarity Score: -0.0402
    Run 5, Batch 25: ERP Similarity Score: -0.0397
    Run 5, Batch 26: ERP Similarity Score: -0.0371
    Run 5, Batch 27: ERP Similarity Score: -0.0373
    Run 5, Batch 28: ERP Similarity Score: -0.0365
    Run 5, Batch 29: ERP Similarity Score: -0.0403
    Run 5, Batch 30: ERP Similarity Score: -0.0377


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 2, Batch 22, Score: -0.0326
  Top 2: Run 2, Batch 4, Score: -0.0334
  Top 3: Run 5, Batch 10, Score: -0.0343
  Top 4: Run 4, Batch 16, Score: -0.0348
  Top 5: Run 5, Batch 8, Score: -0.0350
  Top 6: Run 5, Batch 11, Score: -0.0351
  Top 7: Run 4, Batch 28, Score: -0.0351
  Top 8: Run 1, Batch 29, Score: -0.0352
  Top 9: Run 2, Batch 30, Score: -0.0354
  Top 10: Run 1, Batch 28, Score: -0.0355

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 2, Batch 22, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 2, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 2, Batch 4, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 2, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 10, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 16, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 8, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 11, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 5, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 5, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 28, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 29, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 2, Batch 30, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 2, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 0.00%
    Run 1, Batch 28, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 33.33%

Found 7 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 2, Batch 4, Ratio 0): Accuracy=100.00, ERP Score=-0.0334
  - Strategy (Run 2, Batch 4, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0334
  - Strategy (Run 2, Batch 4, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0334
  - Strategy (Run 5, Batch 8, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0350
  - Strategy (Run 5, Batch 11, Ratio 0): Accuracy=100.00, ERP Score=-0.0351
  - Strategy (Run 4, Batch 28, Ratio 0): Accuracy=100.00, ERP Score=-0.0351
  - Strategy (Run 4, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0351

Selected best strategy: Run 2, Batch 4, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 75.00%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 75.00%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H3_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H3_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
