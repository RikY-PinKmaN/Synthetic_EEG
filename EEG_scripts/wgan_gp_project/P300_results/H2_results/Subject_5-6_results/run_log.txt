Log for Subject Pair 5-6 from H2
========================================


========================= PROCESSING SUBJECT PAIR: 5-6 from H2 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 232 clean Target and 880 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 737

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 48

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 56.25%

--- Training cWGAN-GP for Subject 5-6, Run 1 ---
Epoch 0/1000: D Loss=75.6379, G Loss (Comb)=1.6884
Epoch 50/1000: D Loss=-0.4372, G Loss (Comb)=-3.1135
Epoch 100/1000: D Loss=-0.3383, G Loss (Comb)=-2.6555
Epoch 150/1000: D Loss=-0.2239, G Loss (Comb)=-1.8879
Epoch 200/1000: D Loss=-0.1700, G Loss (Comb)=-2.2468
Epoch 250/1000: D Loss=-0.3456, G Loss (Comb)=-1.7782
Epoch 300/1000: D Loss=-0.2488, G Loss (Comb)=-1.4075
Epoch 350/1000: D Loss=-0.2673, G Loss (Comb)=-1.7016
Epoch 400/1000: D Loss=-0.2791, G Loss (Comb)=-1.7424
Epoch 450/1000: D Loss=-0.3159, G Loss (Comb)=-2.2372
Epoch 500/1000: D Loss=-0.4115, G Loss (Comb)=-2.5741
Epoch 550/1000: D Loss=-0.4588, G Loss (Comb)=-2.9538
Epoch 600/1000: D Loss=-0.5078, G Loss (Comb)=-3.4168
Epoch 650/1000: D Loss=-0.5220, G Loss (Comb)=-3.7514
Epoch 700/1000: D Loss=-0.5305, G Loss (Comb)=-4.0490
Epoch 750/1000: D Loss=-0.5075, G Loss (Comb)=-4.1820
Epoch 800/1000: D Loss=-0.6225, G Loss (Comb)=-4.2353
Epoch 850/1000: D Loss=-0.6691, G Loss (Comb)=-4.3911
Epoch 900/1000: D Loss=-0.6735, G Loss (Comb)=-4.4502
Epoch 950/1000: D Loss=-0.6926, G Loss (Comb)=-4.6483
Epoch 999/1000: D Loss=-0.7012, G Loss (Comb)=-4.6863

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0584
    Run 1, Batch 2: ERP Similarity Score: -0.0501
    Run 1, Batch 3: ERP Similarity Score: -0.0538
    Run 1, Batch 4: ERP Similarity Score: -0.0633
    Run 1, Batch 5: ERP Similarity Score: -0.0565
    Run 1, Batch 6: ERP Similarity Score: -0.0580
    Run 1, Batch 7: ERP Similarity Score: -0.0583
    Run 1, Batch 8: ERP Similarity Score: -0.0611
    Run 1, Batch 9: ERP Similarity Score: -0.0592
    Run 1, Batch 10: ERP Similarity Score: -0.0659
    Run 1, Batch 11: ERP Similarity Score: -0.0588
    Run 1, Batch 12: ERP Similarity Score: -0.0598
    Run 1, Batch 13: ERP Similarity Score: -0.0546
    Run 1, Batch 14: ERP Similarity Score: -0.0573
    Run 1, Batch 15: ERP Similarity Score: -0.0631
    Run 1, Batch 16: ERP Similarity Score: -0.0623
    Run 1, Batch 17: ERP Similarity Score: -0.0583
    Run 1, Batch 18: ERP Similarity Score: -0.0586
    Run 1, Batch 19: ERP Similarity Score: -0.0547
    Run 1, Batch 20: ERP Similarity Score: -0.0548
    Run 1, Batch 21: ERP Similarity Score: -0.0562
    Run 1, Batch 22: ERP Similarity Score: -0.0647
    Run 1, Batch 23: ERP Similarity Score: -0.0636
    Run 1, Batch 24: ERP Similarity Score: -0.0532
    Run 1, Batch 25: ERP Similarity Score: -0.0626
    Run 1, Batch 26: ERP Similarity Score: -0.0585
    Run 1, Batch 27: ERP Similarity Score: -0.0551
    Run 1, Batch 28: ERP Similarity Score: -0.0571
    Run 1, Batch 29: ERP Similarity Score: -0.0550
    Run 1, Batch 30: ERP Similarity Score: -0.0634

--- Training cWGAN-GP for Subject 5-6, Run 2 ---
Epoch 0/1000: D Loss=69.6449, G Loss (Comb)=1.2088
Epoch 50/1000: D Loss=-0.5159, G Loss (Comb)=-3.0686
Epoch 100/1000: D Loss=-0.2917, G Loss (Comb)=-2.5900
Epoch 150/1000: D Loss=-0.3388, G Loss (Comb)=-2.2982
Epoch 200/1000: D Loss=-0.2540, G Loss (Comb)=-1.7573
Epoch 250/1000: D Loss=-0.2581, G Loss (Comb)=-1.4700
Epoch 300/1000: D Loss=-0.2667, G Loss (Comb)=-1.2203
Epoch 350/1000: D Loss=-0.2282, G Loss (Comb)=-0.8681
Epoch 400/1000: D Loss=-0.2149, G Loss (Comb)=-1.0208
Epoch 450/1000: D Loss=-0.2819, G Loss (Comb)=-1.3614
Epoch 500/1000: D Loss=-0.3771, G Loss (Comb)=-1.6112
Epoch 550/1000: D Loss=-0.3991, G Loss (Comb)=-1.9492
Epoch 600/1000: D Loss=-0.4270, G Loss (Comb)=-2.4813
Epoch 650/1000: D Loss=-0.4171, G Loss (Comb)=-2.9621
Epoch 700/1000: D Loss=-0.5147, G Loss (Comb)=-3.1624
Epoch 750/1000: D Loss=-0.5072, G Loss (Comb)=-3.2887
Epoch 800/1000: D Loss=-0.5218, G Loss (Comb)=-3.3148
Epoch 850/1000: D Loss=-0.5509, G Loss (Comb)=-3.3420
Epoch 900/1000: D Loss=-0.6118, G Loss (Comb)=-3.4739
Epoch 950/1000: D Loss=-0.6193, G Loss (Comb)=-3.4181
Epoch 999/1000: D Loss=-0.6264, G Loss (Comb)=-3.4735

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0584
    Run 2, Batch 2: ERP Similarity Score: -0.0609
    Run 2, Batch 3: ERP Similarity Score: -0.0687
    Run 2, Batch 4: ERP Similarity Score: -0.0621
    Run 2, Batch 5: ERP Similarity Score: -0.0666
    Run 2, Batch 6: ERP Similarity Score: -0.0647
    Run 2, Batch 7: ERP Similarity Score: -0.0646
    Run 2, Batch 8: ERP Similarity Score: -0.0642
    Run 2, Batch 9: ERP Similarity Score: -0.0645
    Run 2, Batch 10: ERP Similarity Score: -0.0628
    Run 2, Batch 11: ERP Similarity Score: -0.0588
    Run 2, Batch 12: ERP Similarity Score: -0.0634
    Run 2, Batch 13: ERP Similarity Score: -0.0602
    Run 2, Batch 14: ERP Similarity Score: -0.0702
    Run 2, Batch 15: ERP Similarity Score: -0.0633
    Run 2, Batch 16: ERP Similarity Score: -0.0593
    Run 2, Batch 17: ERP Similarity Score: -0.0665
    Run 2, Batch 18: ERP Similarity Score: -0.0630
    Run 2, Batch 19: ERP Similarity Score: -0.0664
    Run 2, Batch 20: ERP Similarity Score: -0.0643
    Run 2, Batch 21: ERP Similarity Score: -0.0615
    Run 2, Batch 22: ERP Similarity Score: -0.0643
    Run 2, Batch 23: ERP Similarity Score: -0.0628
    Run 2, Batch 24: ERP Similarity Score: -0.0633
    Run 2, Batch 25: ERP Similarity Score: -0.0649
    Run 2, Batch 26: ERP Similarity Score: -0.0606
    Run 2, Batch 27: ERP Similarity Score: -0.0635
    Run 2, Batch 28: ERP Similarity Score: -0.0621
    Run 2, Batch 29: ERP Similarity Score: -0.0616
    Run 2, Batch 30: ERP Similarity Score: -0.0626

--- Training cWGAN-GP for Subject 5-6, Run 3 ---
Epoch 0/1000: D Loss=90.1803, G Loss (Comb)=1.9533
Epoch 50/1000: D Loss=-0.4485, G Loss (Comb)=-2.7610
Epoch 100/1000: D Loss=-0.5431, G Loss (Comb)=-1.8292
Epoch 150/1000: D Loss=-0.3197, G Loss (Comb)=-1.8061
Epoch 200/1000: D Loss=-0.2138, G Loss (Comb)=-1.9359
Epoch 250/1000: D Loss=-0.2931, G Loss (Comb)=-1.3972
Epoch 300/1000: D Loss=-0.2872, G Loss (Comb)=-1.9726
Epoch 350/1000: D Loss=-0.2310, G Loss (Comb)=-1.8800
Epoch 400/1000: D Loss=-0.1880, G Loss (Comb)=-1.9682
Epoch 450/1000: D Loss=-0.2657, G Loss (Comb)=-1.8231
Epoch 500/1000: D Loss=-0.3493, G Loss (Comb)=-2.3309
Epoch 550/1000: D Loss=-0.3383, G Loss (Comb)=-2.7680
Epoch 600/1000: D Loss=-0.3446, G Loss (Comb)=-3.3497
Epoch 650/1000: D Loss=-0.3820, G Loss (Comb)=-3.7161
Epoch 700/1000: D Loss=-0.4414, G Loss (Comb)=-3.9614
Epoch 750/1000: D Loss=-0.4965, G Loss (Comb)=-4.0994
Epoch 800/1000: D Loss=-0.4845, G Loss (Comb)=-4.1890
Epoch 850/1000: D Loss=-0.5388, G Loss (Comb)=-4.1862
Epoch 900/1000: D Loss=-0.6142, G Loss (Comb)=-4.1604
Epoch 950/1000: D Loss=-0.6042, G Loss (Comb)=-4.1838
Epoch 999/1000: D Loss=-0.6291, G Loss (Comb)=-4.3095

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0631
    Run 3, Batch 2: ERP Similarity Score: -0.0639
    Run 3, Batch 3: ERP Similarity Score: -0.0608
    Run 3, Batch 4: ERP Similarity Score: -0.0568
    Run 3, Batch 5: ERP Similarity Score: -0.0603
    Run 3, Batch 6: ERP Similarity Score: -0.0581
    Run 3, Batch 7: ERP Similarity Score: -0.0624
    Run 3, Batch 8: ERP Similarity Score: -0.0580
    Run 3, Batch 9: ERP Similarity Score: -0.0652
    Run 3, Batch 10: ERP Similarity Score: -0.0607
    Run 3, Batch 11: ERP Similarity Score: -0.0647
    Run 3, Batch 12: ERP Similarity Score: -0.0592
    Run 3, Batch 13: ERP Similarity Score: -0.0616
    Run 3, Batch 14: ERP Similarity Score: -0.0618
    Run 3, Batch 15: ERP Similarity Score: -0.0669
    Run 3, Batch 16: ERP Similarity Score: -0.0621
    Run 3, Batch 17: ERP Similarity Score: -0.0585
    Run 3, Batch 18: ERP Similarity Score: -0.0599
    Run 3, Batch 19: ERP Similarity Score: -0.0636
    Run 3, Batch 20: ERP Similarity Score: -0.0605
    Run 3, Batch 21: ERP Similarity Score: -0.0552
    Run 3, Batch 22: ERP Similarity Score: -0.0617
    Run 3, Batch 23: ERP Similarity Score: -0.0573
    Run 3, Batch 24: ERP Similarity Score: -0.0598
    Run 3, Batch 25: ERP Similarity Score: -0.0597
    Run 3, Batch 26: ERP Similarity Score: -0.0630
    Run 3, Batch 27: ERP Similarity Score: -0.0660
    Run 3, Batch 28: ERP Similarity Score: -0.0612
    Run 3, Batch 29: ERP Similarity Score: -0.0653
    Run 3, Batch 30: ERP Similarity Score: -0.0632

--- Training cWGAN-GP for Subject 5-6, Run 4 ---
Epoch 0/1000: D Loss=71.8509, G Loss (Comb)=2.5686
Epoch 50/1000: D Loss=-0.5265, G Loss (Comb)=-1.2595
Epoch 100/1000: D Loss=-0.2793, G Loss (Comb)=0.0379
Epoch 150/1000: D Loss=-0.4275, G Loss (Comb)=0.4451
Epoch 200/1000: D Loss=-0.2511, G Loss (Comb)=0.6645
Epoch 250/1000: D Loss=-0.3509, G Loss (Comb)=1.0407
Epoch 300/1000: D Loss=-0.1649, G Loss (Comb)=0.9159
Epoch 350/1000: D Loss=-0.3501, G Loss (Comb)=0.8982
Epoch 400/1000: D Loss=-0.3993, G Loss (Comb)=0.7360
Epoch 450/1000: D Loss=-0.2796, G Loss (Comb)=0.3981
Epoch 500/1000: D Loss=-0.3314, G Loss (Comb)=0.0704
Epoch 550/1000: D Loss=-0.3078, G Loss (Comb)=-0.4993
Epoch 600/1000: D Loss=-0.3835, G Loss (Comb)=-1.0902
Epoch 650/1000: D Loss=-0.3428, G Loss (Comb)=-1.7229
Epoch 700/1000: D Loss=-0.4567, G Loss (Comb)=-2.0655
Epoch 750/1000: D Loss=-0.4684, G Loss (Comb)=-2.3565
Epoch 800/1000: D Loss=-0.4575, G Loss (Comb)=-2.3972
Epoch 850/1000: D Loss=-0.4941, G Loss (Comb)=-2.5632
Epoch 900/1000: D Loss=-0.5450, G Loss (Comb)=-2.8296
Epoch 950/1000: D Loss=-0.5993, G Loss (Comb)=-2.7459
Epoch 999/1000: D Loss=-0.5999, G Loss (Comb)=-2.7950

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0617
    Run 4, Batch 2: ERP Similarity Score: -0.0524
    Run 4, Batch 3: ERP Similarity Score: -0.0594
    Run 4, Batch 4: ERP Similarity Score: -0.0578
    Run 4, Batch 5: ERP Similarity Score: -0.0498
    Run 4, Batch 6: ERP Similarity Score: -0.0602
    Run 4, Batch 7: ERP Similarity Score: -0.0628
    Run 4, Batch 8: ERP Similarity Score: -0.0616
    Run 4, Batch 9: ERP Similarity Score: -0.0526
    Run 4, Batch 10: ERP Similarity Score: -0.0484
    Run 4, Batch 11: ERP Similarity Score: -0.0518
    Run 4, Batch 12: ERP Similarity Score: -0.0562
    Run 4, Batch 13: ERP Similarity Score: -0.0555
    Run 4, Batch 14: ERP Similarity Score: -0.0598
    Run 4, Batch 15: ERP Similarity Score: -0.0643
    Run 4, Batch 16: ERP Similarity Score: -0.0529
    Run 4, Batch 17: ERP Similarity Score: -0.0541
    Run 4, Batch 18: ERP Similarity Score: -0.0597
    Run 4, Batch 19: ERP Similarity Score: -0.0557
    Run 4, Batch 20: ERP Similarity Score: -0.0505
    Run 4, Batch 21: ERP Similarity Score: -0.0520
    Run 4, Batch 22: ERP Similarity Score: -0.0560
    Run 4, Batch 23: ERP Similarity Score: -0.0622
    Run 4, Batch 24: ERP Similarity Score: -0.0635
    Run 4, Batch 25: ERP Similarity Score: -0.0581
    Run 4, Batch 26: ERP Similarity Score: -0.0539
    Run 4, Batch 27: ERP Similarity Score: -0.0630
    Run 4, Batch 28: ERP Similarity Score: -0.0602
    Run 4, Batch 29: ERP Similarity Score: -0.0523
    Run 4, Batch 30: ERP Similarity Score: -0.0533

--- Training cWGAN-GP for Subject 5-6, Run 5 ---
Epoch 0/1000: D Loss=86.8200, G Loss (Comb)=0.8956
Epoch 50/1000: D Loss=-0.6503, G Loss (Comb)=-2.2646
Epoch 100/1000: D Loss=-0.1905, G Loss (Comb)=-2.0546
Epoch 150/1000: D Loss=-0.3520, G Loss (Comb)=-1.7893
Epoch 200/1000: D Loss=-0.1549, G Loss (Comb)=-2.2057
Epoch 250/1000: D Loss=-0.2615, G Loss (Comb)=-1.6279
Epoch 300/1000: D Loss=-0.2037, G Loss (Comb)=-1.8245
Epoch 350/1000: D Loss=-0.2651, G Loss (Comb)=-1.4236
Epoch 400/1000: D Loss=-0.2864, G Loss (Comb)=-1.7816
Epoch 450/1000: D Loss=-0.2743, G Loss (Comb)=-1.7703
Epoch 500/1000: D Loss=-0.3107, G Loss (Comb)=-2.2149
Epoch 550/1000: D Loss=-0.3339, G Loss (Comb)=-2.5036
Epoch 600/1000: D Loss=-0.3401, G Loss (Comb)=-3.2053
Epoch 650/1000: D Loss=-0.4505, G Loss (Comb)=-3.4602
Epoch 700/1000: D Loss=-0.4319, G Loss (Comb)=-4.0256
Epoch 750/1000: D Loss=-0.4906, G Loss (Comb)=-4.0393
Epoch 800/1000: D Loss=-0.4903, G Loss (Comb)=-4.1880
Epoch 850/1000: D Loss=-0.5614, G Loss (Comb)=-4.2373
Epoch 900/1000: D Loss=-0.5871, G Loss (Comb)=-4.2370
Epoch 950/1000: D Loss=-0.5888, G Loss (Comb)=-4.2900
Epoch 999/1000: D Loss=-0.6475, G Loss (Comb)=-4.4228

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0527
    Run 5, Batch 2: ERP Similarity Score: -0.0610
    Run 5, Batch 3: ERP Similarity Score: -0.0559
    Run 5, Batch 4: ERP Similarity Score: -0.0586
    Run 5, Batch 5: ERP Similarity Score: -0.0473
    Run 5, Batch 6: ERP Similarity Score: -0.0555
    Run 5, Batch 7: ERP Similarity Score: -0.0544
    Run 5, Batch 8: ERP Similarity Score: -0.0552
    Run 5, Batch 9: ERP Similarity Score: -0.0590
    Run 5, Batch 10: ERP Similarity Score: -0.0567
    Run 5, Batch 11: ERP Similarity Score: -0.0540
    Run 5, Batch 12: ERP Similarity Score: -0.0578
    Run 5, Batch 13: ERP Similarity Score: -0.0496
    Run 5, Batch 14: ERP Similarity Score: -0.0580
    Run 5, Batch 15: ERP Similarity Score: -0.0568
    Run 5, Batch 16: ERP Similarity Score: -0.0520
    Run 5, Batch 17: ERP Similarity Score: -0.0577
    Run 5, Batch 18: ERP Similarity Score: -0.0628
    Run 5, Batch 19: ERP Similarity Score: -0.0618
    Run 5, Batch 20: ERP Similarity Score: -0.0582
    Run 5, Batch 21: ERP Similarity Score: -0.0528
    Run 5, Batch 22: ERP Similarity Score: -0.0602
    Run 5, Batch 23: ERP Similarity Score: -0.0579
    Run 5, Batch 24: ERP Similarity Score: -0.0560
    Run 5, Batch 25: ERP Similarity Score: -0.0539
    Run 5, Batch 26: ERP Similarity Score: -0.0589
    Run 5, Batch 27: ERP Similarity Score: -0.0556
    Run 5, Batch 28: ERP Similarity Score: -0.0604
    Run 5, Batch 29: ERP Similarity Score: -0.0571
    Run 5, Batch 30: ERP Similarity Score: -0.0581


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 5, Batch 5, Score: -0.0473
  Top 2: Run 4, Batch 10, Score: -0.0484
  Top 3: Run 5, Batch 13, Score: -0.0496
  Top 4: Run 4, Batch 5, Score: -0.0498
  Top 5: Run 1, Batch 2, Score: -0.0501
  Top 6: Run 4, Batch 20, Score: -0.0505
  Top 7: Run 4, Batch 11, Score: -0.0518
  Top 8: Run 5, Batch 16, Score: -0.0520
  Top 9: Run 4, Batch 21, Score: -0.0520
  Top 10: Run 4, Batch 29, Score: -0.0523

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 5, Batch 5, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 5, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 5, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 10, Strategy 'Synth Only': Validation Acc: 20.00%
    Run 4, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 5, Batch 13, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 5, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 5, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 5, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 5, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 4, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 1, Batch 2, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 1, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 20, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 4, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 4, Batch 11, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 4, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 4, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 4, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 5, Batch 16, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 5, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 5, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 21, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 4, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 4, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 4, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 4, Batch 29, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 4, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 80.00%

Found 6 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 10, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0484
  - Strategy (Run 4, Batch 10, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0484
  - Strategy (Run 1, Batch 2, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0501
  - Strategy (Run 4, Batch 20, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0505
  - Strategy (Run 4, Batch 29, Ratio 0): Accuracy=100.00, ERP Score=-0.0523
  - Strategy (Run 4, Batch 29, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0523

Selected best strategy: Run 4, Batch 10, Strategy: Augmented (25%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 75.00%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (25%), Val Acc: 100.00%) -> REAL test accuracy: 56.25%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H2_results/Subject_5-6_results/accuracy_comparison_S5-6.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 5-6) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H2_results/Subject_5-6_results/GA_ERP_Combined_S5-6_ChCz.png

--- Subject 5-6 processing finished successfully. ---
