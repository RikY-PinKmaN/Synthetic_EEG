Log for Subject Pair 3-4 from H8
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H8 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 270 clean Target and 539 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 584

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 38

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 55.26%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=61.1051, G Loss (Comb)=1.7387
Epoch 50/1000: D Loss=-1.5512, G Loss (Comb)=-0.6245
Epoch 100/1000: D Loss=-0.5038, G Loss (Comb)=-4.3798
Epoch 150/1000: D Loss=-0.3571, G Loss (Comb)=-3.7647
Epoch 200/1000: D Loss=-0.2681, G Loss (Comb)=-4.5544
Epoch 250/1000: D Loss=-0.3203, G Loss (Comb)=-4.1271
Epoch 300/1000: D Loss=-0.2485, G Loss (Comb)=-3.5271
Epoch 350/1000: D Loss=-0.3025, G Loss (Comb)=-2.8675
Epoch 400/1000: D Loss=-0.4319, G Loss (Comb)=-2.7804
Epoch 450/1000: D Loss=-0.4785, G Loss (Comb)=-3.5087
Epoch 500/1000: D Loss=-0.4751, G Loss (Comb)=-3.2266
Epoch 550/1000: D Loss=-0.5316, G Loss (Comb)=-3.0665
Epoch 600/1000: D Loss=-0.5409, G Loss (Comb)=-3.2200
Epoch 650/1000: D Loss=-0.6208, G Loss (Comb)=-3.0579
Epoch 700/1000: D Loss=-0.6666, G Loss (Comb)=-3.1642
Epoch 750/1000: D Loss=-0.6972, G Loss (Comb)=-2.9642
Epoch 800/1000: D Loss=-0.6993, G Loss (Comb)=-2.5505
Epoch 850/1000: D Loss=-0.7935, G Loss (Comb)=-2.9150
Epoch 900/1000: D Loss=-0.7950, G Loss (Comb)=-2.7393
Epoch 950/1000: D Loss=-0.8143, G Loss (Comb)=-2.8570
Epoch 999/1000: D Loss=-0.9151, G Loss (Comb)=-2.8250

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0328
    Run 1, Batch 2: ERP Similarity Score: -0.0313
    Run 1, Batch 3: ERP Similarity Score: -0.0371
    Run 1, Batch 4: ERP Similarity Score: -0.0406
    Run 1, Batch 5: ERP Similarity Score: -0.0343
    Run 1, Batch 6: ERP Similarity Score: -0.0407
    Run 1, Batch 7: ERP Similarity Score: -0.0395
    Run 1, Batch 8: ERP Similarity Score: -0.0389
    Run 1, Batch 9: ERP Similarity Score: -0.0388
    Run 1, Batch 10: ERP Similarity Score: -0.0351
    Run 1, Batch 11: ERP Similarity Score: -0.0361
    Run 1, Batch 12: ERP Similarity Score: -0.0363
    Run 1, Batch 13: ERP Similarity Score: -0.0403
    Run 1, Batch 14: ERP Similarity Score: -0.0434
    Run 1, Batch 15: ERP Similarity Score: -0.0410
    Run 1, Batch 16: ERP Similarity Score: -0.0395
    Run 1, Batch 17: ERP Similarity Score: -0.0380
    Run 1, Batch 18: ERP Similarity Score: -0.0332
    Run 1, Batch 19: ERP Similarity Score: -0.0291
    Run 1, Batch 20: ERP Similarity Score: -0.0303
    Run 1, Batch 21: ERP Similarity Score: -0.0344
    Run 1, Batch 22: ERP Similarity Score: -0.0373
    Run 1, Batch 23: ERP Similarity Score: -0.0370
    Run 1, Batch 24: ERP Similarity Score: -0.0456
    Run 1, Batch 25: ERP Similarity Score: -0.0376
    Run 1, Batch 26: ERP Similarity Score: -0.0404
    Run 1, Batch 27: ERP Similarity Score: -0.0461
    Run 1, Batch 28: ERP Similarity Score: -0.0386
    Run 1, Batch 29: ERP Similarity Score: -0.0384
    Run 1, Batch 30: ERP Similarity Score: -0.0365

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=58.2483, G Loss (Comb)=1.7767
Epoch 50/1000: D Loss=-1.3600, G Loss (Comb)=-1.6481
Epoch 100/1000: D Loss=-0.4728, G Loss (Comb)=-3.5515
Epoch 150/1000: D Loss=-0.2998, G Loss (Comb)=-4.0037
Epoch 200/1000: D Loss=-0.3619, G Loss (Comb)=-3.2339
Epoch 250/1000: D Loss=-0.3739, G Loss (Comb)=-3.2379
Epoch 300/1000: D Loss=-0.4843, G Loss (Comb)=-3.1131
Epoch 350/1000: D Loss=-0.3017, G Loss (Comb)=-3.2721
Epoch 400/1000: D Loss=-0.4407, G Loss (Comb)=-3.3765
Epoch 450/1000: D Loss=-0.5292, G Loss (Comb)=-3.3509
Epoch 500/1000: D Loss=-0.4504, G Loss (Comb)=-3.0976
Epoch 550/1000: D Loss=-0.4974, G Loss (Comb)=-2.5086
Epoch 600/1000: D Loss=-0.5278, G Loss (Comb)=-2.5889
Epoch 650/1000: D Loss=-0.6500, G Loss (Comb)=-2.2696
Epoch 700/1000: D Loss=-0.6725, G Loss (Comb)=-2.4611
Epoch 750/1000: D Loss=-0.6531, G Loss (Comb)=-2.2483
Epoch 800/1000: D Loss=-0.6953, G Loss (Comb)=-2.3315
Epoch 850/1000: D Loss=-0.7928, G Loss (Comb)=-2.1766
Epoch 900/1000: D Loss=-0.8605, G Loss (Comb)=-2.2056
Epoch 950/1000: D Loss=-0.8202, G Loss (Comb)=-2.3866
Epoch 999/1000: D Loss=-0.9233, G Loss (Comb)=-2.3695

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0408
    Run 2, Batch 2: ERP Similarity Score: -0.0342
    Run 2, Batch 3: ERP Similarity Score: -0.0395
    Run 2, Batch 4: ERP Similarity Score: -0.0371
    Run 2, Batch 5: ERP Similarity Score: -0.0404
    Run 2, Batch 6: ERP Similarity Score: -0.0409
    Run 2, Batch 7: ERP Similarity Score: -0.0396
    Run 2, Batch 8: ERP Similarity Score: -0.0445
    Run 2, Batch 9: ERP Similarity Score: -0.0354
    Run 2, Batch 10: ERP Similarity Score: -0.0471
    Run 2, Batch 11: ERP Similarity Score: -0.0387
    Run 2, Batch 12: ERP Similarity Score: -0.0420
    Run 2, Batch 13: ERP Similarity Score: -0.0412
    Run 2, Batch 14: ERP Similarity Score: -0.0427
    Run 2, Batch 15: ERP Similarity Score: -0.0430
    Run 2, Batch 16: ERP Similarity Score: -0.0477
    Run 2, Batch 17: ERP Similarity Score: -0.0408
    Run 2, Batch 18: ERP Similarity Score: -0.0374
    Run 2, Batch 19: ERP Similarity Score: -0.0423
    Run 2, Batch 20: ERP Similarity Score: -0.0358
    Run 2, Batch 21: ERP Similarity Score: -0.0381
    Run 2, Batch 22: ERP Similarity Score: -0.0430
    Run 2, Batch 23: ERP Similarity Score: -0.0446
    Run 2, Batch 24: ERP Similarity Score: -0.0382
    Run 2, Batch 25: ERP Similarity Score: -0.0382
    Run 2, Batch 26: ERP Similarity Score: -0.0453
    Run 2, Batch 27: ERP Similarity Score: -0.0457
    Run 2, Batch 28: ERP Similarity Score: -0.0442
    Run 2, Batch 29: ERP Similarity Score: -0.0405
    Run 2, Batch 30: ERP Similarity Score: -0.0438

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=86.1222, G Loss (Comb)=1.7012
Epoch 50/1000: D Loss=-1.4093, G Loss (Comb)=-0.4139
Epoch 100/1000: D Loss=-0.5547, G Loss (Comb)=-3.5917
Epoch 150/1000: D Loss=-0.4761, G Loss (Comb)=-2.8666
Epoch 200/1000: D Loss=-0.3136, G Loss (Comb)=-3.2970
Epoch 250/1000: D Loss=-0.2566, G Loss (Comb)=-3.6110
Epoch 300/1000: D Loss=-0.4120, G Loss (Comb)=-2.8021
Epoch 350/1000: D Loss=-0.3783, G Loss (Comb)=-2.9239
Epoch 400/1000: D Loss=-0.4523, G Loss (Comb)=-2.8871
Epoch 450/1000: D Loss=-0.3912, G Loss (Comb)=-2.8699
Epoch 500/1000: D Loss=-0.5039, G Loss (Comb)=-2.5899
Epoch 550/1000: D Loss=-0.3921, G Loss (Comb)=-2.8434
Epoch 600/1000: D Loss=-0.5018, G Loss (Comb)=-2.7566
Epoch 650/1000: D Loss=-0.5370, G Loss (Comb)=-2.5961
Epoch 700/1000: D Loss=-0.5521, G Loss (Comb)=-2.5347
Epoch 750/1000: D Loss=-0.6694, G Loss (Comb)=-2.9130
Epoch 800/1000: D Loss=-0.7316, G Loss (Comb)=-2.8012
Epoch 850/1000: D Loss=-0.7396, G Loss (Comb)=-2.5953
Epoch 900/1000: D Loss=-0.8010, G Loss (Comb)=-2.8993
Epoch 950/1000: D Loss=-0.8634, G Loss (Comb)=-3.0435
Epoch 999/1000: D Loss=-0.8320, G Loss (Comb)=-3.0023

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0371
    Run 3, Batch 2: ERP Similarity Score: -0.0405
    Run 3, Batch 3: ERP Similarity Score: -0.0333
    Run 3, Batch 4: ERP Similarity Score: -0.0434
    Run 3, Batch 5: ERP Similarity Score: -0.0413
    Run 3, Batch 6: ERP Similarity Score: -0.0404
    Run 3, Batch 7: ERP Similarity Score: -0.0394
    Run 3, Batch 8: ERP Similarity Score: -0.0470
    Run 3, Batch 9: ERP Similarity Score: -0.0416
    Run 3, Batch 10: ERP Similarity Score: -0.0442
    Run 3, Batch 11: ERP Similarity Score: -0.0419
    Run 3, Batch 12: ERP Similarity Score: -0.0377
    Run 3, Batch 13: ERP Similarity Score: -0.0437
    Run 3, Batch 14: ERP Similarity Score: -0.0341
    Run 3, Batch 15: ERP Similarity Score: -0.0318
    Run 3, Batch 16: ERP Similarity Score: -0.0294
    Run 3, Batch 17: ERP Similarity Score: -0.0458
    Run 3, Batch 18: ERP Similarity Score: -0.0395
    Run 3, Batch 19: ERP Similarity Score: -0.0290
    Run 3, Batch 20: ERP Similarity Score: -0.0465
    Run 3, Batch 21: ERP Similarity Score: -0.0419
    Run 3, Batch 22: ERP Similarity Score: -0.0394
    Run 3, Batch 23: ERP Similarity Score: -0.0428
    Run 3, Batch 24: ERP Similarity Score: -0.0286
    Run 3, Batch 25: ERP Similarity Score: -0.0315
    Run 3, Batch 26: ERP Similarity Score: -0.0431
    Run 3, Batch 27: ERP Similarity Score: -0.0369
    Run 3, Batch 28: ERP Similarity Score: -0.0313
    Run 3, Batch 29: ERP Similarity Score: -0.0318
    Run 3, Batch 30: ERP Similarity Score: -0.0361

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=73.5590, G Loss (Comb)=0.5928
Epoch 50/1000: D Loss=-1.4496, G Loss (Comb)=-0.9653
Epoch 100/1000: D Loss=-0.5238, G Loss (Comb)=-2.8199
Epoch 150/1000: D Loss=-0.4900, G Loss (Comb)=-2.9865
Epoch 200/1000: D Loss=-0.3959, G Loss (Comb)=-2.7937
Epoch 250/1000: D Loss=-0.3545, G Loss (Comb)=-2.7252
Epoch 300/1000: D Loss=-0.3024, G Loss (Comb)=-2.0156
Epoch 350/1000: D Loss=-0.4520, G Loss (Comb)=-2.3569
Epoch 400/1000: D Loss=-0.4162, G Loss (Comb)=-2.0127
Epoch 450/1000: D Loss=-0.6135, G Loss (Comb)=-2.1717
Epoch 500/1000: D Loss=-0.5029, G Loss (Comb)=-1.8026
Epoch 550/1000: D Loss=-0.5292, G Loss (Comb)=-2.1359
Epoch 600/1000: D Loss=-0.6500, G Loss (Comb)=-1.8183
Epoch 650/1000: D Loss=-0.6527, G Loss (Comb)=-2.1710
Epoch 700/1000: D Loss=-0.6274, G Loss (Comb)=-1.9876
Epoch 750/1000: D Loss=-0.7203, G Loss (Comb)=-2.2590
Epoch 800/1000: D Loss=-0.7863, G Loss (Comb)=-2.1444
Epoch 850/1000: D Loss=-0.8605, G Loss (Comb)=-2.0653
Epoch 900/1000: D Loss=-0.9252, G Loss (Comb)=-2.3630
Epoch 950/1000: D Loss=-0.8865, G Loss (Comb)=-2.5239
Epoch 999/1000: D Loss=-0.8439, G Loss (Comb)=-2.4303

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0588
    Run 4, Batch 2: ERP Similarity Score: -0.0537
    Run 4, Batch 3: ERP Similarity Score: -0.0538
    Run 4, Batch 4: ERP Similarity Score: -0.0535
    Run 4, Batch 5: ERP Similarity Score: -0.0612
    Run 4, Batch 6: ERP Similarity Score: -0.0496
    Run 4, Batch 7: ERP Similarity Score: -0.0543
    Run 4, Batch 8: ERP Similarity Score: -0.0443
    Run 4, Batch 9: ERP Similarity Score: -0.0553
    Run 4, Batch 10: ERP Similarity Score: -0.0523
    Run 4, Batch 11: ERP Similarity Score: -0.0482
    Run 4, Batch 12: ERP Similarity Score: -0.0475
    Run 4, Batch 13: ERP Similarity Score: -0.0495
    Run 4, Batch 14: ERP Similarity Score: -0.0503
    Run 4, Batch 15: ERP Similarity Score: -0.0516
    Run 4, Batch 16: ERP Similarity Score: -0.0576
    Run 4, Batch 17: ERP Similarity Score: -0.0576
    Run 4, Batch 18: ERP Similarity Score: -0.0558
    Run 4, Batch 19: ERP Similarity Score: -0.0505
    Run 4, Batch 20: ERP Similarity Score: -0.0554
    Run 4, Batch 21: ERP Similarity Score: -0.0447
    Run 4, Batch 22: ERP Similarity Score: -0.0550
    Run 4, Batch 23: ERP Similarity Score: -0.0584
    Run 4, Batch 24: ERP Similarity Score: -0.0549
    Run 4, Batch 25: ERP Similarity Score: -0.0542
    Run 4, Batch 26: ERP Similarity Score: -0.0502
    Run 4, Batch 27: ERP Similarity Score: -0.0495
    Run 4, Batch 28: ERP Similarity Score: -0.0572
    Run 4, Batch 29: ERP Similarity Score: -0.0656
    Run 4, Batch 30: ERP Similarity Score: -0.0485

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=94.5064, G Loss (Comb)=2.1426
Epoch 50/1000: D Loss=-1.3696, G Loss (Comb)=-1.1901
Epoch 100/1000: D Loss=-0.2828, G Loss (Comb)=-3.9890
Epoch 150/1000: D Loss=-0.3313, G Loss (Comb)=-3.6377
Epoch 200/1000: D Loss=-0.4456, G Loss (Comb)=-3.6334
Epoch 250/1000: D Loss=-0.2549, G Loss (Comb)=-3.4578
Epoch 300/1000: D Loss=-0.3802, G Loss (Comb)=-2.8301
Epoch 350/1000: D Loss=-0.3750, G Loss (Comb)=-2.7078
Epoch 400/1000: D Loss=-0.4318, G Loss (Comb)=-2.8170
Epoch 450/1000: D Loss=-0.4347, G Loss (Comb)=-2.7394
Epoch 500/1000: D Loss=-0.5404, G Loss (Comb)=-2.2221
Epoch 550/1000: D Loss=-0.5448, G Loss (Comb)=-2.2251
Epoch 600/1000: D Loss=-0.6630, G Loss (Comb)=-2.6990
Epoch 650/1000: D Loss=-0.6826, G Loss (Comb)=-2.4527
Epoch 700/1000: D Loss=-0.7162, G Loss (Comb)=-2.3877
Epoch 750/1000: D Loss=-0.7490, G Loss (Comb)=-2.2521
Epoch 800/1000: D Loss=-0.8393, G Loss (Comb)=-2.4555
Epoch 850/1000: D Loss=-0.8206, G Loss (Comb)=-2.3951
Epoch 900/1000: D Loss=-0.8516, G Loss (Comb)=-2.3388
Epoch 950/1000: D Loss=-0.9030, G Loss (Comb)=-2.3039
Epoch 999/1000: D Loss=-0.9905, G Loss (Comb)=-2.2209

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0540
    Run 5, Batch 2: ERP Similarity Score: -0.0407
    Run 5, Batch 3: ERP Similarity Score: -0.0386
    Run 5, Batch 4: ERP Similarity Score: -0.0406
    Run 5, Batch 5: ERP Similarity Score: -0.0361
    Run 5, Batch 6: ERP Similarity Score: -0.0541
    Run 5, Batch 7: ERP Similarity Score: -0.0441
    Run 5, Batch 8: ERP Similarity Score: -0.0488
    Run 5, Batch 9: ERP Similarity Score: -0.0555
    Run 5, Batch 10: ERP Similarity Score: -0.0463
    Run 5, Batch 11: ERP Similarity Score: -0.0495
    Run 5, Batch 12: ERP Similarity Score: -0.0389
    Run 5, Batch 13: ERP Similarity Score: -0.0532
    Run 5, Batch 14: ERP Similarity Score: -0.0543
    Run 5, Batch 15: ERP Similarity Score: -0.0440
    Run 5, Batch 16: ERP Similarity Score: -0.0381
    Run 5, Batch 17: ERP Similarity Score: -0.0460
    Run 5, Batch 18: ERP Similarity Score: -0.0465
    Run 5, Batch 19: ERP Similarity Score: -0.0471
    Run 5, Batch 20: ERP Similarity Score: -0.0373
    Run 5, Batch 21: ERP Similarity Score: -0.0482
    Run 5, Batch 22: ERP Similarity Score: -0.0421
    Run 5, Batch 23: ERP Similarity Score: -0.0411
    Run 5, Batch 24: ERP Similarity Score: -0.0420
    Run 5, Batch 25: ERP Similarity Score: -0.0538
    Run 5, Batch 26: ERP Similarity Score: -0.0540
    Run 5, Batch 27: ERP Similarity Score: -0.0347
    Run 5, Batch 28: ERP Similarity Score: -0.0446
    Run 5, Batch 29: ERP Similarity Score: -0.0413
    Run 5, Batch 30: ERP Similarity Score: -0.0552


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 24, Score: -0.0286
  Top 2: Run 3, Batch 19, Score: -0.0290
  Top 3: Run 1, Batch 19, Score: -0.0291
  Top 4: Run 3, Batch 16, Score: -0.0294
  Top 5: Run 1, Batch 20, Score: -0.0303
  Top 6: Run 3, Batch 28, Score: -0.0313
  Top 7: Run 1, Batch 2, Score: -0.0313
  Top 8: Run 3, Batch 25, Score: -0.0315
  Top 9: Run 3, Batch 15, Score: -0.0318
  Top 10: Run 3, Batch 29, Score: -0.0318

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 24, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 19, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 19, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 16, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 20, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 20, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 20, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 20, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 28, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 2, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 25, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 15, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 29, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 15 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 24, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0286
  - Strategy (Run 3, Batch 24, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0286
  - Strategy (Run 1, Batch 19, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0291
  - Strategy (Run 1, Batch 19, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0291
  - Strategy (Run 1, Batch 19, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0291
  - Strategy (Run 1, Batch 20, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0303
  - Strategy (Run 1, Batch 20, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0303
  - Strategy (Run 3, Batch 28, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0313
  - Strategy (Run 3, Batch 28, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0313
  - Strategy (Run 3, Batch 25, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0315
  - Strategy (Run 3, Batch 25, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0315
  - Strategy (Run 3, Batch 15, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 3, Batch 15, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 3, Batch 29, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0318
  - Strategy (Run 3, Batch 29, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0318

Selected best strategy: Run 3, Batch 24, Strategy: Augmented (50%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 66.67%) -> REAL test accuracy: 52.63%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (50%), Val Acc: 100.00%) -> REAL test accuracy: 60.53%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H8_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H8_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
