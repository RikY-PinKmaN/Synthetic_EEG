Log for Subject Pair 5-6 from H8
========================================


========================= PROCESSING SUBJECT PAIR: 5-6 from H8 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 255 clean Target and 997 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 877

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 58

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 82.76%

--- Training cWGAN-GP for Subject 5-6, Run 1 ---
Epoch 0/1000: D Loss=66.4742, G Loss (Comb)=1.0813
Epoch 50/1000: D Loss=-0.2872, G Loss (Comb)=-3.7881
Epoch 100/1000: D Loss=-0.2262, G Loss (Comb)=-3.0990
Epoch 150/1000: D Loss=-0.1952, G Loss (Comb)=-2.6614
Epoch 200/1000: D Loss=-0.2195, G Loss (Comb)=-2.7710
Epoch 250/1000: D Loss=-0.1026, G Loss (Comb)=-2.9789
Epoch 300/1000: D Loss=-0.1212, G Loss (Comb)=-2.2573
Epoch 350/1000: D Loss=-0.2263, G Loss (Comb)=-2.2910
Epoch 400/1000: D Loss=-0.3354, G Loss (Comb)=-2.6989
Epoch 450/1000: D Loss=-0.3593, G Loss (Comb)=-2.2118
Epoch 500/1000: D Loss=-0.3013, G Loss (Comb)=-2.3714
Epoch 550/1000: D Loss=-0.3573, G Loss (Comb)=-2.3974
Epoch 600/1000: D Loss=-0.3803, G Loss (Comb)=-2.8438
Epoch 650/1000: D Loss=-0.4566, G Loss (Comb)=-2.9000
Epoch 700/1000: D Loss=-0.4203, G Loss (Comb)=-3.2174
Epoch 750/1000: D Loss=-0.5714, G Loss (Comb)=-3.3750
Epoch 800/1000: D Loss=-0.5266, G Loss (Comb)=-3.6536
Epoch 850/1000: D Loss=-0.5716, G Loss (Comb)=-3.6576
Epoch 900/1000: D Loss=-0.6119, G Loss (Comb)=-4.0523
Epoch 950/1000: D Loss=-0.6074, G Loss (Comb)=-3.9909
Epoch 999/1000: D Loss=-0.6883, G Loss (Comb)=-4.2546

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0573
    Run 1, Batch 2: ERP Similarity Score: -0.0486
    Run 1, Batch 3: ERP Similarity Score: -0.0467
    Run 1, Batch 4: ERP Similarity Score: -0.0530
    Run 1, Batch 5: ERP Similarity Score: -0.0570
    Run 1, Batch 6: ERP Similarity Score: -0.0460
    Run 1, Batch 7: ERP Similarity Score: -0.0472
    Run 1, Batch 8: ERP Similarity Score: -0.0491
    Run 1, Batch 9: ERP Similarity Score: -0.0464
    Run 1, Batch 10: ERP Similarity Score: -0.0501
    Run 1, Batch 11: ERP Similarity Score: -0.0539
    Run 1, Batch 12: ERP Similarity Score: -0.0514
    Run 1, Batch 13: ERP Similarity Score: -0.0537
    Run 1, Batch 14: ERP Similarity Score: -0.0488
    Run 1, Batch 15: ERP Similarity Score: -0.0511
    Run 1, Batch 16: ERP Similarity Score: -0.0483
    Run 1, Batch 17: ERP Similarity Score: -0.0471
    Run 1, Batch 18: ERP Similarity Score: -0.0552
    Run 1, Batch 19: ERP Similarity Score: -0.0594
    Run 1, Batch 20: ERP Similarity Score: -0.0509
    Run 1, Batch 21: ERP Similarity Score: -0.0438
    Run 1, Batch 22: ERP Similarity Score: -0.0532
    Run 1, Batch 23: ERP Similarity Score: -0.0508
    Run 1, Batch 24: ERP Similarity Score: -0.0521
    Run 1, Batch 25: ERP Similarity Score: -0.0530
    Run 1, Batch 26: ERP Similarity Score: -0.0402
    Run 1, Batch 27: ERP Similarity Score: -0.0529
    Run 1, Batch 28: ERP Similarity Score: -0.0578
    Run 1, Batch 29: ERP Similarity Score: -0.0516
    Run 1, Batch 30: ERP Similarity Score: -0.0486

--- Training cWGAN-GP for Subject 5-6, Run 2 ---
Epoch 0/1000: D Loss=93.6618, G Loss (Comb)=1.9037
Epoch 50/1000: D Loss=-0.3736, G Loss (Comb)=-2.8625
Epoch 100/1000: D Loss=-0.0035, G Loss (Comb)=-3.0997
Epoch 150/1000: D Loss=-0.1592, G Loss (Comb)=-2.7363
Epoch 200/1000: D Loss=-0.1057, G Loss (Comb)=-2.8221
Epoch 250/1000: D Loss=-0.2429, G Loss (Comb)=-2.3184
Epoch 300/1000: D Loss=-0.1601, G Loss (Comb)=-1.8737
Epoch 350/1000: D Loss=-0.1942, G Loss (Comb)=-2.0778
Epoch 400/1000: D Loss=-0.1482, G Loss (Comb)=-2.3683
Epoch 450/1000: D Loss=-0.2056, G Loss (Comb)=-2.3510
Epoch 500/1000: D Loss=-0.2780, G Loss (Comb)=-1.9947
Epoch 550/1000: D Loss=-0.2855, G Loss (Comb)=-2.3775
Epoch 600/1000: D Loss=-0.2414, G Loss (Comb)=-2.7533
Epoch 650/1000: D Loss=-0.3690, G Loss (Comb)=-2.9693
Epoch 700/1000: D Loss=-0.4606, G Loss (Comb)=-3.2152
Epoch 750/1000: D Loss=-0.4366, G Loss (Comb)=-3.5204
Epoch 800/1000: D Loss=-0.4811, G Loss (Comb)=-3.8836
Epoch 850/1000: D Loss=-0.4790, G Loss (Comb)=-3.9701
Epoch 900/1000: D Loss=-0.5163, G Loss (Comb)=-4.2081
Epoch 950/1000: D Loss=-0.6056, G Loss (Comb)=-4.3192
Epoch 999/1000: D Loss=-0.6104, G Loss (Comb)=-4.6325

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0496
    Run 2, Batch 2: ERP Similarity Score: -0.0515
    Run 2, Batch 3: ERP Similarity Score: -0.0488
    Run 2, Batch 4: ERP Similarity Score: -0.0558
    Run 2, Batch 5: ERP Similarity Score: -0.0482
    Run 2, Batch 6: ERP Similarity Score: -0.0536
    Run 2, Batch 7: ERP Similarity Score: -0.0571
    Run 2, Batch 8: ERP Similarity Score: -0.0546
    Run 2, Batch 9: ERP Similarity Score: -0.0475
    Run 2, Batch 10: ERP Similarity Score: -0.0578
    Run 2, Batch 11: ERP Similarity Score: -0.0476
    Run 2, Batch 12: ERP Similarity Score: -0.0523
    Run 2, Batch 13: ERP Similarity Score: -0.0480
    Run 2, Batch 14: ERP Similarity Score: -0.0444
    Run 2, Batch 15: ERP Similarity Score: -0.0522
    Run 2, Batch 16: ERP Similarity Score: -0.0560
    Run 2, Batch 17: ERP Similarity Score: -0.0520
    Run 2, Batch 18: ERP Similarity Score: -0.0555
    Run 2, Batch 19: ERP Similarity Score: -0.0596
    Run 2, Batch 20: ERP Similarity Score: -0.0548
    Run 2, Batch 21: ERP Similarity Score: -0.0528
    Run 2, Batch 22: ERP Similarity Score: -0.0648
    Run 2, Batch 23: ERP Similarity Score: -0.0494
    Run 2, Batch 24: ERP Similarity Score: -0.0532
    Run 2, Batch 25: ERP Similarity Score: -0.0554
    Run 2, Batch 26: ERP Similarity Score: -0.0509
    Run 2, Batch 27: ERP Similarity Score: -0.0577
    Run 2, Batch 28: ERP Similarity Score: -0.0616
    Run 2, Batch 29: ERP Similarity Score: -0.0515
    Run 2, Batch 30: ERP Similarity Score: -0.0554

--- Training cWGAN-GP for Subject 5-6, Run 3 ---
Epoch 0/1000: D Loss=85.1133, G Loss (Comb)=1.2677
Epoch 50/1000: D Loss=-0.3102, G Loss (Comb)=-3.6965
Epoch 100/1000: D Loss=-0.2710, G Loss (Comb)=-3.4692
Epoch 150/1000: D Loss=-0.0984, G Loss (Comb)=-3.2239
Epoch 200/1000: D Loss=-0.1233, G Loss (Comb)=-2.7603
Epoch 250/1000: D Loss=-0.1602, G Loss (Comb)=-3.0633
Epoch 300/1000: D Loss=-0.2586, G Loss (Comb)=-3.2329
Epoch 350/1000: D Loss=-0.2596, G Loss (Comb)=-2.8295
Epoch 400/1000: D Loss=-0.2932, G Loss (Comb)=-3.0879
Epoch 450/1000: D Loss=-0.3211, G Loss (Comb)=-3.2240
Epoch 500/1000: D Loss=-0.3299, G Loss (Comb)=-2.8900
Epoch 550/1000: D Loss=-0.3885, G Loss (Comb)=-3.0919
Epoch 600/1000: D Loss=-0.4523, G Loss (Comb)=-3.1786
Epoch 650/1000: D Loss=-0.4801, G Loss (Comb)=-3.2334
Epoch 700/1000: D Loss=-0.5115, G Loss (Comb)=-3.4413
Epoch 750/1000: D Loss=-0.5741, G Loss (Comb)=-3.6103
Epoch 800/1000: D Loss=-0.5832, G Loss (Comb)=-3.7604
Epoch 850/1000: D Loss=-0.6206, G Loss (Comb)=-3.8506
Epoch 900/1000: D Loss=-0.6761, G Loss (Comb)=-3.9525
Epoch 950/1000: D Loss=-0.6938, G Loss (Comb)=-4.0926
Epoch 999/1000: D Loss=-0.7034, G Loss (Comb)=-4.1824

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0465
    Run 3, Batch 2: ERP Similarity Score: -0.0495
    Run 3, Batch 3: ERP Similarity Score: -0.0435
    Run 3, Batch 4: ERP Similarity Score: -0.0492
    Run 3, Batch 5: ERP Similarity Score: -0.0493
    Run 3, Batch 6: ERP Similarity Score: -0.0476
    Run 3, Batch 7: ERP Similarity Score: -0.0491
    Run 3, Batch 8: ERP Similarity Score: -0.0412
    Run 3, Batch 9: ERP Similarity Score: -0.0396
    Run 3, Batch 10: ERP Similarity Score: -0.0388
    Run 3, Batch 11: ERP Similarity Score: -0.0500
    Run 3, Batch 12: ERP Similarity Score: -0.0447
    Run 3, Batch 13: ERP Similarity Score: -0.0449
    Run 3, Batch 14: ERP Similarity Score: -0.0391
    Run 3, Batch 15: ERP Similarity Score: -0.0465
    Run 3, Batch 16: ERP Similarity Score: -0.0533
    Run 3, Batch 17: ERP Similarity Score: -0.0409
    Run 3, Batch 18: ERP Similarity Score: -0.0412
    Run 3, Batch 19: ERP Similarity Score: -0.0513
    Run 3, Batch 20: ERP Similarity Score: -0.0467
    Run 3, Batch 21: ERP Similarity Score: -0.0399
    Run 3, Batch 22: ERP Similarity Score: -0.0533
    Run 3, Batch 23: ERP Similarity Score: -0.0495
    Run 3, Batch 24: ERP Similarity Score: -0.0455
    Run 3, Batch 25: ERP Similarity Score: -0.0511
    Run 3, Batch 26: ERP Similarity Score: -0.0476
    Run 3, Batch 27: ERP Similarity Score: -0.0414
    Run 3, Batch 28: ERP Similarity Score: -0.0445
    Run 3, Batch 29: ERP Similarity Score: -0.0459
    Run 3, Batch 30: ERP Similarity Score: -0.0433

--- Training cWGAN-GP for Subject 5-6, Run 4 ---
Epoch 0/1000: D Loss=72.2762, G Loss (Comb)=2.3006
Epoch 50/1000: D Loss=-0.4840, G Loss (Comb)=-0.6937
Epoch 100/1000: D Loss=-0.3052, G Loss (Comb)=-0.4513
Epoch 150/1000: D Loss=-0.2971, G Loss (Comb)=-0.6236
Epoch 200/1000: D Loss=0.0163, G Loss (Comb)=-0.6962
Epoch 250/1000: D Loss=-0.2532, G Loss (Comb)=-0.2110
Epoch 300/1000: D Loss=-0.2641, G Loss (Comb)=-0.0214
Epoch 350/1000: D Loss=-0.1681, G Loss (Comb)=-0.5208
Epoch 400/1000: D Loss=-0.1471, G Loss (Comb)=-0.1612
Epoch 450/1000: D Loss=-0.2931, G Loss (Comb)=-0.2504
Epoch 500/1000: D Loss=-0.3230, G Loss (Comb)=-0.8332
Epoch 550/1000: D Loss=-0.3736, G Loss (Comb)=-0.8483
Epoch 600/1000: D Loss=-0.4424, G Loss (Comb)=-1.3363
Epoch 650/1000: D Loss=-0.4083, G Loss (Comb)=-1.6528
Epoch 700/1000: D Loss=-0.4527, G Loss (Comb)=-2.0051
Epoch 750/1000: D Loss=-0.5699, G Loss (Comb)=-2.3723
Epoch 800/1000: D Loss=-0.5802, G Loss (Comb)=-2.6163
Epoch 850/1000: D Loss=-0.6124, G Loss (Comb)=-2.7930
Epoch 900/1000: D Loss=-0.6581, G Loss (Comb)=-2.9570
Epoch 950/1000: D Loss=-0.7099, G Loss (Comb)=-2.9396
Epoch 999/1000: D Loss=-0.6533, G Loss (Comb)=-3.1352

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0507
    Run 4, Batch 2: ERP Similarity Score: -0.0460
    Run 4, Batch 3: ERP Similarity Score: -0.0518
    Run 4, Batch 4: ERP Similarity Score: -0.0578
    Run 4, Batch 5: ERP Similarity Score: -0.0572
    Run 4, Batch 6: ERP Similarity Score: -0.0548
    Run 4, Batch 7: ERP Similarity Score: -0.0535
    Run 4, Batch 8: ERP Similarity Score: -0.0598
    Run 4, Batch 9: ERP Similarity Score: -0.0546
    Run 4, Batch 10: ERP Similarity Score: -0.0453
    Run 4, Batch 11: ERP Similarity Score: -0.0548
    Run 4, Batch 12: ERP Similarity Score: -0.0583
    Run 4, Batch 13: ERP Similarity Score: -0.0526
    Run 4, Batch 14: ERP Similarity Score: -0.0532
    Run 4, Batch 15: ERP Similarity Score: -0.0540
    Run 4, Batch 16: ERP Similarity Score: -0.0589
    Run 4, Batch 17: ERP Similarity Score: -0.0546
    Run 4, Batch 18: ERP Similarity Score: -0.0565
    Run 4, Batch 19: ERP Similarity Score: -0.0603
    Run 4, Batch 20: ERP Similarity Score: -0.0526
    Run 4, Batch 21: ERP Similarity Score: -0.0523
    Run 4, Batch 22: ERP Similarity Score: -0.0622
    Run 4, Batch 23: ERP Similarity Score: -0.0537
    Run 4, Batch 24: ERP Similarity Score: -0.0554
    Run 4, Batch 25: ERP Similarity Score: -0.0554
    Run 4, Batch 26: ERP Similarity Score: -0.0545
    Run 4, Batch 27: ERP Similarity Score: -0.0561
    Run 4, Batch 28: ERP Similarity Score: -0.0547
    Run 4, Batch 29: ERP Similarity Score: -0.0450
    Run 4, Batch 30: ERP Similarity Score: -0.0454

--- Training cWGAN-GP for Subject 5-6, Run 5 ---
Epoch 0/1000: D Loss=79.3258, G Loss (Comb)=1.6087
Epoch 50/1000: D Loss=-0.4372, G Loss (Comb)=-3.5468
Epoch 100/1000: D Loss=-0.1372, G Loss (Comb)=-3.2206
Epoch 150/1000: D Loss=-0.2352, G Loss (Comb)=-2.9713
Epoch 200/1000: D Loss=-0.0842, G Loss (Comb)=-3.5865
Epoch 250/1000: D Loss=-0.2824, G Loss (Comb)=-3.0581
Epoch 300/1000: D Loss=-0.2963, G Loss (Comb)=-3.0674
Epoch 350/1000: D Loss=-0.2336, G Loss (Comb)=-3.0196
Epoch 400/1000: D Loss=-0.3154, G Loss (Comb)=-2.5654
Epoch 450/1000: D Loss=-0.3668, G Loss (Comb)=-2.9699
Epoch 500/1000: D Loss=-0.3482, G Loss (Comb)=-2.8980
Epoch 550/1000: D Loss=-0.4240, G Loss (Comb)=-2.8910
Epoch 600/1000: D Loss=-0.4435, G Loss (Comb)=-3.1168
Epoch 650/1000: D Loss=-0.4831, G Loss (Comb)=-3.3267
Epoch 700/1000: D Loss=-0.5242, G Loss (Comb)=-3.3280
Epoch 750/1000: D Loss=-0.5389, G Loss (Comb)=-3.5862
Epoch 800/1000: D Loss=-0.5648, G Loss (Comb)=-3.6384
Epoch 850/1000: D Loss=-0.5735, G Loss (Comb)=-3.8761
Epoch 900/1000: D Loss=-0.6535, G Loss (Comb)=-3.9840
Epoch 950/1000: D Loss=-0.6951, G Loss (Comb)=-4.0618
Epoch 999/1000: D Loss=-0.6485, G Loss (Comb)=-4.1847

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0502
    Run 5, Batch 2: ERP Similarity Score: -0.0585
    Run 5, Batch 3: ERP Similarity Score: -0.0564
    Run 5, Batch 4: ERP Similarity Score: -0.0494
    Run 5, Batch 5: ERP Similarity Score: -0.0451
    Run 5, Batch 6: ERP Similarity Score: -0.0528
    Run 5, Batch 7: ERP Similarity Score: -0.0445
    Run 5, Batch 8: ERP Similarity Score: -0.0561
    Run 5, Batch 9: ERP Similarity Score: -0.0491
    Run 5, Batch 10: ERP Similarity Score: -0.0500
    Run 5, Batch 11: ERP Similarity Score: -0.0478
    Run 5, Batch 12: ERP Similarity Score: -0.0488
    Run 5, Batch 13: ERP Similarity Score: -0.0481
    Run 5, Batch 14: ERP Similarity Score: -0.0460
    Run 5, Batch 15: ERP Similarity Score: -0.0583
    Run 5, Batch 16: ERP Similarity Score: -0.0580
    Run 5, Batch 17: ERP Similarity Score: -0.0486
    Run 5, Batch 18: ERP Similarity Score: -0.0519
    Run 5, Batch 19: ERP Similarity Score: -0.0578
    Run 5, Batch 20: ERP Similarity Score: -0.0467
    Run 5, Batch 21: ERP Similarity Score: -0.0477
    Run 5, Batch 22: ERP Similarity Score: -0.0594
    Run 5, Batch 23: ERP Similarity Score: -0.0450
    Run 5, Batch 24: ERP Similarity Score: -0.0566
    Run 5, Batch 25: ERP Similarity Score: -0.0503
    Run 5, Batch 26: ERP Similarity Score: -0.0553
    Run 5, Batch 27: ERP Similarity Score: -0.0428
    Run 5, Batch 28: ERP Similarity Score: -0.0553
    Run 5, Batch 29: ERP Similarity Score: -0.0466
    Run 5, Batch 30: ERP Similarity Score: -0.0529


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 10, Score: -0.0388
  Top 2: Run 3, Batch 14, Score: -0.0391
  Top 3: Run 3, Batch 9, Score: -0.0396
  Top 4: Run 3, Batch 21, Score: -0.0399
  Top 5: Run 1, Batch 26, Score: -0.0402
  Top 6: Run 3, Batch 17, Score: -0.0409
  Top 7: Run 3, Batch 18, Score: -0.0412
  Top 8: Run 3, Batch 8, Score: -0.0412
  Top 9: Run 3, Batch 27, Score: -0.0414
  Top 10: Run 5, Batch 27, Score: -0.0428

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 10, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 40.00%
    Run 3, Batch 14, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 9, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 3, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 21, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 26, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 1, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 1, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 17, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 3, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 18, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 3, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 60.00%
    Run 3, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 8, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 3, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 27, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 3, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 5, Batch 27, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 5, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 5, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 5, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 80.00%

Found 2 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 1, Batch 26, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0402
  - Strategy (Run 3, Batch 27, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0414

Selected best strategy: Run 1, Batch 26, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 80.00%) -> REAL test accuracy: 81.03%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 91.38%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H8_results/Subject_5-6_results/accuracy_comparison_S5-6.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 5-6) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H8_results/Subject_5-6_results/GA_ERP_Combined_S5-6_ChCz.png

--- Subject 5-6 processing finished successfully. ---
