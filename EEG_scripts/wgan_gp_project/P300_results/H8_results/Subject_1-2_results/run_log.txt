Log for Subject Pair 1-2 from H8
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H8 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 266 clean Target and 531 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 572

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 37

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 72.97%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=59.9861, G Loss (Comb)=3.4816
Epoch 50/1000: D Loss=-1.9287, G Loss (Comb)=0.4249
Epoch 100/1000: D Loss=-0.5590, G Loss (Comb)=-1.4853
Epoch 150/1000: D Loss=-0.3922, G Loss (Comb)=-1.5392
Epoch 200/1000: D Loss=-0.2200, G Loss (Comb)=-1.6660
Epoch 250/1000: D Loss=-0.2930, G Loss (Comb)=-1.2605
Epoch 300/1000: D Loss=-0.2516, G Loss (Comb)=-1.7717
Epoch 350/1000: D Loss=-0.3764, G Loss (Comb)=-1.0842
Epoch 400/1000: D Loss=-0.4297, G Loss (Comb)=-1.2617
Epoch 450/1000: D Loss=-0.4002, G Loss (Comb)=-1.6599
Epoch 500/1000: D Loss=-0.4687, G Loss (Comb)=-1.1445
Epoch 550/1000: D Loss=-0.5510, G Loss (Comb)=-0.7075
Epoch 600/1000: D Loss=-0.4960, G Loss (Comb)=-0.8839
Epoch 650/1000: D Loss=-0.5487, G Loss (Comb)=-1.0989
Epoch 700/1000: D Loss=-0.6325, G Loss (Comb)=-0.8006
Epoch 750/1000: D Loss=-0.6321, G Loss (Comb)=-0.9929
Epoch 800/1000: D Loss=-0.6452, G Loss (Comb)=-0.4940
Epoch 850/1000: D Loss=-0.7108, G Loss (Comb)=-0.7394
Epoch 900/1000: D Loss=-0.7753, G Loss (Comb)=-0.5680
Epoch 950/1000: D Loss=-0.7959, G Loss (Comb)=-0.6816
Epoch 999/1000: D Loss=-0.8526, G Loss (Comb)=-0.7071

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0559
    Run 1, Batch 2: ERP Similarity Score: -0.0580
    Run 1, Batch 3: ERP Similarity Score: -0.0624
    Run 1, Batch 4: ERP Similarity Score: -0.0559
    Run 1, Batch 5: ERP Similarity Score: -0.0651
    Run 1, Batch 6: ERP Similarity Score: -0.0693
    Run 1, Batch 7: ERP Similarity Score: -0.0729
    Run 1, Batch 8: ERP Similarity Score: -0.0463
    Run 1, Batch 9: ERP Similarity Score: -0.0556
    Run 1, Batch 10: ERP Similarity Score: -0.0563
    Run 1, Batch 11: ERP Similarity Score: -0.0579
    Run 1, Batch 12: ERP Similarity Score: -0.0585
    Run 1, Batch 13: ERP Similarity Score: -0.0666
    Run 1, Batch 14: ERP Similarity Score: -0.0572
    Run 1, Batch 15: ERP Similarity Score: -0.0550
    Run 1, Batch 16: ERP Similarity Score: -0.0606
    Run 1, Batch 17: ERP Similarity Score: -0.0525
    Run 1, Batch 18: ERP Similarity Score: -0.0603
    Run 1, Batch 19: ERP Similarity Score: -0.0609
    Run 1, Batch 20: ERP Similarity Score: -0.0649
    Run 1, Batch 21: ERP Similarity Score: -0.0561
    Run 1, Batch 22: ERP Similarity Score: -0.0629
    Run 1, Batch 23: ERP Similarity Score: -0.0575
    Run 1, Batch 24: ERP Similarity Score: -0.0583
    Run 1, Batch 25: ERP Similarity Score: -0.0588
    Run 1, Batch 26: ERP Similarity Score: -0.0618
    Run 1, Batch 27: ERP Similarity Score: -0.0626
    Run 1, Batch 28: ERP Similarity Score: -0.0693
    Run 1, Batch 29: ERP Similarity Score: -0.0529
    Run 1, Batch 30: ERP Similarity Score: -0.0510

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=53.8029, G Loss (Comb)=1.9458
Epoch 50/1000: D Loss=-1.7338, G Loss (Comb)=-1.3835
Epoch 100/1000: D Loss=-0.4796, G Loss (Comb)=-2.9784
Epoch 150/1000: D Loss=-0.5111, G Loss (Comb)=-3.2707
Epoch 200/1000: D Loss=-0.2768, G Loss (Comb)=-2.9394
Epoch 250/1000: D Loss=-0.3764, G Loss (Comb)=-2.3175
Epoch 300/1000: D Loss=-0.3575, G Loss (Comb)=-2.7889
Epoch 350/1000: D Loss=-0.3019, G Loss (Comb)=-3.9696
Epoch 400/1000: D Loss=-0.2846, G Loss (Comb)=-3.6196
Epoch 450/1000: D Loss=-0.2369, G Loss (Comb)=-3.2854
Epoch 500/1000: D Loss=-0.4949, G Loss (Comb)=-3.2077
Epoch 550/1000: D Loss=-0.4259, G Loss (Comb)=-3.4596
Epoch 600/1000: D Loss=-0.5385, G Loss (Comb)=-3.2196
Epoch 650/1000: D Loss=-0.6530, G Loss (Comb)=-3.4915
Epoch 700/1000: D Loss=-0.6437, G Loss (Comb)=-3.3488
Epoch 750/1000: D Loss=-0.6507, G Loss (Comb)=-3.3013
Epoch 800/1000: D Loss=-0.6753, G Loss (Comb)=-3.3196
Epoch 850/1000: D Loss=-0.7261, G Loss (Comb)=-3.4326
Epoch 900/1000: D Loss=-0.7229, G Loss (Comb)=-2.9792
Epoch 950/1000: D Loss=-0.8086, G Loss (Comb)=-3.3993
Epoch 999/1000: D Loss=-0.8562, G Loss (Comb)=-3.5296

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0517
    Run 2, Batch 2: ERP Similarity Score: -0.0580
    Run 2, Batch 3: ERP Similarity Score: -0.0626
    Run 2, Batch 4: ERP Similarity Score: -0.0652
    Run 2, Batch 5: ERP Similarity Score: -0.0593
    Run 2, Batch 6: ERP Similarity Score: -0.0463
    Run 2, Batch 7: ERP Similarity Score: -0.0556
    Run 2, Batch 8: ERP Similarity Score: -0.0538
    Run 2, Batch 9: ERP Similarity Score: -0.0552
    Run 2, Batch 10: ERP Similarity Score: -0.0552
    Run 2, Batch 11: ERP Similarity Score: -0.0509
    Run 2, Batch 12: ERP Similarity Score: -0.0542
    Run 2, Batch 13: ERP Similarity Score: -0.0511
    Run 2, Batch 14: ERP Similarity Score: -0.0497
    Run 2, Batch 15: ERP Similarity Score: -0.0480
    Run 2, Batch 16: ERP Similarity Score: -0.0585
    Run 2, Batch 17: ERP Similarity Score: -0.0562
    Run 2, Batch 18: ERP Similarity Score: -0.0571
    Run 2, Batch 19: ERP Similarity Score: -0.0509
    Run 2, Batch 20: ERP Similarity Score: -0.0502
    Run 2, Batch 21: ERP Similarity Score: -0.0604
    Run 2, Batch 22: ERP Similarity Score: -0.0670
    Run 2, Batch 23: ERP Similarity Score: -0.0524
    Run 2, Batch 24: ERP Similarity Score: -0.0486
    Run 2, Batch 25: ERP Similarity Score: -0.0580
    Run 2, Batch 26: ERP Similarity Score: -0.0522
    Run 2, Batch 27: ERP Similarity Score: -0.0441
    Run 2, Batch 28: ERP Similarity Score: -0.0575
    Run 2, Batch 29: ERP Similarity Score: -0.0469
    Run 2, Batch 30: ERP Similarity Score: -0.0513

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=76.0950, G Loss (Comb)=2.0857
Epoch 50/1000: D Loss=-1.6383, G Loss (Comb)=0.2580
Epoch 100/1000: D Loss=-0.3995, G Loss (Comb)=-2.7121
Epoch 150/1000: D Loss=-0.2714, G Loss (Comb)=-2.7197
Epoch 200/1000: D Loss=-0.2767, G Loss (Comb)=-2.3433
Epoch 250/1000: D Loss=-0.3252, G Loss (Comb)=-2.4945
Epoch 300/1000: D Loss=-0.2735, G Loss (Comb)=-1.9314
Epoch 350/1000: D Loss=-0.4207, G Loss (Comb)=-2.5186
Epoch 400/1000: D Loss=-0.4541, G Loss (Comb)=-2.4272
Epoch 450/1000: D Loss=-0.5386, G Loss (Comb)=-2.1658
Epoch 500/1000: D Loss=-0.3912, G Loss (Comb)=-2.3582
Epoch 550/1000: D Loss=-0.5527, G Loss (Comb)=-2.7348
Epoch 600/1000: D Loss=-0.5846, G Loss (Comb)=-2.4107
Epoch 650/1000: D Loss=-0.6509, G Loss (Comb)=-2.5613
Epoch 700/1000: D Loss=-0.6163, G Loss (Comb)=-2.2465
Epoch 750/1000: D Loss=-0.6586, G Loss (Comb)=-2.4561
Epoch 800/1000: D Loss=-0.7102, G Loss (Comb)=-2.3981
Epoch 850/1000: D Loss=-0.8427, G Loss (Comb)=-2.5194
Epoch 900/1000: D Loss=-0.7873, G Loss (Comb)=-2.5809
Epoch 950/1000: D Loss=-0.8553, G Loss (Comb)=-2.3810
Epoch 999/1000: D Loss=-0.9072, G Loss (Comb)=-2.3685

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0528
    Run 3, Batch 2: ERP Similarity Score: -0.0559
    Run 3, Batch 3: ERP Similarity Score: -0.0443
    Run 3, Batch 4: ERP Similarity Score: -0.0508
    Run 3, Batch 5: ERP Similarity Score: -0.0420
    Run 3, Batch 6: ERP Similarity Score: -0.0558
    Run 3, Batch 7: ERP Similarity Score: -0.0462
    Run 3, Batch 8: ERP Similarity Score: -0.0515
    Run 3, Batch 9: ERP Similarity Score: -0.0454
    Run 3, Batch 10: ERP Similarity Score: -0.0503
    Run 3, Batch 11: ERP Similarity Score: -0.0545
    Run 3, Batch 12: ERP Similarity Score: -0.0467
    Run 3, Batch 13: ERP Similarity Score: -0.0515
    Run 3, Batch 14: ERP Similarity Score: -0.0475
    Run 3, Batch 15: ERP Similarity Score: -0.0480
    Run 3, Batch 16: ERP Similarity Score: -0.0437
    Run 3, Batch 17: ERP Similarity Score: -0.0500
    Run 3, Batch 18: ERP Similarity Score: -0.0425
    Run 3, Batch 19: ERP Similarity Score: -0.0452
    Run 3, Batch 20: ERP Similarity Score: -0.0529
    Run 3, Batch 21: ERP Similarity Score: -0.0484
    Run 3, Batch 22: ERP Similarity Score: -0.0480
    Run 3, Batch 23: ERP Similarity Score: -0.0413
    Run 3, Batch 24: ERP Similarity Score: -0.0477
    Run 3, Batch 25: ERP Similarity Score: -0.0498
    Run 3, Batch 26: ERP Similarity Score: -0.0440
    Run 3, Batch 27: ERP Similarity Score: -0.0557
    Run 3, Batch 28: ERP Similarity Score: -0.0460
    Run 3, Batch 29: ERP Similarity Score: -0.0461
    Run 3, Batch 30: ERP Similarity Score: -0.0579

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=46.0821, G Loss (Comb)=1.8855
Epoch 50/1000: D Loss=-1.7608, G Loss (Comb)=-0.4877
Epoch 100/1000: D Loss=-0.5364, G Loss (Comb)=-2.6744
Epoch 150/1000: D Loss=-0.4974, G Loss (Comb)=-1.5609
Epoch 200/1000: D Loss=-0.1272, G Loss (Comb)=-2.2760
Epoch 250/1000: D Loss=-0.0987, G Loss (Comb)=-2.0702
Epoch 300/1000: D Loss=-0.3447, G Loss (Comb)=-1.8333
Epoch 350/1000: D Loss=-0.3213, G Loss (Comb)=-2.5928
Epoch 400/1000: D Loss=-0.3872, G Loss (Comb)=-2.2829
Epoch 450/1000: D Loss=-0.3839, G Loss (Comb)=-2.1425
Epoch 500/1000: D Loss=-0.4126, G Loss (Comb)=-2.2564
Epoch 550/1000: D Loss=-0.4480, G Loss (Comb)=-2.4312
Epoch 600/1000: D Loss=-0.5919, G Loss (Comb)=-2.3914
Epoch 650/1000: D Loss=-0.4595, G Loss (Comb)=-2.7067
Epoch 700/1000: D Loss=-0.5945, G Loss (Comb)=-2.2770
Epoch 750/1000: D Loss=-0.6444, G Loss (Comb)=-2.3859
Epoch 800/1000: D Loss=-0.7418, G Loss (Comb)=-2.7394
Epoch 850/1000: D Loss=-0.7222, G Loss (Comb)=-2.2761
Epoch 900/1000: D Loss=-0.7498, G Loss (Comb)=-2.3753
Epoch 950/1000: D Loss=-0.8742, G Loss (Comb)=-2.2400
Epoch 999/1000: D Loss=-0.8566, G Loss (Comb)=-2.1272

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0448
    Run 4, Batch 2: ERP Similarity Score: -0.0463
    Run 4, Batch 3: ERP Similarity Score: -0.0433
    Run 4, Batch 4: ERP Similarity Score: -0.0396
    Run 4, Batch 5: ERP Similarity Score: -0.0441
    Run 4, Batch 6: ERP Similarity Score: -0.0520
    Run 4, Batch 7: ERP Similarity Score: -0.0542
    Run 4, Batch 8: ERP Similarity Score: -0.0446
    Run 4, Batch 9: ERP Similarity Score: -0.0453
    Run 4, Batch 10: ERP Similarity Score: -0.0427
    Run 4, Batch 11: ERP Similarity Score: -0.0472
    Run 4, Batch 12: ERP Similarity Score: -0.0420
    Run 4, Batch 13: ERP Similarity Score: -0.0518
    Run 4, Batch 14: ERP Similarity Score: -0.0432
    Run 4, Batch 15: ERP Similarity Score: -0.0437
    Run 4, Batch 16: ERP Similarity Score: -0.0349
    Run 4, Batch 17: ERP Similarity Score: -0.0493
    Run 4, Batch 18: ERP Similarity Score: -0.0423
    Run 4, Batch 19: ERP Similarity Score: -0.0385
    Run 4, Batch 20: ERP Similarity Score: -0.0486
    Run 4, Batch 21: ERP Similarity Score: -0.0469
    Run 4, Batch 22: ERP Similarity Score: -0.0484
    Run 4, Batch 23: ERP Similarity Score: -0.0491
    Run 4, Batch 24: ERP Similarity Score: -0.0427
    Run 4, Batch 25: ERP Similarity Score: -0.0392
    Run 4, Batch 26: ERP Similarity Score: -0.0429
    Run 4, Batch 27: ERP Similarity Score: -0.0438
    Run 4, Batch 28: ERP Similarity Score: -0.0522
    Run 4, Batch 29: ERP Similarity Score: -0.0403
    Run 4, Batch 30: ERP Similarity Score: -0.0445

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=68.0804, G Loss (Comb)=1.5037
Epoch 50/1000: D Loss=-1.6547, G Loss (Comb)=-0.9553
Epoch 100/1000: D Loss=-0.2904, G Loss (Comb)=-2.7399
Epoch 150/1000: D Loss=-0.3010, G Loss (Comb)=-2.9089
Epoch 200/1000: D Loss=-0.2235, G Loss (Comb)=-3.4827
Epoch 250/1000: D Loss=-0.4205, G Loss (Comb)=-3.2266
Epoch 300/1000: D Loss=-0.2983, G Loss (Comb)=-3.8467
Epoch 350/1000: D Loss=-0.4177, G Loss (Comb)=-3.1120
Epoch 400/1000: D Loss=-0.3748, G Loss (Comb)=-3.3058
Epoch 450/1000: D Loss=-0.5136, G Loss (Comb)=-3.6136
Epoch 500/1000: D Loss=-0.5953, G Loss (Comb)=-3.6522
Epoch 550/1000: D Loss=-0.6712, G Loss (Comb)=-3.2710
Epoch 600/1000: D Loss=-0.6732, G Loss (Comb)=-3.2508
Epoch 650/1000: D Loss=-0.7661, G Loss (Comb)=-2.8963
Epoch 700/1000: D Loss=-0.7248, G Loss (Comb)=-3.2546
Epoch 750/1000: D Loss=-0.7941, G Loss (Comb)=-2.8521
Epoch 800/1000: D Loss=-0.8439, G Loss (Comb)=-2.7509
Epoch 850/1000: D Loss=-0.9096, G Loss (Comb)=-2.9508
Epoch 900/1000: D Loss=-0.8887, G Loss (Comb)=-2.9055
Epoch 950/1000: D Loss=-0.9449, G Loss (Comb)=-3.2158
Epoch 999/1000: D Loss=-0.9386, G Loss (Comb)=-3.0187

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0665
    Run 5, Batch 2: ERP Similarity Score: -0.0614
    Run 5, Batch 3: ERP Similarity Score: -0.0676
    Run 5, Batch 4: ERP Similarity Score: -0.0584
    Run 5, Batch 5: ERP Similarity Score: -0.0627
    Run 5, Batch 6: ERP Similarity Score: -0.0625
    Run 5, Batch 7: ERP Similarity Score: -0.0496
    Run 5, Batch 8: ERP Similarity Score: -0.0608
    Run 5, Batch 9: ERP Similarity Score: -0.0577
    Run 5, Batch 10: ERP Similarity Score: -0.0519
    Run 5, Batch 11: ERP Similarity Score: -0.0554
    Run 5, Batch 12: ERP Similarity Score: -0.0593
    Run 5, Batch 13: ERP Similarity Score: -0.0704
    Run 5, Batch 14: ERP Similarity Score: -0.0507
    Run 5, Batch 15: ERP Similarity Score: -0.0532
    Run 5, Batch 16: ERP Similarity Score: -0.0665
    Run 5, Batch 17: ERP Similarity Score: -0.0595
    Run 5, Batch 18: ERP Similarity Score: -0.0539
    Run 5, Batch 19: ERP Similarity Score: -0.0616
    Run 5, Batch 20: ERP Similarity Score: -0.0503
    Run 5, Batch 21: ERP Similarity Score: -0.0577
    Run 5, Batch 22: ERP Similarity Score: -0.0644
    Run 5, Batch 23: ERP Similarity Score: -0.0623
    Run 5, Batch 24: ERP Similarity Score: -0.0567
    Run 5, Batch 25: ERP Similarity Score: -0.0588
    Run 5, Batch 26: ERP Similarity Score: -0.0643
    Run 5, Batch 27: ERP Similarity Score: -0.0603
    Run 5, Batch 28: ERP Similarity Score: -0.0532
    Run 5, Batch 29: ERP Similarity Score: -0.0552
    Run 5, Batch 30: ERP Similarity Score: -0.0597


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 4, Batch 16, Score: -0.0349
  Top 2: Run 4, Batch 19, Score: -0.0385
  Top 3: Run 4, Batch 25, Score: -0.0392
  Top 4: Run 4, Batch 4, Score: -0.0396
  Top 5: Run 4, Batch 29, Score: -0.0403
  Top 6: Run 3, Batch 23, Score: -0.0413
  Top 7: Run 3, Batch 5, Score: -0.0420
  Top 8: Run 4, Batch 12, Score: -0.0420
  Top 9: Run 4, Batch 18, Score: -0.0423
  Top 10: Run 3, Batch 18, Score: -0.0425

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 4, Batch 16, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 16, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 16, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 19, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 4, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 25, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 25, Strategy 'Augmented (100%)': Validation Acc: 0.00%
    Run 4, Batch 4, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 4, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 4, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 4, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 29, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 4, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 4, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 23, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 23, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 23, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 23, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 5, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 5, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 5, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 5, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 12, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 12, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 12, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 12, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 18, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 3 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 4, Batch 19, Ratio 0): Accuracy=100.00, ERP Score=-0.0385
  - Strategy (Run 4, Batch 25, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0392
  - Strategy (Run 4, Batch 29, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0403

Selected best strategy: Run 4, Batch 19, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 64.86%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 64.86%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H8_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H8_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
