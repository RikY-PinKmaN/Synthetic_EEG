Log for Subject Pair 3-4 from H7
========================================


========================= PROCESSING SUBJECT PAIR: 3-4 from H7 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 209 clean Target and 429 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 413

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 26

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 80.77%

--- Training cWGAN-GP for Subject 3-4, Run 1 ---
Epoch 0/1000: D Loss=62.5516, G Loss (Comb)=0.9577
Epoch 50/1000: D Loss=-1.2939, G Loss (Comb)=-1.3156
Epoch 100/1000: D Loss=-0.5951, G Loss (Comb)=-3.5951
Epoch 150/1000: D Loss=-0.5333, G Loss (Comb)=-3.7489
Epoch 200/1000: D Loss=-0.4677, G Loss (Comb)=-4.0415
Epoch 250/1000: D Loss=-0.4553, G Loss (Comb)=-4.0108
Epoch 300/1000: D Loss=-0.5298, G Loss (Comb)=-3.7641
Epoch 350/1000: D Loss=-0.5538, G Loss (Comb)=-3.8683
Epoch 400/1000: D Loss=-0.5257, G Loss (Comb)=-3.9509
Epoch 450/1000: D Loss=-0.6077, G Loss (Comb)=-3.5509
Epoch 500/1000: D Loss=-0.7148, G Loss (Comb)=-3.1934
Epoch 550/1000: D Loss=-0.8068, G Loss (Comb)=-3.0170
Epoch 600/1000: D Loss=-0.9106, G Loss (Comb)=-3.0298
Epoch 650/1000: D Loss=-0.9220, G Loss (Comb)=-3.0173
Epoch 700/1000: D Loss=-0.9385, G Loss (Comb)=-2.9712
Epoch 750/1000: D Loss=-1.0606, G Loss (Comb)=-2.8561
Epoch 800/1000: D Loss=-1.1499, G Loss (Comb)=-2.8456
Epoch 850/1000: D Loss=-1.1890, G Loss (Comb)=-2.8447
Epoch 900/1000: D Loss=-1.2077, G Loss (Comb)=-2.5849
Epoch 950/1000: D Loss=-1.3017, G Loss (Comb)=-2.6320
Epoch 999/1000: D Loss=-1.2878, G Loss (Comb)=-2.7091

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0385
    Run 1, Batch 2: ERP Similarity Score: -0.0391
    Run 1, Batch 3: ERP Similarity Score: -0.0409
    Run 1, Batch 4: ERP Similarity Score: -0.0403
    Run 1, Batch 5: ERP Similarity Score: -0.0396
    Run 1, Batch 6: ERP Similarity Score: -0.0400
    Run 1, Batch 7: ERP Similarity Score: -0.0398
    Run 1, Batch 8: ERP Similarity Score: -0.0384
    Run 1, Batch 9: ERP Similarity Score: -0.0402
    Run 1, Batch 10: ERP Similarity Score: -0.0391
    Run 1, Batch 11: ERP Similarity Score: -0.0394
    Run 1, Batch 12: ERP Similarity Score: -0.0404
    Run 1, Batch 13: ERP Similarity Score: -0.0411
    Run 1, Batch 14: ERP Similarity Score: -0.0389
    Run 1, Batch 15: ERP Similarity Score: -0.0389
    Run 1, Batch 16: ERP Similarity Score: -0.0413
    Run 1, Batch 17: ERP Similarity Score: -0.0395
    Run 1, Batch 18: ERP Similarity Score: -0.0416
    Run 1, Batch 19: ERP Similarity Score: -0.0415
    Run 1, Batch 20: ERP Similarity Score: -0.0450
    Run 1, Batch 21: ERP Similarity Score: -0.0411
    Run 1, Batch 22: ERP Similarity Score: -0.0414
    Run 1, Batch 23: ERP Similarity Score: -0.0407
    Run 1, Batch 24: ERP Similarity Score: -0.0404
    Run 1, Batch 25: ERP Similarity Score: -0.0409
    Run 1, Batch 26: ERP Similarity Score: -0.0432
    Run 1, Batch 27: ERP Similarity Score: -0.0413
    Run 1, Batch 28: ERP Similarity Score: -0.0395
    Run 1, Batch 29: ERP Similarity Score: -0.0413
    Run 1, Batch 30: ERP Similarity Score: -0.0396

--- Training cWGAN-GP for Subject 3-4, Run 2 ---
Epoch 0/1000: D Loss=75.4692, G Loss (Comb)=0.7385
Epoch 50/1000: D Loss=-1.4014, G Loss (Comb)=-1.5938
Epoch 100/1000: D Loss=-0.5178, G Loss (Comb)=-4.7675
Epoch 150/1000: D Loss=-0.4149, G Loss (Comb)=-5.3303
Epoch 200/1000: D Loss=-0.4428, G Loss (Comb)=-5.2310
Epoch 250/1000: D Loss=-0.5024, G Loss (Comb)=-4.9514
Epoch 300/1000: D Loss=-0.6253, G Loss (Comb)=-4.9332
Epoch 350/1000: D Loss=-0.5995, G Loss (Comb)=-5.2321
Epoch 400/1000: D Loss=-0.6975, G Loss (Comb)=-4.7928
Epoch 450/1000: D Loss=-0.7804, G Loss (Comb)=-4.8094
Epoch 500/1000: D Loss=-0.8831, G Loss (Comb)=-4.2642
Epoch 550/1000: D Loss=-0.8819, G Loss (Comb)=-4.1022
Epoch 600/1000: D Loss=-0.9899, G Loss (Comb)=-3.9482
Epoch 650/1000: D Loss=-1.0628, G Loss (Comb)=-3.6726
Epoch 700/1000: D Loss=-1.0665, G Loss (Comb)=-3.8977
Epoch 750/1000: D Loss=-1.0967, G Loss (Comb)=-3.7867
Epoch 800/1000: D Loss=-1.1382, G Loss (Comb)=-3.8852
Epoch 850/1000: D Loss=-1.2766, G Loss (Comb)=-3.5485
Epoch 900/1000: D Loss=-1.2549, G Loss (Comb)=-3.5522
Epoch 950/1000: D Loss=-1.3334, G Loss (Comb)=-3.4828
Epoch 999/1000: D Loss=-1.4083, G Loss (Comb)=-3.3333

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0346
    Run 2, Batch 2: ERP Similarity Score: -0.0363
    Run 2, Batch 3: ERP Similarity Score: -0.0415
    Run 2, Batch 4: ERP Similarity Score: -0.0362
    Run 2, Batch 5: ERP Similarity Score: -0.0353
    Run 2, Batch 6: ERP Similarity Score: -0.0424
    Run 2, Batch 7: ERP Similarity Score: -0.0339
    Run 2, Batch 8: ERP Similarity Score: -0.0387
    Run 2, Batch 9: ERP Similarity Score: -0.0387
    Run 2, Batch 10: ERP Similarity Score: -0.0375
    Run 2, Batch 11: ERP Similarity Score: -0.0348
    Run 2, Batch 12: ERP Similarity Score: -0.0389
    Run 2, Batch 13: ERP Similarity Score: -0.0367
    Run 2, Batch 14: ERP Similarity Score: -0.0432
    Run 2, Batch 15: ERP Similarity Score: -0.0373
    Run 2, Batch 16: ERP Similarity Score: -0.0380
    Run 2, Batch 17: ERP Similarity Score: -0.0342
    Run 2, Batch 18: ERP Similarity Score: -0.0332
    Run 2, Batch 19: ERP Similarity Score: -0.0361
    Run 2, Batch 20: ERP Similarity Score: -0.0427
    Run 2, Batch 21: ERP Similarity Score: -0.0352
    Run 2, Batch 22: ERP Similarity Score: -0.0363
    Run 2, Batch 23: ERP Similarity Score: -0.0360
    Run 2, Batch 24: ERP Similarity Score: -0.0366
    Run 2, Batch 25: ERP Similarity Score: -0.0354
    Run 2, Batch 26: ERP Similarity Score: -0.0411
    Run 2, Batch 27: ERP Similarity Score: -0.0354
    Run 2, Batch 28: ERP Similarity Score: -0.0351
    Run 2, Batch 29: ERP Similarity Score: -0.0432
    Run 2, Batch 30: ERP Similarity Score: -0.0356

--- Training cWGAN-GP for Subject 3-4, Run 3 ---
Epoch 0/1000: D Loss=67.5621, G Loss (Comb)=2.1066
Epoch 50/1000: D Loss=-1.4177, G Loss (Comb)=0.1945
Epoch 100/1000: D Loss=-0.4791, G Loss (Comb)=-2.0187
Epoch 150/1000: D Loss=-0.4345, G Loss (Comb)=-2.7380
Epoch 200/1000: D Loss=-0.4190, G Loss (Comb)=-3.0903
Epoch 250/1000: D Loss=-0.3875, G Loss (Comb)=-2.9959
Epoch 300/1000: D Loss=-0.5451, G Loss (Comb)=-2.7629
Epoch 350/1000: D Loss=-0.6032, G Loss (Comb)=-2.4905
Epoch 400/1000: D Loss=-0.5735, G Loss (Comb)=-2.5895
Epoch 450/1000: D Loss=-0.7100, G Loss (Comb)=-2.1342
Epoch 500/1000: D Loss=-0.7363, G Loss (Comb)=-2.1010
Epoch 550/1000: D Loss=-0.7846, G Loss (Comb)=-2.0221
Epoch 600/1000: D Loss=-0.8854, G Loss (Comb)=-1.9195
Epoch 650/1000: D Loss=-1.0286, G Loss (Comb)=-1.7432
Epoch 700/1000: D Loss=-1.0269, G Loss (Comb)=-1.8117
Epoch 750/1000: D Loss=-0.9971, G Loss (Comb)=-1.6919
Epoch 800/1000: D Loss=-1.1861, G Loss (Comb)=-1.5782
Epoch 850/1000: D Loss=-1.1719, G Loss (Comb)=-1.5598
Epoch 900/1000: D Loss=-1.2077, G Loss (Comb)=-1.8165
Epoch 950/1000: D Loss=-1.3193, G Loss (Comb)=-1.7278
Epoch 999/1000: D Loss=-1.2705, G Loss (Comb)=-1.6309

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0416
    Run 3, Batch 2: ERP Similarity Score: -0.0379
    Run 3, Batch 3: ERP Similarity Score: -0.0385
    Run 3, Batch 4: ERP Similarity Score: -0.0366
    Run 3, Batch 5: ERP Similarity Score: -0.0382
    Run 3, Batch 6: ERP Similarity Score: -0.0406
    Run 3, Batch 7: ERP Similarity Score: -0.0325
    Run 3, Batch 8: ERP Similarity Score: -0.0355
    Run 3, Batch 9: ERP Similarity Score: -0.0339
    Run 3, Batch 10: ERP Similarity Score: -0.0382
    Run 3, Batch 11: ERP Similarity Score: -0.0368
    Run 3, Batch 12: ERP Similarity Score: -0.0380
    Run 3, Batch 13: ERP Similarity Score: -0.0408
    Run 3, Batch 14: ERP Similarity Score: -0.0377
    Run 3, Batch 15: ERP Similarity Score: -0.0358
    Run 3, Batch 16: ERP Similarity Score: -0.0397
    Run 3, Batch 17: ERP Similarity Score: -0.0370
    Run 3, Batch 18: ERP Similarity Score: -0.0397
    Run 3, Batch 19: ERP Similarity Score: -0.0370
    Run 3, Batch 20: ERP Similarity Score: -0.0368
    Run 3, Batch 21: ERP Similarity Score: -0.0367
    Run 3, Batch 22: ERP Similarity Score: -0.0360
    Run 3, Batch 23: ERP Similarity Score: -0.0377
    Run 3, Batch 24: ERP Similarity Score: -0.0364
    Run 3, Batch 25: ERP Similarity Score: -0.0395
    Run 3, Batch 26: ERP Similarity Score: -0.0436
    Run 3, Batch 27: ERP Similarity Score: -0.0344
    Run 3, Batch 28: ERP Similarity Score: -0.0348
    Run 3, Batch 29: ERP Similarity Score: -0.0397
    Run 3, Batch 30: ERP Similarity Score: -0.0382

--- Training cWGAN-GP for Subject 3-4, Run 4 ---
Epoch 0/1000: D Loss=71.8057, G Loss (Comb)=2.2367
Epoch 50/1000: D Loss=-1.3930, G Loss (Comb)=1.1763
Epoch 100/1000: D Loss=-0.5691, G Loss (Comb)=-0.3058
Epoch 150/1000: D Loss=-0.4097, G Loss (Comb)=-0.2267
Epoch 200/1000: D Loss=-0.4203, G Loss (Comb)=-0.7486
Epoch 250/1000: D Loss=-0.5007, G Loss (Comb)=-0.6173
Epoch 300/1000: D Loss=-0.4264, G Loss (Comb)=-1.0772
Epoch 350/1000: D Loss=-0.4779, G Loss (Comb)=-1.2902
Epoch 400/1000: D Loss=-0.6520, G Loss (Comb)=-0.8637
Epoch 450/1000: D Loss=-0.6370, G Loss (Comb)=-0.5275
Epoch 500/1000: D Loss=-0.8106, G Loss (Comb)=-0.4640
Epoch 550/1000: D Loss=-0.8415, G Loss (Comb)=-0.4462
Epoch 600/1000: D Loss=-0.9139, G Loss (Comb)=-0.2579
Epoch 650/1000: D Loss=-0.9496, G Loss (Comb)=-0.2320
Epoch 700/1000: D Loss=-1.1098, G Loss (Comb)=-0.1996
Epoch 750/1000: D Loss=-1.0698, G Loss (Comb)=-0.1775
Epoch 800/1000: D Loss=-1.1217, G Loss (Comb)=-0.0159
Epoch 850/1000: D Loss=-1.1572, G Loss (Comb)=-0.0065
Epoch 900/1000: D Loss=-1.2453, G Loss (Comb)=0.1862
Epoch 950/1000: D Loss=-1.3340, G Loss (Comb)=0.0058
Epoch 999/1000: D Loss=-1.3239, G Loss (Comb)=-0.1212

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0372
    Run 4, Batch 2: ERP Similarity Score: -0.0372
    Run 4, Batch 3: ERP Similarity Score: -0.0393
    Run 4, Batch 4: ERP Similarity Score: -0.0366
    Run 4, Batch 5: ERP Similarity Score: -0.0397
    Run 4, Batch 6: ERP Similarity Score: -0.0410
    Run 4, Batch 7: ERP Similarity Score: -0.0392
    Run 4, Batch 8: ERP Similarity Score: -0.0387
    Run 4, Batch 9: ERP Similarity Score: -0.0401
    Run 4, Batch 10: ERP Similarity Score: -0.0440
    Run 4, Batch 11: ERP Similarity Score: -0.0369
    Run 4, Batch 12: ERP Similarity Score: -0.0402
    Run 4, Batch 13: ERP Similarity Score: -0.0373
    Run 4, Batch 14: ERP Similarity Score: -0.0389
    Run 4, Batch 15: ERP Similarity Score: -0.0410
    Run 4, Batch 16: ERP Similarity Score: -0.0400
    Run 4, Batch 17: ERP Similarity Score: -0.0387
    Run 4, Batch 18: ERP Similarity Score: -0.0404
    Run 4, Batch 19: ERP Similarity Score: -0.0442
    Run 4, Batch 20: ERP Similarity Score: -0.0445
    Run 4, Batch 21: ERP Similarity Score: -0.0399
    Run 4, Batch 22: ERP Similarity Score: -0.0390
    Run 4, Batch 23: ERP Similarity Score: -0.0432
    Run 4, Batch 24: ERP Similarity Score: -0.0420
    Run 4, Batch 25: ERP Similarity Score: -0.0393
    Run 4, Batch 26: ERP Similarity Score: -0.0416
    Run 4, Batch 27: ERP Similarity Score: -0.0417
    Run 4, Batch 28: ERP Similarity Score: -0.0432
    Run 4, Batch 29: ERP Similarity Score: -0.0387
    Run 4, Batch 30: ERP Similarity Score: -0.0412

--- Training cWGAN-GP for Subject 3-4, Run 5 ---
Epoch 0/1000: D Loss=65.5008, G Loss (Comb)=1.8923
Epoch 50/1000: D Loss=-1.2753, G Loss (Comb)=-1.0855
Epoch 100/1000: D Loss=-0.4091, G Loss (Comb)=-3.0083
Epoch 150/1000: D Loss=-0.3098, G Loss (Comb)=-3.3840
Epoch 200/1000: D Loss=-0.4613, G Loss (Comb)=-3.4661
Epoch 250/1000: D Loss=-0.3705, G Loss (Comb)=-3.6047
Epoch 300/1000: D Loss=-0.4754, G Loss (Comb)=-3.1004
Epoch 350/1000: D Loss=-0.4693, G Loss (Comb)=-3.2450
Epoch 400/1000: D Loss=-0.5292, G Loss (Comb)=-2.3745
Epoch 450/1000: D Loss=-0.6496, G Loss (Comb)=-2.2816
Epoch 500/1000: D Loss=-0.6926, G Loss (Comb)=-2.3218
Epoch 550/1000: D Loss=-0.7581, G Loss (Comb)=-2.1905
Epoch 600/1000: D Loss=-0.9192, G Loss (Comb)=-1.8779
Epoch 650/1000: D Loss=-0.9436, G Loss (Comb)=-2.0046
Epoch 700/1000: D Loss=-1.0560, G Loss (Comb)=-1.9269
Epoch 750/1000: D Loss=-1.1023, G Loss (Comb)=-2.0572
Epoch 800/1000: D Loss=-1.1539, G Loss (Comb)=-1.8883
Epoch 850/1000: D Loss=-1.1446, G Loss (Comb)=-1.7851
Epoch 900/1000: D Loss=-1.2217, G Loss (Comb)=-1.8127
Epoch 950/1000: D Loss=-1.3238, G Loss (Comb)=-1.7229
Epoch 999/1000: D Loss=-1.3774, G Loss (Comb)=-1.6239

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0384
    Run 5, Batch 2: ERP Similarity Score: -0.0426
    Run 5, Batch 3: ERP Similarity Score: -0.0385
    Run 5, Batch 4: ERP Similarity Score: -0.0406
    Run 5, Batch 5: ERP Similarity Score: -0.0389
    Run 5, Batch 6: ERP Similarity Score: -0.0369
    Run 5, Batch 7: ERP Similarity Score: -0.0401
    Run 5, Batch 8: ERP Similarity Score: -0.0409
    Run 5, Batch 9: ERP Similarity Score: -0.0392
    Run 5, Batch 10: ERP Similarity Score: -0.0389
    Run 5, Batch 11: ERP Similarity Score: -0.0393
    Run 5, Batch 12: ERP Similarity Score: -0.0394
    Run 5, Batch 13: ERP Similarity Score: -0.0399
    Run 5, Batch 14: ERP Similarity Score: -0.0398
    Run 5, Batch 15: ERP Similarity Score: -0.0425
    Run 5, Batch 16: ERP Similarity Score: -0.0414
    Run 5, Batch 17: ERP Similarity Score: -0.0379
    Run 5, Batch 18: ERP Similarity Score: -0.0363
    Run 5, Batch 19: ERP Similarity Score: -0.0449
    Run 5, Batch 20: ERP Similarity Score: -0.0369
    Run 5, Batch 21: ERP Similarity Score: -0.0415
    Run 5, Batch 22: ERP Similarity Score: -0.0399
    Run 5, Batch 23: ERP Similarity Score: -0.0408
    Run 5, Batch 24: ERP Similarity Score: -0.0421
    Run 5, Batch 25: ERP Similarity Score: -0.0408
    Run 5, Batch 26: ERP Similarity Score: -0.0389
    Run 5, Batch 27: ERP Similarity Score: -0.0370
    Run 5, Batch 28: ERP Similarity Score: -0.0425
    Run 5, Batch 29: ERP Similarity Score: -0.0421
    Run 5, Batch 30: ERP Similarity Score: -0.0473


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 7, Score: -0.0325
  Top 2: Run 2, Batch 18, Score: -0.0332
  Top 3: Run 3, Batch 9, Score: -0.0339
  Top 4: Run 2, Batch 7, Score: -0.0339
  Top 5: Run 2, Batch 17, Score: -0.0342
  Top 6: Run 3, Batch 27, Score: -0.0344
  Top 7: Run 2, Batch 1, Score: -0.0346
  Top 8: Run 2, Batch 11, Score: -0.0348
  Top 9: Run 3, Batch 28, Score: -0.0348
  Top 10: Run 2, Batch 28, Score: -0.0351

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 7, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 7, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 7, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 7, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 18, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 9, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 3, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 3, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 7, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 7, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 7, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 7, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 2, Batch 17, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 2, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 27, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 3, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 1, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 2, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 11, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 2, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 3, Batch 28, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 28, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 16 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 7, Ratio 0): Accuracy=100.00, ERP Score=-0.0325
  - Strategy (Run 3, Batch 7, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0325
  - Strategy (Run 2, Batch 18, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0332
  - Strategy (Run 3, Batch 9, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0339
  - Strategy (Run 3, Batch 9, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0339
  - Strategy (Run 2, Batch 7, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0339
  - Strategy (Run 2, Batch 17, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0342
  - Strategy (Run 2, Batch 17, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0342
  - Strategy (Run 2, Batch 17, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0342
  - Strategy (Run 3, Batch 27, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0344
  - Strategy (Run 2, Batch 1, Ratio 0): Accuracy=100.00, ERP Score=-0.0346
  - Strategy (Run 2, Batch 1, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0346
  - Strategy (Run 2, Batch 11, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0348
  - Strategy (Run 3, Batch 28, Ratio 0): Accuracy=100.00, ERP Score=-0.0348
  - Strategy (Run 3, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0348
  - Strategy (Run 2, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0351

Selected best strategy: Run 3, Batch 7, Strategy: Synth Only with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 73.08%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Synth Only, Val Acc: 100.00%) -> REAL test accuracy: 73.08%

--- Step 9: Final Plotting and Summary ---

Saved accuracy comparison plot to: H7_results/Subject_3-4_results/accuracy_comparison_S3-4.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 3-4) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H7_results/Subject_3-4_results/GA_ERP_Combined_S3-4_ChCz.png

--- Subject 3-4 processing finished successfully. ---
