Log for Subject Pair 1-2 from H1
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H1 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 261 clean Target and 524 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 560

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 36

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 61.11%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=81.2445, G Loss (Comb)=2.3078
Epoch 50/1000: D Loss=-1.5198, G Loss (Comb)=-1.0348
Epoch 100/1000: D Loss=-0.4525, G Loss (Comb)=-4.1296
Epoch 150/1000: D Loss=-0.4228, G Loss (Comb)=-3.0620
Epoch 200/1000: D Loss=-0.4399, G Loss (Comb)=-2.9321
Epoch 250/1000: D Loss=-0.3486, G Loss (Comb)=-2.7119
Epoch 300/1000: D Loss=-0.4396, G Loss (Comb)=-2.3746
Epoch 350/1000: D Loss=-0.2683, G Loss (Comb)=-2.2155
Epoch 400/1000: D Loss=-0.2571, G Loss (Comb)=-1.7204
Epoch 450/1000: D Loss=-0.3433, G Loss (Comb)=-1.4360
Epoch 500/1000: D Loss=-0.4464, G Loss (Comb)=-1.5522
Epoch 550/1000: D Loss=-0.4063, G Loss (Comb)=-1.5766
Epoch 600/1000: D Loss=-0.4136, G Loss (Comb)=-1.7428
Epoch 650/1000: D Loss=-0.4276, G Loss (Comb)=-1.5518
Epoch 700/1000: D Loss=-0.5435, G Loss (Comb)=-1.5233
Epoch 750/1000: D Loss=-0.5318, G Loss (Comb)=-1.9247
Epoch 800/1000: D Loss=-0.5259, G Loss (Comb)=-1.8655
Epoch 850/1000: D Loss=-0.6030, G Loss (Comb)=-1.8227
Epoch 900/1000: D Loss=-0.6014, G Loss (Comb)=-2.1945
Epoch 950/1000: D Loss=-0.7304, G Loss (Comb)=-2.1523
Epoch 999/1000: D Loss=-0.6693, G Loss (Comb)=-2.1876

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0307
    Run 1, Batch 2: ERP Similarity Score: -0.0317
    Run 1, Batch 3: ERP Similarity Score: -0.0292
    Run 1, Batch 4: ERP Similarity Score: -0.0339
    Run 1, Batch 5: ERP Similarity Score: -0.0287
    Run 1, Batch 6: ERP Similarity Score: -0.0270
    Run 1, Batch 7: ERP Similarity Score: -0.0333
    Run 1, Batch 8: ERP Similarity Score: -0.0308
    Run 1, Batch 9: ERP Similarity Score: -0.0286
    Run 1, Batch 10: ERP Similarity Score: -0.0301
    Run 1, Batch 11: ERP Similarity Score: -0.0306
    Run 1, Batch 12: ERP Similarity Score: -0.0295
    Run 1, Batch 13: ERP Similarity Score: -0.0308
    Run 1, Batch 14: ERP Similarity Score: -0.0335
    Run 1, Batch 15: ERP Similarity Score: -0.0346
    Run 1, Batch 16: ERP Similarity Score: -0.0313
    Run 1, Batch 17: ERP Similarity Score: -0.0299
    Run 1, Batch 18: ERP Similarity Score: -0.0307
    Run 1, Batch 19: ERP Similarity Score: -0.0299
    Run 1, Batch 20: ERP Similarity Score: -0.0294
    Run 1, Batch 21: ERP Similarity Score: -0.0324
    Run 1, Batch 22: ERP Similarity Score: -0.0264
    Run 1, Batch 23: ERP Similarity Score: -0.0274
    Run 1, Batch 24: ERP Similarity Score: -0.0315
    Run 1, Batch 25: ERP Similarity Score: -0.0295
    Run 1, Batch 26: ERP Similarity Score: -0.0271
    Run 1, Batch 27: ERP Similarity Score: -0.0263
    Run 1, Batch 28: ERP Similarity Score: -0.0298
    Run 1, Batch 29: ERP Similarity Score: -0.0274
    Run 1, Batch 30: ERP Similarity Score: -0.0311

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=81.5103, G Loss (Comb)=0.5713
Epoch 50/1000: D Loss=-1.6253, G Loss (Comb)=-2.7545
Epoch 100/1000: D Loss=-0.4330, G Loss (Comb)=-6.0571
Epoch 150/1000: D Loss=-0.3843, G Loss (Comb)=-5.6174
Epoch 200/1000: D Loss=-0.4117, G Loss (Comb)=-5.5436
Epoch 250/1000: D Loss=-0.3815, G Loss (Comb)=-4.9309
Epoch 300/1000: D Loss=-0.3498, G Loss (Comb)=-4.8837
Epoch 350/1000: D Loss=-0.3074, G Loss (Comb)=-4.0238
Epoch 400/1000: D Loss=-0.4005, G Loss (Comb)=-3.8785
Epoch 450/1000: D Loss=-0.5411, G Loss (Comb)=-3.6630
Epoch 500/1000: D Loss=-0.4858, G Loss (Comb)=-3.3900
Epoch 550/1000: D Loss=-0.4887, G Loss (Comb)=-3.2706
Epoch 600/1000: D Loss=-0.4358, G Loss (Comb)=-3.4438
Epoch 650/1000: D Loss=-0.5659, G Loss (Comb)=-3.2628
Epoch 700/1000: D Loss=-0.4852, G Loss (Comb)=-3.5280
Epoch 750/1000: D Loss=-0.6233, G Loss (Comb)=-3.2335
Epoch 800/1000: D Loss=-0.6089, G Loss (Comb)=-3.5732
Epoch 850/1000: D Loss=-0.6416, G Loss (Comb)=-3.5332
Epoch 900/1000: D Loss=-0.6246, G Loss (Comb)=-3.7656
Epoch 950/1000: D Loss=-0.5988, G Loss (Comb)=-3.7435
Epoch 999/1000: D Loss=-0.6118, G Loss (Comb)=-4.0017

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0337
    Run 2, Batch 2: ERP Similarity Score: -0.0350
    Run 2, Batch 3: ERP Similarity Score: -0.0388
    Run 2, Batch 4: ERP Similarity Score: -0.0299
    Run 2, Batch 5: ERP Similarity Score: -0.0297
    Run 2, Batch 6: ERP Similarity Score: -0.0339
    Run 2, Batch 7: ERP Similarity Score: -0.0343
    Run 2, Batch 8: ERP Similarity Score: -0.0307
    Run 2, Batch 9: ERP Similarity Score: -0.0288
    Run 2, Batch 10: ERP Similarity Score: -0.0295
    Run 2, Batch 11: ERP Similarity Score: -0.0365
    Run 2, Batch 12: ERP Similarity Score: -0.0330
    Run 2, Batch 13: ERP Similarity Score: -0.0348
    Run 2, Batch 14: ERP Similarity Score: -0.0309
    Run 2, Batch 15: ERP Similarity Score: -0.0318
    Run 2, Batch 16: ERP Similarity Score: -0.0353
    Run 2, Batch 17: ERP Similarity Score: -0.0301
    Run 2, Batch 18: ERP Similarity Score: -0.0316
    Run 2, Batch 19: ERP Similarity Score: -0.0393
    Run 2, Batch 20: ERP Similarity Score: -0.0336
    Run 2, Batch 21: ERP Similarity Score: -0.0330
    Run 2, Batch 22: ERP Similarity Score: -0.0340
    Run 2, Batch 23: ERP Similarity Score: -0.0325
    Run 2, Batch 24: ERP Similarity Score: -0.0313
    Run 2, Batch 25: ERP Similarity Score: -0.0340
    Run 2, Batch 26: ERP Similarity Score: -0.0317
    Run 2, Batch 27: ERP Similarity Score: -0.0286
    Run 2, Batch 28: ERP Similarity Score: -0.0385
    Run 2, Batch 29: ERP Similarity Score: -0.0345
    Run 2, Batch 30: ERP Similarity Score: -0.0274

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=81.3472, G Loss (Comb)=0.5959
Epoch 50/1000: D Loss=-1.8810, G Loss (Comb)=-1.9534
Epoch 100/1000: D Loss=-0.4853, G Loss (Comb)=-5.7855
Epoch 150/1000: D Loss=-0.5312, G Loss (Comb)=-4.6596
Epoch 200/1000: D Loss=-0.3275, G Loss (Comb)=-4.3782
Epoch 250/1000: D Loss=-0.4300, G Loss (Comb)=-3.8914
Epoch 300/1000: D Loss=-0.2657, G Loss (Comb)=-4.3123
Epoch 350/1000: D Loss=-0.2717, G Loss (Comb)=-2.6913
Epoch 400/1000: D Loss=-0.3275, G Loss (Comb)=-2.8993
Epoch 450/1000: D Loss=-0.3328, G Loss (Comb)=-2.7111
Epoch 500/1000: D Loss=-0.4327, G Loss (Comb)=-2.3862
Epoch 550/1000: D Loss=-0.5016, G Loss (Comb)=-2.0928
Epoch 600/1000: D Loss=-0.4977, G Loss (Comb)=-1.8886
Epoch 650/1000: D Loss=-0.6018, G Loss (Comb)=-1.4867
Epoch 700/1000: D Loss=-0.5783, G Loss (Comb)=-1.9150
Epoch 750/1000: D Loss=-0.6232, G Loss (Comb)=-1.6732
Epoch 800/1000: D Loss=-0.6436, G Loss (Comb)=-1.8245
Epoch 850/1000: D Loss=-0.6929, G Loss (Comb)=-1.6607
Epoch 900/1000: D Loss=-0.6621, G Loss (Comb)=-1.9497
Epoch 950/1000: D Loss=-0.7182, G Loss (Comb)=-2.0637
Epoch 999/1000: D Loss=-0.7322, G Loss (Comb)=-2.1389

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0294
    Run 3, Batch 2: ERP Similarity Score: -0.0358
    Run 3, Batch 3: ERP Similarity Score: -0.0363
    Run 3, Batch 4: ERP Similarity Score: -0.0328
    Run 3, Batch 5: ERP Similarity Score: -0.0278
    Run 3, Batch 6: ERP Similarity Score: -0.0307
    Run 3, Batch 7: ERP Similarity Score: -0.0292
    Run 3, Batch 8: ERP Similarity Score: -0.0353
    Run 3, Batch 9: ERP Similarity Score: -0.0330
    Run 3, Batch 10: ERP Similarity Score: -0.0281
    Run 3, Batch 11: ERP Similarity Score: -0.0323
    Run 3, Batch 12: ERP Similarity Score: -0.0320
    Run 3, Batch 13: ERP Similarity Score: -0.0303
    Run 3, Batch 14: ERP Similarity Score: -0.0399
    Run 3, Batch 15: ERP Similarity Score: -0.0285
    Run 3, Batch 16: ERP Similarity Score: -0.0284
    Run 3, Batch 17: ERP Similarity Score: -0.0269
    Run 3, Batch 18: ERP Similarity Score: -0.0326
    Run 3, Batch 19: ERP Similarity Score: -0.0285
    Run 3, Batch 20: ERP Similarity Score: -0.0352
    Run 3, Batch 21: ERP Similarity Score: -0.0277
    Run 3, Batch 22: ERP Similarity Score: -0.0342
    Run 3, Batch 23: ERP Similarity Score: -0.0309
    Run 3, Batch 24: ERP Similarity Score: -0.0378
    Run 3, Batch 25: ERP Similarity Score: -0.0348
    Run 3, Batch 26: ERP Similarity Score: -0.0290
    Run 3, Batch 27: ERP Similarity Score: -0.0380
    Run 3, Batch 28: ERP Similarity Score: -0.0287
    Run 3, Batch 29: ERP Similarity Score: -0.0346
    Run 3, Batch 30: ERP Similarity Score: -0.0351

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=58.9190, G Loss (Comb)=1.8274
Epoch 50/1000: D Loss=-1.5419, G Loss (Comb)=-0.6673
Epoch 100/1000: D Loss=-0.5432, G Loss (Comb)=-4.3090
Epoch 150/1000: D Loss=-0.3394, G Loss (Comb)=-4.0658
Epoch 200/1000: D Loss=-0.2682, G Loss (Comb)=-3.9258
Epoch 250/1000: D Loss=-0.2393, G Loss (Comb)=-3.0246
Epoch 300/1000: D Loss=-0.3415, G Loss (Comb)=-3.0904
Epoch 350/1000: D Loss=-0.4758, G Loss (Comb)=-2.1938
Epoch 400/1000: D Loss=-0.5600, G Loss (Comb)=-1.9991
Epoch 450/1000: D Loss=-0.4601, G Loss (Comb)=-1.4319
Epoch 500/1000: D Loss=-0.3637, G Loss (Comb)=-1.1979
Epoch 550/1000: D Loss=-0.4340, G Loss (Comb)=-1.5457
Epoch 600/1000: D Loss=-0.5037, G Loss (Comb)=-1.2410
Epoch 650/1000: D Loss=-0.5596, G Loss (Comb)=-1.2769
Epoch 700/1000: D Loss=-0.5509, G Loss (Comb)=-1.5614
Epoch 750/1000: D Loss=-0.5912, G Loss (Comb)=-1.4580
Epoch 800/1000: D Loss=-0.6083, G Loss (Comb)=-2.1062
Epoch 850/1000: D Loss=-0.6680, G Loss (Comb)=-1.7409
Epoch 900/1000: D Loss=-0.7024, G Loss (Comb)=-2.1387
Epoch 950/1000: D Loss=-0.5969, G Loss (Comb)=-2.4070
Epoch 999/1000: D Loss=-0.6863, G Loss (Comb)=-2.5171

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0430
    Run 4, Batch 2: ERP Similarity Score: -0.0286
    Run 4, Batch 3: ERP Similarity Score: -0.0350
    Run 4, Batch 4: ERP Similarity Score: -0.0319
    Run 4, Batch 5: ERP Similarity Score: -0.0335
    Run 4, Batch 6: ERP Similarity Score: -0.0381
    Run 4, Batch 7: ERP Similarity Score: -0.0390
    Run 4, Batch 8: ERP Similarity Score: -0.0309
    Run 4, Batch 9: ERP Similarity Score: -0.0362
    Run 4, Batch 10: ERP Similarity Score: -0.0272
    Run 4, Batch 11: ERP Similarity Score: -0.0381
    Run 4, Batch 12: ERP Similarity Score: -0.0346
    Run 4, Batch 13: ERP Similarity Score: -0.0413
    Run 4, Batch 14: ERP Similarity Score: -0.0322
    Run 4, Batch 15: ERP Similarity Score: -0.0348
    Run 4, Batch 16: ERP Similarity Score: -0.0379
    Run 4, Batch 17: ERP Similarity Score: -0.0338
    Run 4, Batch 18: ERP Similarity Score: -0.0335
    Run 4, Batch 19: ERP Similarity Score: -0.0355
    Run 4, Batch 20: ERP Similarity Score: -0.0421
    Run 4, Batch 21: ERP Similarity Score: -0.0348
    Run 4, Batch 22: ERP Similarity Score: -0.0338
    Run 4, Batch 23: ERP Similarity Score: -0.0363
    Run 4, Batch 24: ERP Similarity Score: -0.0274
    Run 4, Batch 25: ERP Similarity Score: -0.0367
    Run 4, Batch 26: ERP Similarity Score: -0.0389
    Run 4, Batch 27: ERP Similarity Score: -0.0322
    Run 4, Batch 28: ERP Similarity Score: -0.0356
    Run 4, Batch 29: ERP Similarity Score: -0.0373
    Run 4, Batch 30: ERP Similarity Score: -0.0364

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=75.4539, G Loss (Comb)=0.3993
Epoch 50/1000: D Loss=-1.6491, G Loss (Comb)=-2.0856
Epoch 100/1000: D Loss=-0.4149, G Loss (Comb)=-5.7909
Epoch 150/1000: D Loss=-0.6099, G Loss (Comb)=-5.1371
Epoch 200/1000: D Loss=-0.4984, G Loss (Comb)=-4.8661
Epoch 250/1000: D Loss=-0.2869, G Loss (Comb)=-4.9329
Epoch 300/1000: D Loss=-0.2417, G Loss (Comb)=-5.0348
Epoch 350/1000: D Loss=-0.3776, G Loss (Comb)=-5.0238
Epoch 400/1000: D Loss=-0.3580, G Loss (Comb)=-4.3776
Epoch 450/1000: D Loss=-0.5646, G Loss (Comb)=-3.9270
Epoch 500/1000: D Loss=-0.4692, G Loss (Comb)=-3.6013
Epoch 550/1000: D Loss=-0.3675, G Loss (Comb)=-3.6452
Epoch 600/1000: D Loss=-0.4715, G Loss (Comb)=-3.6113
Epoch 650/1000: D Loss=-0.5929, G Loss (Comb)=-3.5269
Epoch 700/1000: D Loss=-0.5696, G Loss (Comb)=-3.2680
Epoch 750/1000: D Loss=-0.5906, G Loss (Comb)=-3.4734
Epoch 800/1000: D Loss=-0.5822, G Loss (Comb)=-3.3646
Epoch 850/1000: D Loss=-0.6078, G Loss (Comb)=-3.4478
Epoch 900/1000: D Loss=-0.6750, G Loss (Comb)=-3.5790
Epoch 950/1000: D Loss=-0.7109, G Loss (Comb)=-3.5585
Epoch 999/1000: D Loss=-0.7355, G Loss (Comb)=-3.2861

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0324
    Run 5, Batch 2: ERP Similarity Score: -0.0253
    Run 5, Batch 3: ERP Similarity Score: -0.0319
    Run 5, Batch 4: ERP Similarity Score: -0.0289
    Run 5, Batch 5: ERP Similarity Score: -0.0319
    Run 5, Batch 6: ERP Similarity Score: -0.0360
    Run 5, Batch 7: ERP Similarity Score: -0.0281
    Run 5, Batch 8: ERP Similarity Score: -0.0279
    Run 5, Batch 9: ERP Similarity Score: -0.0334
    Run 5, Batch 10: ERP Similarity Score: -0.0305
    Run 5, Batch 11: ERP Similarity Score: -0.0367
    Run 5, Batch 12: ERP Similarity Score: -0.0315
    Run 5, Batch 13: ERP Similarity Score: -0.0272
    Run 5, Batch 14: ERP Similarity Score: -0.0316
    Run 5, Batch 15: ERP Similarity Score: -0.0291
    Run 5, Batch 16: ERP Similarity Score: -0.0367
    Run 5, Batch 17: ERP Similarity Score: -0.0299
    Run 5, Batch 18: ERP Similarity Score: -0.0298
    Run 5, Batch 19: ERP Similarity Score: -0.0269
    Run 5, Batch 20: ERP Similarity Score: -0.0312
    Run 5, Batch 21: ERP Similarity Score: -0.0335
    Run 5, Batch 22: ERP Similarity Score: -0.0347
    Run 5, Batch 23: ERP Similarity Score: -0.0324
    Run 5, Batch 24: ERP Similarity Score: -0.0288
    Run 5, Batch 25: ERP Similarity Score: -0.0378
    Run 5, Batch 26: ERP Similarity Score: -0.0327
    Run 5, Batch 27: ERP Similarity Score: -0.0311
    Run 5, Batch 28: ERP Similarity Score: -0.0287
    Run 5, Batch 29: ERP Similarity Score: -0.0299
    Run 5, Batch 30: ERP Similarity Score: -0.0299


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 5, Batch 2, Score: -0.0253
  Top 2: Run 1, Batch 27, Score: -0.0263
  Top 3: Run 1, Batch 22, Score: -0.0264
  Top 4: Run 3, Batch 17, Score: -0.0269
  Top 5: Run 5, Batch 19, Score: -0.0269
  Top 6: Run 1, Batch 6, Score: -0.0270
  Top 7: Run 1, Batch 26, Score: -0.0271
  Top 8: Run 4, Batch 10, Score: -0.0272
  Top 9: Run 5, Batch 13, Score: -0.0272
  Top 10: Run 4, Batch 24, Score: -0.0274

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 5, Batch 2, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 2, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 2, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 2, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 27, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 22, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 3, Batch 17, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 5, Batch 19, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 5, Batch 19, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 6, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 6, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 6, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 6, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 1, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 10, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 10, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 4, Batch 10, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 4, Batch 10, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 5, Batch 13, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 5, Batch 13, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 5, Batch 13, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 5, Batch 13, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 66.67%

Found 9 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 5, Batch 2, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0253
  - Strategy (Run 5, Batch 2, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0253
  - Strategy (Run 1, Batch 27, Ratio 0): Accuracy=100.00, ERP Score=-0.0263
  - Strategy (Run 1, Batch 22, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0264
  - Strategy (Run 1, Batch 22, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0264
  - Strategy (Run 4, Batch 10, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0272
  - Strategy (Run 4, Batch 10, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0272
  - Strategy (Run 4, Batch 10, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0272
  - Strategy (Run 5, Batch 13, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0272

Selected best strategy: Run 5, Batch 2, Strategy: Augmented (25%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 69.44%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (25%), Val Acc: 100.00%) -> REAL test accuracy: 94.44%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H1_results/Subject_1-2_results/target_synthetic_data_S1-2.mat
Saved non-target class of best synthetic batch to H1_results/Subject_1-2_results/nontarget_synthetic_data_S1-2.mat
Saved target class of training data to H1_results/Subject_1-2_results/target_training_data_S1-2.mat
Saved non-target class of training data to H1_results/Subject_1-2_results/nontarget_training_data_S1-2.mat

Saved accuracy comparison plot to: H1_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H1_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
