Log for Subject Pair 7-8 from H5
========================================


========================= PROCESSING SUBJECT PAIR: 7-8 from H5 =========================
Using 1:4 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 256 clean Target and 991 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 300, Valid: 75, Test: 872

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 20, Valid: 5, Test: 58

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 25 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 72.41%

--- Training cWGAN-GP for Subject 7-8, Run 1 ---
Epoch 0/1000: D Loss=94.9719, G Loss (Comb)=2.5046
Epoch 50/1000: D Loss=-0.4651, G Loss (Comb)=-3.8636
Epoch 100/1000: D Loss=-0.3852, G Loss (Comb)=-3.9461
Epoch 150/1000: D Loss=-0.2027, G Loss (Comb)=-3.0384
Epoch 200/1000: D Loss=-0.1323, G Loss (Comb)=-2.9176
Epoch 250/1000: D Loss=-0.4239, G Loss (Comb)=-3.4944
Epoch 300/1000: D Loss=-0.1866, G Loss (Comb)=-3.2778
Epoch 350/1000: D Loss=-0.3417, G Loss (Comb)=-3.2383
Epoch 400/1000: D Loss=-0.3247, G Loss (Comb)=-3.4054
Epoch 450/1000: D Loss=-0.3891, G Loss (Comb)=-3.5004
Epoch 500/1000: D Loss=-0.3936, G Loss (Comb)=-3.5737
Epoch 550/1000: D Loss=-0.4837, G Loss (Comb)=-3.8034
Epoch 600/1000: D Loss=-0.5322, G Loss (Comb)=-3.5985
Epoch 650/1000: D Loss=-0.5137, G Loss (Comb)=-3.8059
Epoch 700/1000: D Loss=-0.5824, G Loss (Comb)=-3.9597
Epoch 750/1000: D Loss=-0.6434, G Loss (Comb)=-3.8906
Epoch 800/1000: D Loss=-0.6919, G Loss (Comb)=-3.9642
Epoch 850/1000: D Loss=-0.6818, G Loss (Comb)=-4.1046
Epoch 900/1000: D Loss=-0.7254, G Loss (Comb)=-4.0776
Epoch 950/1000: D Loss=-0.7635, G Loss (Comb)=-4.1512
Epoch 999/1000: D Loss=-0.8151, G Loss (Comb)=-4.0328

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0243
    Run 1, Batch 2: ERP Similarity Score: -0.0267
    Run 1, Batch 3: ERP Similarity Score: -0.0251
    Run 1, Batch 4: ERP Similarity Score: -0.0256
    Run 1, Batch 5: ERP Similarity Score: -0.0248
    Run 1, Batch 6: ERP Similarity Score: -0.0290
    Run 1, Batch 7: ERP Similarity Score: -0.0256
    Run 1, Batch 8: ERP Similarity Score: -0.0276
    Run 1, Batch 9: ERP Similarity Score: -0.0289
    Run 1, Batch 10: ERP Similarity Score: -0.0268
    Run 1, Batch 11: ERP Similarity Score: -0.0242
    Run 1, Batch 12: ERP Similarity Score: -0.0269
    Run 1, Batch 13: ERP Similarity Score: -0.0283
    Run 1, Batch 14: ERP Similarity Score: -0.0268
    Run 1, Batch 15: ERP Similarity Score: -0.0246
    Run 1, Batch 16: ERP Similarity Score: -0.0256
    Run 1, Batch 17: ERP Similarity Score: -0.0253
    Run 1, Batch 18: ERP Similarity Score: -0.0247
    Run 1, Batch 19: ERP Similarity Score: -0.0271
    Run 1, Batch 20: ERP Similarity Score: -0.0264
    Run 1, Batch 21: ERP Similarity Score: -0.0282
    Run 1, Batch 22: ERP Similarity Score: -0.0295
    Run 1, Batch 23: ERP Similarity Score: -0.0248
    Run 1, Batch 24: ERP Similarity Score: -0.0263
    Run 1, Batch 25: ERP Similarity Score: -0.0262
    Run 1, Batch 26: ERP Similarity Score: -0.0278
    Run 1, Batch 27: ERP Similarity Score: -0.0262
    Run 1, Batch 28: ERP Similarity Score: -0.0277
    Run 1, Batch 29: ERP Similarity Score: -0.0245
    Run 1, Batch 30: ERP Similarity Score: -0.0247

--- Training cWGAN-GP for Subject 7-8, Run 2 ---
Epoch 0/1000: D Loss=62.8612, G Loss (Comb)=1.8830
Epoch 50/1000: D Loss=-0.5194, G Loss (Comb)=-4.1897
Epoch 100/1000: D Loss=-0.4551, G Loss (Comb)=-4.3635
Epoch 150/1000: D Loss=-0.2349, G Loss (Comb)=-4.0584
Epoch 200/1000: D Loss=-0.3347, G Loss (Comb)=-3.6715
Epoch 250/1000: D Loss=-0.4225, G Loss (Comb)=-4.2856
Epoch 300/1000: D Loss=-0.1376, G Loss (Comb)=-5.0475
Epoch 350/1000: D Loss=-0.3413, G Loss (Comb)=-4.8220
Epoch 400/1000: D Loss=-0.3627, G Loss (Comb)=-4.7519
Epoch 450/1000: D Loss=-0.4416, G Loss (Comb)=-4.3311
Epoch 500/1000: D Loss=-0.4927, G Loss (Comb)=-4.2640
Epoch 550/1000: D Loss=-0.4555, G Loss (Comb)=-4.0594
Epoch 600/1000: D Loss=-0.4706, G Loss (Comb)=-3.8957
Epoch 650/1000: D Loss=-0.5650, G Loss (Comb)=-3.8616
Epoch 700/1000: D Loss=-0.6336, G Loss (Comb)=-3.9485
Epoch 750/1000: D Loss=-0.6519, G Loss (Comb)=-3.9984
Epoch 800/1000: D Loss=-0.7239, G Loss (Comb)=-4.0986
Epoch 850/1000: D Loss=-0.7207, G Loss (Comb)=-3.9601
Epoch 900/1000: D Loss=-0.7529, G Loss (Comb)=-3.9343
Epoch 950/1000: D Loss=-0.8082, G Loss (Comb)=-4.0275
Epoch 999/1000: D Loss=-0.8470, G Loss (Comb)=-4.0178

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0294
    Run 2, Batch 2: ERP Similarity Score: -0.0275
    Run 2, Batch 3: ERP Similarity Score: -0.0301
    Run 2, Batch 4: ERP Similarity Score: -0.0265
    Run 2, Batch 5: ERP Similarity Score: -0.0298
    Run 2, Batch 6: ERP Similarity Score: -0.0259
    Run 2, Batch 7: ERP Similarity Score: -0.0273
    Run 2, Batch 8: ERP Similarity Score: -0.0255
    Run 2, Batch 9: ERP Similarity Score: -0.0265
    Run 2, Batch 10: ERP Similarity Score: -0.0273
    Run 2, Batch 11: ERP Similarity Score: -0.0270
    Run 2, Batch 12: ERP Similarity Score: -0.0282
    Run 2, Batch 13: ERP Similarity Score: -0.0263
    Run 2, Batch 14: ERP Similarity Score: -0.0267
    Run 2, Batch 15: ERP Similarity Score: -0.0274
    Run 2, Batch 16: ERP Similarity Score: -0.0284
    Run 2, Batch 17: ERP Similarity Score: -0.0284
    Run 2, Batch 18: ERP Similarity Score: -0.0287
    Run 2, Batch 19: ERP Similarity Score: -0.0292
    Run 2, Batch 20: ERP Similarity Score: -0.0309
    Run 2, Batch 21: ERP Similarity Score: -0.0252
    Run 2, Batch 22: ERP Similarity Score: -0.0264
    Run 2, Batch 23: ERP Similarity Score: -0.0279
    Run 2, Batch 24: ERP Similarity Score: -0.0272
    Run 2, Batch 25: ERP Similarity Score: -0.0306
    Run 2, Batch 26: ERP Similarity Score: -0.0273
    Run 2, Batch 27: ERP Similarity Score: -0.0279
    Run 2, Batch 28: ERP Similarity Score: -0.0286
    Run 2, Batch 29: ERP Similarity Score: -0.0267
    Run 2, Batch 30: ERP Similarity Score: -0.0261

--- Training cWGAN-GP for Subject 7-8, Run 3 ---
Epoch 0/1000: D Loss=67.1722, G Loss (Comb)=0.8602
Epoch 50/1000: D Loss=-0.4557, G Loss (Comb)=-4.5710
Epoch 100/1000: D Loss=-0.3252, G Loss (Comb)=-4.2834
Epoch 150/1000: D Loss=-0.1311, G Loss (Comb)=-4.2541
Epoch 200/1000: D Loss=-0.2338, G Loss (Comb)=-4.5540
Epoch 250/1000: D Loss=-0.2097, G Loss (Comb)=-4.6602
Epoch 300/1000: D Loss=-0.3194, G Loss (Comb)=-4.7053
Epoch 350/1000: D Loss=-0.2949, G Loss (Comb)=-4.7760
Epoch 400/1000: D Loss=-0.3880, G Loss (Comb)=-4.7791
Epoch 450/1000: D Loss=-0.3755, G Loss (Comb)=-4.8815
Epoch 500/1000: D Loss=-0.3885, G Loss (Comb)=-4.6736
Epoch 550/1000: D Loss=-0.5491, G Loss (Comb)=-4.3763
Epoch 600/1000: D Loss=-0.5766, G Loss (Comb)=-4.3454
Epoch 650/1000: D Loss=-0.6311, G Loss (Comb)=-4.4195
Epoch 700/1000: D Loss=-0.6519, G Loss (Comb)=-4.4790
Epoch 750/1000: D Loss=-0.6238, G Loss (Comb)=-4.5834
Epoch 800/1000: D Loss=-0.7251, G Loss (Comb)=-4.6163
Epoch 850/1000: D Loss=-0.7315, G Loss (Comb)=-4.6352
Epoch 900/1000: D Loss=-0.7970, G Loss (Comb)=-4.5844
Epoch 950/1000: D Loss=-0.8260, G Loss (Comb)=-4.6647
Epoch 999/1000: D Loss=-0.8508, G Loss (Comb)=-4.5882

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0268
    Run 3, Batch 2: ERP Similarity Score: -0.0290
    Run 3, Batch 3: ERP Similarity Score: -0.0283
    Run 3, Batch 4: ERP Similarity Score: -0.0273
    Run 3, Batch 5: ERP Similarity Score: -0.0268
    Run 3, Batch 6: ERP Similarity Score: -0.0265
    Run 3, Batch 7: ERP Similarity Score: -0.0258
    Run 3, Batch 8: ERP Similarity Score: -0.0252
    Run 3, Batch 9: ERP Similarity Score: -0.0257
    Run 3, Batch 10: ERP Similarity Score: -0.0269
    Run 3, Batch 11: ERP Similarity Score: -0.0266
    Run 3, Batch 12: ERP Similarity Score: -0.0268
    Run 3, Batch 13: ERP Similarity Score: -0.0274
    Run 3, Batch 14: ERP Similarity Score: -0.0239
    Run 3, Batch 15: ERP Similarity Score: -0.0241
    Run 3, Batch 16: ERP Similarity Score: -0.0273
    Run 3, Batch 17: ERP Similarity Score: -0.0261
    Run 3, Batch 18: ERP Similarity Score: -0.0283
    Run 3, Batch 19: ERP Similarity Score: -0.0249
    Run 3, Batch 20: ERP Similarity Score: -0.0306
    Run 3, Batch 21: ERP Similarity Score: -0.0244
    Run 3, Batch 22: ERP Similarity Score: -0.0246
    Run 3, Batch 23: ERP Similarity Score: -0.0248
    Run 3, Batch 24: ERP Similarity Score: -0.0265
    Run 3, Batch 25: ERP Similarity Score: -0.0290
    Run 3, Batch 26: ERP Similarity Score: -0.0272
    Run 3, Batch 27: ERP Similarity Score: -0.0273
    Run 3, Batch 28: ERP Similarity Score: -0.0270
    Run 3, Batch 29: ERP Similarity Score: -0.0251
    Run 3, Batch 30: ERP Similarity Score: -0.0275

--- Training cWGAN-GP for Subject 7-8, Run 4 ---
Epoch 0/1000: D Loss=80.3716, G Loss (Comb)=0.6009
Epoch 50/1000: D Loss=-0.4015, G Loss (Comb)=-5.0427
Epoch 100/1000: D Loss=-0.3218, G Loss (Comb)=-4.5618
Epoch 150/1000: D Loss=-0.3759, G Loss (Comb)=-3.9181
Epoch 200/1000: D Loss=-0.2822, G Loss (Comb)=-4.4067
Epoch 250/1000: D Loss=-0.2164, G Loss (Comb)=-4.5954
Epoch 300/1000: D Loss=-0.2831, G Loss (Comb)=-5.0647
Epoch 350/1000: D Loss=-0.3465, G Loss (Comb)=-5.2155
Epoch 400/1000: D Loss=-0.3338, G Loss (Comb)=-4.8873
Epoch 450/1000: D Loss=-0.4808, G Loss (Comb)=-5.1793
Epoch 500/1000: D Loss=-0.4563, G Loss (Comb)=-5.4680
Epoch 550/1000: D Loss=-0.4865, G Loss (Comb)=-5.4340
Epoch 600/1000: D Loss=-0.5482, G Loss (Comb)=-5.4783
Epoch 650/1000: D Loss=-0.5836, G Loss (Comb)=-5.3397
Epoch 700/1000: D Loss=-0.6402, G Loss (Comb)=-5.6642
Epoch 750/1000: D Loss=-0.6611, G Loss (Comb)=-5.9206
Epoch 800/1000: D Loss=-0.7133, G Loss (Comb)=-5.9474
Epoch 850/1000: D Loss=-0.7591, G Loss (Comb)=-6.0164
Epoch 900/1000: D Loss=-0.7670, G Loss (Comb)=-6.3593
Epoch 950/1000: D Loss=-0.8342, G Loss (Comb)=-6.3802
Epoch 999/1000: D Loss=-0.8336, G Loss (Comb)=-6.4238

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0300
    Run 4, Batch 2: ERP Similarity Score: -0.0271
    Run 4, Batch 3: ERP Similarity Score: -0.0267
    Run 4, Batch 4: ERP Similarity Score: -0.0295
    Run 4, Batch 5: ERP Similarity Score: -0.0292
    Run 4, Batch 6: ERP Similarity Score: -0.0295
    Run 4, Batch 7: ERP Similarity Score: -0.0281
    Run 4, Batch 8: ERP Similarity Score: -0.0272
    Run 4, Batch 9: ERP Similarity Score: -0.0272
    Run 4, Batch 10: ERP Similarity Score: -0.0271
    Run 4, Batch 11: ERP Similarity Score: -0.0277
    Run 4, Batch 12: ERP Similarity Score: -0.0290
    Run 4, Batch 13: ERP Similarity Score: -0.0287
    Run 4, Batch 14: ERP Similarity Score: -0.0301
    Run 4, Batch 15: ERP Similarity Score: -0.0295
    Run 4, Batch 16: ERP Similarity Score: -0.0291
    Run 4, Batch 17: ERP Similarity Score: -0.0271
    Run 4, Batch 18: ERP Similarity Score: -0.0265
    Run 4, Batch 19: ERP Similarity Score: -0.0295
    Run 4, Batch 20: ERP Similarity Score: -0.0292
    Run 4, Batch 21: ERP Similarity Score: -0.0290
    Run 4, Batch 22: ERP Similarity Score: -0.0262
    Run 4, Batch 23: ERP Similarity Score: -0.0270
    Run 4, Batch 24: ERP Similarity Score: -0.0306
    Run 4, Batch 25: ERP Similarity Score: -0.0307
    Run 4, Batch 26: ERP Similarity Score: -0.0324
    Run 4, Batch 27: ERP Similarity Score: -0.0310
    Run 4, Batch 28: ERP Similarity Score: -0.0285
    Run 4, Batch 29: ERP Similarity Score: -0.0282
    Run 4, Batch 30: ERP Similarity Score: -0.0269

--- Training cWGAN-GP for Subject 7-8, Run 5 ---
Epoch 0/1000: D Loss=93.8735, G Loss (Comb)=1.0512
Epoch 50/1000: D Loss=-0.4600, G Loss (Comb)=-5.1788
Epoch 100/1000: D Loss=-0.4802, G Loss (Comb)=-4.4638
Epoch 150/1000: D Loss=-0.2488, G Loss (Comb)=-4.7608
Epoch 200/1000: D Loss=-0.3069, G Loss (Comb)=-3.7173
Epoch 250/1000: D Loss=-0.2478, G Loss (Comb)=-3.8944
Epoch 300/1000: D Loss=-0.3051, G Loss (Comb)=-4.0807
Epoch 350/1000: D Loss=-0.3347, G Loss (Comb)=-3.7223
Epoch 400/1000: D Loss=-0.2707, G Loss (Comb)=-4.4019
Epoch 450/1000: D Loss=-0.3732, G Loss (Comb)=-3.8985
Epoch 500/1000: D Loss=-0.3901, G Loss (Comb)=-3.8651
Epoch 550/1000: D Loss=-0.3931, G Loss (Comb)=-4.1523
Epoch 600/1000: D Loss=-0.5691, G Loss (Comb)=-4.1428
Epoch 650/1000: D Loss=-0.5523, G Loss (Comb)=-4.2719
Epoch 700/1000: D Loss=-0.6007, G Loss (Comb)=-4.2441
Epoch 750/1000: D Loss=-0.6262, G Loss (Comb)=-4.4884
Epoch 800/1000: D Loss=-0.6575, G Loss (Comb)=-4.5602
Epoch 850/1000: D Loss=-0.7207, G Loss (Comb)=-4.6446
Epoch 900/1000: D Loss=-0.7908, G Loss (Comb)=-4.6407
Epoch 950/1000: D Loss=-0.7337, G Loss (Comb)=-4.7377
Epoch 999/1000: D Loss=-0.8025, G Loss (Comb)=-4.8605

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0266
    Run 5, Batch 2: ERP Similarity Score: -0.0267
    Run 5, Batch 3: ERP Similarity Score: -0.0295
    Run 5, Batch 4: ERP Similarity Score: -0.0277
    Run 5, Batch 5: ERP Similarity Score: -0.0289
    Run 5, Batch 6: ERP Similarity Score: -0.0294
    Run 5, Batch 7: ERP Similarity Score: -0.0280
    Run 5, Batch 8: ERP Similarity Score: -0.0268
    Run 5, Batch 9: ERP Similarity Score: -0.0313
    Run 5, Batch 10: ERP Similarity Score: -0.0289
    Run 5, Batch 11: ERP Similarity Score: -0.0276
    Run 5, Batch 12: ERP Similarity Score: -0.0276
    Run 5, Batch 13: ERP Similarity Score: -0.0279
    Run 5, Batch 14: ERP Similarity Score: -0.0260
    Run 5, Batch 15: ERP Similarity Score: -0.0278
    Run 5, Batch 16: ERP Similarity Score: -0.0284
    Run 5, Batch 17: ERP Similarity Score: -0.0286
    Run 5, Batch 18: ERP Similarity Score: -0.0287
    Run 5, Batch 19: ERP Similarity Score: -0.0318
    Run 5, Batch 20: ERP Similarity Score: -0.0303
    Run 5, Batch 21: ERP Similarity Score: -0.0280
    Run 5, Batch 22: ERP Similarity Score: -0.0321
    Run 5, Batch 23: ERP Similarity Score: -0.0284
    Run 5, Batch 24: ERP Similarity Score: -0.0299
    Run 5, Batch 25: ERP Similarity Score: -0.0282
    Run 5, Batch 26: ERP Similarity Score: -0.0291
    Run 5, Batch 27: ERP Similarity Score: -0.0313
    Run 5, Batch 28: ERP Similarity Score: -0.0284
    Run 5, Batch 29: ERP Similarity Score: -0.0282
    Run 5, Batch 30: ERP Similarity Score: -0.0284


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 3, Batch 14, Score: -0.0239
  Top 2: Run 3, Batch 15, Score: -0.0241
  Top 3: Run 1, Batch 11, Score: -0.0242
  Top 4: Run 1, Batch 1, Score: -0.0243
  Top 5: Run 3, Batch 21, Score: -0.0244
  Top 6: Run 1, Batch 29, Score: -0.0245
  Top 7: Run 1, Batch 15, Score: -0.0246
  Top 8: Run 3, Batch 22, Score: -0.0246
  Top 9: Run 1, Batch 30, Score: -0.0247
  Top 10: Run 1, Batch 18, Score: -0.0247

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 3, Batch 14, Strategy 'Synth Only': Validation Acc: 0.00%
    Run 3, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 3, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 3, Batch 15, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 3, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 40.00%
    Run 3, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 11, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 60.00%
    Run 1, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 40.00%
    Run 1, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 1, Batch 1, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 3, Batch 21, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 3, Batch 21, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 21, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 21, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 1, Batch 29, Strategy 'Synth Only': Validation Acc: 60.00%
    Run 1, Batch 29, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 29, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 29, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 15, Strategy 'Synth Only': Validation Acc: 100.00%
    Run 1, Batch 15, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 15, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 15, Strategy 'Augmented (100%)': Validation Acc: 60.00%
    Run 3, Batch 22, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 3, Batch 22, Strategy 'Augmented (25%)': Validation Acc: 80.00%
    Run 3, Batch 22, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 3, Batch 22, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 30, Strategy 'Synth Only': Validation Acc: 80.00%
    Run 1, Batch 30, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 30, Strategy 'Augmented (50%)': Validation Acc: 80.00%
    Run 1, Batch 30, Strategy 'Augmented (100%)': Validation Acc: 80.00%
    Run 1, Batch 18, Strategy 'Synth Only': Validation Acc: 40.00%
    Run 1, Batch 18, Strategy 'Augmented (25%)': Validation Acc: 100.00%
    Run 1, Batch 18, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 18, Strategy 'Augmented (100%)': Validation Acc: 40.00%

Found 19 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 3, Batch 14, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0239
  - Strategy (Run 3, Batch 14, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0239
  - Strategy (Run 3, Batch 15, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0241
  - Strategy (Run 3, Batch 15, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0241
  - Strategy (Run 1, Batch 1, Ratio 0): Accuracy=100.00, ERP Score=-0.0243
  - Strategy (Run 1, Batch 1, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0243
  - Strategy (Run 1, Batch 1, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0243
  - Strategy (Run 1, Batch 1, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0243
  - Strategy (Run 3, Batch 21, Ratio 0): Accuracy=100.00, ERP Score=-0.0244
  - Strategy (Run 3, Batch 21, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0244
  - Strategy (Run 3, Batch 21, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0244
  - Strategy (Run 1, Batch 29, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0245
  - Strategy (Run 1, Batch 29, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0245
  - Strategy (Run 1, Batch 15, Ratio 0): Accuracy=100.00, ERP Score=-0.0246
  - Strategy (Run 1, Batch 15, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0246
  - Strategy (Run 3, Batch 22, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0246
  - Strategy (Run 1, Batch 30, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0247
  - Strategy (Run 1, Batch 18, Ratio 0.25): Accuracy=100.00, ERP Score=-0.0247
  - Strategy (Run 1, Batch 18, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0247

Selected best strategy: Run 3, Batch 14, Strategy: Augmented (25%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 100.00%) -> REAL test accuracy: 79.31%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (25%), Val Acc: 100.00%) -> REAL test accuracy: 62.07%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H5_results/Subject_7-8_results/target_synthetic_data_S7-8.mat
Saved non-target class of best synthetic batch to H5_results/Subject_7-8_results/nontarget_synthetic_data_S7-8.mat
Saved target class of training data to H5_results/Subject_7-8_results/target_training_data_S7-8.mat
Saved non-target class of training data to H5_results/Subject_7-8_results/nontarget_training_data_S7-8.mat

Saved accuracy comparison plot to: H5_results/Subject_7-8_results/accuracy_comparison_S7-8.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 7-8) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H5_results/Subject_7-8_results/GA_ERP_Combined_S7-8_ChCz.png

--- Subject 7-8 processing finished successfully. ---
