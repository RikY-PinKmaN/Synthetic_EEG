Log for Subject Pair 1-2 from H10
========================================


========================= PROCESSING SUBJECT PAIR: 1-2 from H10 =========================
Using 1:2 Target:Non-Target ratio for this subject group.

--- Step 1: Loading and Preprocessing Data ---
Filtering and resampling complete. New Fs: 80.0 Hz

--- Step 2: Epoching and Artifact Rejection ---
Found 244 clean Target and 481 clean Non-Target trials.

--- Step 3: Performing Fixed Sequential Data Split ---
Split complete. Train: 180, Valid: 45, Test: 500

--- Step 4: Creating Averaged Features for LDA Classifier ---
Created averaged features. Train: 12, Valid: 3, Test: 33

--- Step 5: Baseline Evaluation & Creating Unified Selection Set ---
Created combined train+valid feature set with 15 averaged trials.
Baseline Accuracy (Train+Valid -> Test): 66.67%

--- Training cWGAN-GP for Subject 1-2, Run 1 ---
Epoch 0/1000: D Loss=55.1664, G Loss (Comb)=1.5125
Epoch 50/1000: D Loss=-1.5556, G Loss (Comb)=-1.0990
Epoch 100/1000: D Loss=-0.3780, G Loss (Comb)=-4.4510
Epoch 150/1000: D Loss=-0.4018, G Loss (Comb)=-4.6694
Epoch 200/1000: D Loss=-0.4162, G Loss (Comb)=-3.9412
Epoch 250/1000: D Loss=-0.2886, G Loss (Comb)=-3.5988
Epoch 300/1000: D Loss=-0.3809, G Loss (Comb)=-3.2929
Epoch 350/1000: D Loss=-0.3778, G Loss (Comb)=-3.0835
Epoch 400/1000: D Loss=-0.4602, G Loss (Comb)=-3.0679
Epoch 450/1000: D Loss=-0.4561, G Loss (Comb)=-2.4960
Epoch 500/1000: D Loss=-0.6612, G Loss (Comb)=-2.2245
Epoch 550/1000: D Loss=-0.7721, G Loss (Comb)=-1.4590
Epoch 600/1000: D Loss=-0.7543, G Loss (Comb)=-1.4395
Epoch 650/1000: D Loss=-0.7509, G Loss (Comb)=-1.7217
Epoch 700/1000: D Loss=-0.8628, G Loss (Comb)=-1.6669
Epoch 750/1000: D Loss=-0.7889, G Loss (Comb)=-1.3699
Epoch 800/1000: D Loss=-0.9673, G Loss (Comb)=-1.4898
Epoch 850/1000: D Loss=-1.0319, G Loss (Comb)=-1.6538
Epoch 900/1000: D Loss=-1.0122, G Loss (Comb)=-1.5880
Epoch 950/1000: D Loss=-1.0660, G Loss (Comb)=-1.4023
Epoch 999/1000: D Loss=-0.9554, G Loss (Comb)=-1.6619

--- Generating & Evaluating Batches with ERP Similarity (Run 1) ---
    Run 1, Batch 1: ERP Similarity Score: -0.0386
    Run 1, Batch 2: ERP Similarity Score: -0.0455
    Run 1, Batch 3: ERP Similarity Score: -0.0465
    Run 1, Batch 4: ERP Similarity Score: -0.0478
    Run 1, Batch 5: ERP Similarity Score: -0.0414
    Run 1, Batch 6: ERP Similarity Score: -0.0429
    Run 1, Batch 7: ERP Similarity Score: -0.0436
    Run 1, Batch 8: ERP Similarity Score: -0.0441
    Run 1, Batch 9: ERP Similarity Score: -0.0376
    Run 1, Batch 10: ERP Similarity Score: -0.0444
    Run 1, Batch 11: ERP Similarity Score: -0.0433
    Run 1, Batch 12: ERP Similarity Score: -0.0389
    Run 1, Batch 13: ERP Similarity Score: -0.0493
    Run 1, Batch 14: ERP Similarity Score: -0.0536
    Run 1, Batch 15: ERP Similarity Score: -0.0485
    Run 1, Batch 16: ERP Similarity Score: -0.0442
    Run 1, Batch 17: ERP Similarity Score: -0.0468
    Run 1, Batch 18: ERP Similarity Score: -0.0417
    Run 1, Batch 19: ERP Similarity Score: -0.0412
    Run 1, Batch 20: ERP Similarity Score: -0.0445
    Run 1, Batch 21: ERP Similarity Score: -0.0500
    Run 1, Batch 22: ERP Similarity Score: -0.0438
    Run 1, Batch 23: ERP Similarity Score: -0.0396
    Run 1, Batch 24: ERP Similarity Score: -0.0394
    Run 1, Batch 25: ERP Similarity Score: -0.0488
    Run 1, Batch 26: ERP Similarity Score: -0.0492
    Run 1, Batch 27: ERP Similarity Score: -0.0460
    Run 1, Batch 28: ERP Similarity Score: -0.0388
    Run 1, Batch 29: ERP Similarity Score: -0.0498
    Run 1, Batch 30: ERP Similarity Score: -0.0467

--- Training cWGAN-GP for Subject 1-2, Run 2 ---
Epoch 0/1000: D Loss=53.9892, G Loss (Comb)=2.2005
Epoch 50/1000: D Loss=-1.4276, G Loss (Comb)=-0.6427
Epoch 100/1000: D Loss=-0.4708, G Loss (Comb)=-3.3936
Epoch 150/1000: D Loss=-0.5037, G Loss (Comb)=-3.0558
Epoch 200/1000: D Loss=-0.4367, G Loss (Comb)=-2.9905
Epoch 250/1000: D Loss=-0.4551, G Loss (Comb)=-3.0298
Epoch 300/1000: D Loss=-0.3702, G Loss (Comb)=-2.5429
Epoch 350/1000: D Loss=-0.5740, G Loss (Comb)=-1.7947
Epoch 400/1000: D Loss=-0.6978, G Loss (Comb)=-0.6672
Epoch 450/1000: D Loss=-0.7027, G Loss (Comb)=-1.0297
Epoch 500/1000: D Loss=-0.7367, G Loss (Comb)=-0.4662
Epoch 550/1000: D Loss=-0.7883, G Loss (Comb)=-0.0435
Epoch 600/1000: D Loss=-0.8849, G Loss (Comb)=-0.4308
Epoch 650/1000: D Loss=-0.8644, G Loss (Comb)=-0.3324
Epoch 700/1000: D Loss=-0.9290, G Loss (Comb)=-0.4988
Epoch 750/1000: D Loss=-0.8599, G Loss (Comb)=-0.3855
Epoch 800/1000: D Loss=-1.0428, G Loss (Comb)=-0.3376
Epoch 850/1000: D Loss=-1.0004, G Loss (Comb)=-0.4897
Epoch 900/1000: D Loss=-1.0547, G Loss (Comb)=-0.6699
Epoch 950/1000: D Loss=-0.9862, G Loss (Comb)=-0.5372
Epoch 999/1000: D Loss=-0.9588, G Loss (Comb)=-0.5529

--- Generating & Evaluating Batches with ERP Similarity (Run 2) ---
    Run 2, Batch 1: ERP Similarity Score: -0.0503
    Run 2, Batch 2: ERP Similarity Score: -0.0425
    Run 2, Batch 3: ERP Similarity Score: -0.0381
    Run 2, Batch 4: ERP Similarity Score: -0.0420
    Run 2, Batch 5: ERP Similarity Score: -0.0477
    Run 2, Batch 6: ERP Similarity Score: -0.0464
    Run 2, Batch 7: ERP Similarity Score: -0.0418
    Run 2, Batch 8: ERP Similarity Score: -0.0384
    Run 2, Batch 9: ERP Similarity Score: -0.0402
    Run 2, Batch 10: ERP Similarity Score: -0.0392
    Run 2, Batch 11: ERP Similarity Score: -0.0436
    Run 2, Batch 12: ERP Similarity Score: -0.0426
    Run 2, Batch 13: ERP Similarity Score: -0.0410
    Run 2, Batch 14: ERP Similarity Score: -0.0388
    Run 2, Batch 15: ERP Similarity Score: -0.0438
    Run 2, Batch 16: ERP Similarity Score: -0.0447
    Run 2, Batch 17: ERP Similarity Score: -0.0496
    Run 2, Batch 18: ERP Similarity Score: -0.0427
    Run 2, Batch 19: ERP Similarity Score: -0.0496
    Run 2, Batch 20: ERP Similarity Score: -0.0409
    Run 2, Batch 21: ERP Similarity Score: -0.0413
    Run 2, Batch 22: ERP Similarity Score: -0.0438
    Run 2, Batch 23: ERP Similarity Score: -0.0401
    Run 2, Batch 24: ERP Similarity Score: -0.0398
    Run 2, Batch 25: ERP Similarity Score: -0.0403
    Run 2, Batch 26: ERP Similarity Score: -0.0532
    Run 2, Batch 27: ERP Similarity Score: -0.0371
    Run 2, Batch 28: ERP Similarity Score: -0.0402
    Run 2, Batch 29: ERP Similarity Score: -0.0407
    Run 2, Batch 30: ERP Similarity Score: -0.0406

--- Training cWGAN-GP for Subject 1-2, Run 3 ---
Epoch 0/1000: D Loss=62.0362, G Loss (Comb)=0.3669
Epoch 50/1000: D Loss=-1.5930, G Loss (Comb)=-2.3955
Epoch 100/1000: D Loss=-0.4623, G Loss (Comb)=-5.6059
Epoch 150/1000: D Loss=-0.4840, G Loss (Comb)=-4.6164
Epoch 200/1000: D Loss=-0.2976, G Loss (Comb)=-4.9800
Epoch 250/1000: D Loss=-0.3233, G Loss (Comb)=-4.5656
Epoch 300/1000: D Loss=-0.4767, G Loss (Comb)=-4.4730
Epoch 350/1000: D Loss=-0.4159, G Loss (Comb)=-4.0408
Epoch 400/1000: D Loss=-0.5438, G Loss (Comb)=-3.4960
Epoch 450/1000: D Loss=-0.6740, G Loss (Comb)=-2.6009
Epoch 500/1000: D Loss=-0.6408, G Loss (Comb)=-1.9954
Epoch 550/1000: D Loss=-0.7924, G Loss (Comb)=-1.6725
Epoch 600/1000: D Loss=-0.7914, G Loss (Comb)=-1.6397
Epoch 650/1000: D Loss=-0.8329, G Loss (Comb)=-1.5296
Epoch 700/1000: D Loss=-0.8699, G Loss (Comb)=-1.4869
Epoch 750/1000: D Loss=-0.9020, G Loss (Comb)=-1.5238
Epoch 800/1000: D Loss=-0.9936, G Loss (Comb)=-1.2023
Epoch 850/1000: D Loss=-0.9685, G Loss (Comb)=-1.2152
Epoch 900/1000: D Loss=-0.9622, G Loss (Comb)=-1.4062
Epoch 950/1000: D Loss=-0.9646, G Loss (Comb)=-1.1997
Epoch 999/1000: D Loss=-1.1127, G Loss (Comb)=-1.1278

--- Generating & Evaluating Batches with ERP Similarity (Run 3) ---
    Run 3, Batch 1: ERP Similarity Score: -0.0547
    Run 3, Batch 2: ERP Similarity Score: -0.0493
    Run 3, Batch 3: ERP Similarity Score: -0.0643
    Run 3, Batch 4: ERP Similarity Score: -0.0605
    Run 3, Batch 5: ERP Similarity Score: -0.0554
    Run 3, Batch 6: ERP Similarity Score: -0.0579
    Run 3, Batch 7: ERP Similarity Score: -0.0582
    Run 3, Batch 8: ERP Similarity Score: -0.0636
    Run 3, Batch 9: ERP Similarity Score: -0.0516
    Run 3, Batch 10: ERP Similarity Score: -0.0511
    Run 3, Batch 11: ERP Similarity Score: -0.0467
    Run 3, Batch 12: ERP Similarity Score: -0.0539
    Run 3, Batch 13: ERP Similarity Score: -0.0512
    Run 3, Batch 14: ERP Similarity Score: -0.0437
    Run 3, Batch 15: ERP Similarity Score: -0.0550
    Run 3, Batch 16: ERP Similarity Score: -0.0517
    Run 3, Batch 17: ERP Similarity Score: -0.0532
    Run 3, Batch 18: ERP Similarity Score: -0.0567
    Run 3, Batch 19: ERP Similarity Score: -0.0553
    Run 3, Batch 20: ERP Similarity Score: -0.0508
    Run 3, Batch 21: ERP Similarity Score: -0.0579
    Run 3, Batch 22: ERP Similarity Score: -0.0513
    Run 3, Batch 23: ERP Similarity Score: -0.0473
    Run 3, Batch 24: ERP Similarity Score: -0.0555
    Run 3, Batch 25: ERP Similarity Score: -0.0602
    Run 3, Batch 26: ERP Similarity Score: -0.0664
    Run 3, Batch 27: ERP Similarity Score: -0.0520
    Run 3, Batch 28: ERP Similarity Score: -0.0566
    Run 3, Batch 29: ERP Similarity Score: -0.0620
    Run 3, Batch 30: ERP Similarity Score: -0.0501

--- Training cWGAN-GP for Subject 1-2, Run 4 ---
Epoch 0/1000: D Loss=67.0414, G Loss (Comb)=1.2007
Epoch 50/1000: D Loss=-1.7158, G Loss (Comb)=-0.8826
Epoch 100/1000: D Loss=-0.6461, G Loss (Comb)=-3.3616
Epoch 150/1000: D Loss=-0.3758, G Loss (Comb)=-2.7917
Epoch 200/1000: D Loss=-0.3364, G Loss (Comb)=-2.5332
Epoch 250/1000: D Loss=-0.4667, G Loss (Comb)=-2.9581
Epoch 300/1000: D Loss=-0.3685, G Loss (Comb)=-1.9639
Epoch 350/1000: D Loss=-0.5122, G Loss (Comb)=-2.1202
Epoch 400/1000: D Loss=-0.5945, G Loss (Comb)=-2.1078
Epoch 450/1000: D Loss=-0.6456, G Loss (Comb)=-1.8511
Epoch 500/1000: D Loss=-0.7059, G Loss (Comb)=-1.2438
Epoch 550/1000: D Loss=-0.6827, G Loss (Comb)=-1.3156
Epoch 600/1000: D Loss=-0.8333, G Loss (Comb)=-1.1021
Epoch 650/1000: D Loss=-0.8322, G Loss (Comb)=-1.0837
Epoch 700/1000: D Loss=-0.8119, G Loss (Comb)=-1.0426
Epoch 750/1000: D Loss=-0.9258, G Loss (Comb)=-1.3576
Epoch 800/1000: D Loss=-0.9556, G Loss (Comb)=-1.3138
Epoch 850/1000: D Loss=-0.9770, G Loss (Comb)=-1.4922
Epoch 900/1000: D Loss=-1.0453, G Loss (Comb)=-1.3593
Epoch 950/1000: D Loss=-0.9635, G Loss (Comb)=-1.3294
Epoch 999/1000: D Loss=-1.0745, G Loss (Comb)=-1.6419

--- Generating & Evaluating Batches with ERP Similarity (Run 4) ---
    Run 4, Batch 1: ERP Similarity Score: -0.0432
    Run 4, Batch 2: ERP Similarity Score: -0.0591
    Run 4, Batch 3: ERP Similarity Score: -0.0464
    Run 4, Batch 4: ERP Similarity Score: -0.0441
    Run 4, Batch 5: ERP Similarity Score: -0.0418
    Run 4, Batch 6: ERP Similarity Score: -0.0424
    Run 4, Batch 7: ERP Similarity Score: -0.0421
    Run 4, Batch 8: ERP Similarity Score: -0.0402
    Run 4, Batch 9: ERP Similarity Score: -0.0452
    Run 4, Batch 10: ERP Similarity Score: -0.0451
    Run 4, Batch 11: ERP Similarity Score: -0.0381
    Run 4, Batch 12: ERP Similarity Score: -0.0482
    Run 4, Batch 13: ERP Similarity Score: -0.0402
    Run 4, Batch 14: ERP Similarity Score: -0.0391
    Run 4, Batch 15: ERP Similarity Score: -0.0465
    Run 4, Batch 16: ERP Similarity Score: -0.0468
    Run 4, Batch 17: ERP Similarity Score: -0.0408
    Run 4, Batch 18: ERP Similarity Score: -0.0440
    Run 4, Batch 19: ERP Similarity Score: -0.0427
    Run 4, Batch 20: ERP Similarity Score: -0.0581
    Run 4, Batch 21: ERP Similarity Score: -0.0398
    Run 4, Batch 22: ERP Similarity Score: -0.0449
    Run 4, Batch 23: ERP Similarity Score: -0.0474
    Run 4, Batch 24: ERP Similarity Score: -0.0380
    Run 4, Batch 25: ERP Similarity Score: -0.0522
    Run 4, Batch 26: ERP Similarity Score: -0.0388
    Run 4, Batch 27: ERP Similarity Score: -0.0471
    Run 4, Batch 28: ERP Similarity Score: -0.0414
    Run 4, Batch 29: ERP Similarity Score: -0.0438
    Run 4, Batch 30: ERP Similarity Score: -0.0469

--- Training cWGAN-GP for Subject 1-2, Run 5 ---
Epoch 0/1000: D Loss=66.2504, G Loss (Comb)=1.3892
Epoch 50/1000: D Loss=-1.8329, G Loss (Comb)=-1.4132
Epoch 100/1000: D Loss=-0.3853, G Loss (Comb)=-4.2201
Epoch 150/1000: D Loss=-0.4769, G Loss (Comb)=-3.3084
Epoch 200/1000: D Loss=-0.3817, G Loss (Comb)=-3.3529
Epoch 250/1000: D Loss=-0.3211, G Loss (Comb)=-2.8554
Epoch 300/1000: D Loss=-0.4191, G Loss (Comb)=-2.4882
Epoch 350/1000: D Loss=-0.4803, G Loss (Comb)=-2.0663
Epoch 400/1000: D Loss=-0.4457, G Loss (Comb)=-1.7077
Epoch 450/1000: D Loss=-0.4636, G Loss (Comb)=-1.6534
Epoch 500/1000: D Loss=-0.5298, G Loss (Comb)=-0.8477
Epoch 550/1000: D Loss=-0.6565, G Loss (Comb)=-0.4597
Epoch 600/1000: D Loss=-0.6808, G Loss (Comb)=-0.5452
Epoch 650/1000: D Loss=-0.8203, G Loss (Comb)=-0.4061
Epoch 700/1000: D Loss=-0.7697, G Loss (Comb)=-0.2423
Epoch 750/1000: D Loss=-0.9205, G Loss (Comb)=-0.1694
Epoch 800/1000: D Loss=-0.9324, G Loss (Comb)=-0.5431
Epoch 850/1000: D Loss=-0.9849, G Loss (Comb)=-0.5171
Epoch 900/1000: D Loss=-0.9905, G Loss (Comb)=-0.8318
Epoch 950/1000: D Loss=-1.0304, G Loss (Comb)=-0.6714
Epoch 999/1000: D Loss=-1.0335, G Loss (Comb)=-0.5870

--- Generating & Evaluating Batches with ERP Similarity (Run 5) ---
    Run 5, Batch 1: ERP Similarity Score: -0.0438
    Run 5, Batch 2: ERP Similarity Score: -0.0467
    Run 5, Batch 3: ERP Similarity Score: -0.0494
    Run 5, Batch 4: ERP Similarity Score: -0.0526
    Run 5, Batch 5: ERP Similarity Score: -0.0423
    Run 5, Batch 6: ERP Similarity Score: -0.0513
    Run 5, Batch 7: ERP Similarity Score: -0.0494
    Run 5, Batch 8: ERP Similarity Score: -0.0453
    Run 5, Batch 9: ERP Similarity Score: -0.0528
    Run 5, Batch 10: ERP Similarity Score: -0.0407
    Run 5, Batch 11: ERP Similarity Score: -0.0538
    Run 5, Batch 12: ERP Similarity Score: -0.0496
    Run 5, Batch 13: ERP Similarity Score: -0.0424
    Run 5, Batch 14: ERP Similarity Score: -0.0530
    Run 5, Batch 15: ERP Similarity Score: -0.0435
    Run 5, Batch 16: ERP Similarity Score: -0.0395
    Run 5, Batch 17: ERP Similarity Score: -0.0417
    Run 5, Batch 18: ERP Similarity Score: -0.0517
    Run 5, Batch 19: ERP Similarity Score: -0.0509
    Run 5, Batch 20: ERP Similarity Score: -0.0492
    Run 5, Batch 21: ERP Similarity Score: -0.0614
    Run 5, Batch 22: ERP Similarity Score: -0.0457
    Run 5, Batch 23: ERP Similarity Score: -0.0551
    Run 5, Batch 24: ERP Similarity Score: -0.0519
    Run 5, Batch 25: ERP Similarity Score: -0.0453
    Run 5, Batch 26: ERP Similarity Score: -0.0466
    Run 5, Batch 27: ERP Similarity Score: -0.0399
    Run 5, Batch 28: ERP Similarity Score: -0.0455
    Run 5, Batch 29: ERP Similarity Score: -0.0511
    Run 5, Batch 30: ERP Similarity Score: -0.0411


--- Step 7: Selecting Best Augmentation Strategy ---
Selected top 10 synthetic batches based on ERP similarity to the validation set.
  Top 1: Run 2, Batch 27, Score: -0.0371
  Top 2: Run 1, Batch 9, Score: -0.0376
  Top 3: Run 4, Batch 24, Score: -0.0380
  Top 4: Run 4, Batch 11, Score: -0.0381
  Top 5: Run 2, Batch 3, Score: -0.0381
  Top 6: Run 2, Batch 8, Score: -0.0384
  Top 7: Run 1, Batch 1, Score: -0.0386
  Top 8: Run 2, Batch 14, Score: -0.0388
  Top 9: Run 4, Batch 26, Score: -0.0388
  Top 10: Run 1, Batch 28, Score: -0.0388

--- Evaluating strategies on the validation set using classification accuracy ---
    Run 2, Batch 27, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 2, Batch 27, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 27, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 27, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 1, Batch 9, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 1, Batch 9, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 9, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 1, Batch 9, Strategy 'Augmented (100%)': Validation Acc: 0.00%
    Run 4, Batch 24, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 4, Batch 24, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 4, Batch 24, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 4, Batch 24, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 4, Batch 11, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 11, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 4, Batch 11, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 11, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 2, Batch 3, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 3, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 2, Batch 3, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 2, Batch 3, Strategy 'Augmented (100%)': Validation Acc: 100.00%
    Run 2, Batch 8, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 8, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 2, Batch 8, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 2, Batch 8, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 1, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 1, Strategy 'Augmented (25%)': Validation Acc: 66.67%
    Run 1, Batch 1, Strategy 'Augmented (50%)': Validation Acc: 0.00%
    Run 1, Batch 1, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 2, Batch 14, Strategy 'Synth Only': Validation Acc: 66.67%
    Run 2, Batch 14, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 2, Batch 14, Strategy 'Augmented (50%)': Validation Acc: 33.33%
    Run 2, Batch 14, Strategy 'Augmented (100%)': Validation Acc: 33.33%
    Run 4, Batch 26, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 4, Batch 26, Strategy 'Augmented (25%)': Validation Acc: 0.00%
    Run 4, Batch 26, Strategy 'Augmented (50%)': Validation Acc: 66.67%
    Run 4, Batch 26, Strategy 'Augmented (100%)': Validation Acc: 66.67%
    Run 1, Batch 28, Strategy 'Synth Only': Validation Acc: 33.33%
    Run 1, Batch 28, Strategy 'Augmented (25%)': Validation Acc: 33.33%
    Run 1, Batch 28, Strategy 'Augmented (50%)': Validation Acc: 100.00%
    Run 1, Batch 28, Strategy 'Augmented (100%)': Validation Acc: 100.00%

Found 3 strategies with the top validation accuracy of 100.00%.
Using ERP similarity score as a tie-breaker...
  - Strategy (Run 2, Batch 3, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0381
  - Strategy (Run 1, Batch 28, Ratio 0.5): Accuracy=100.00, ERP Score=-0.0388
  - Strategy (Run 1, Batch 28, Ratio 1.0): Accuracy=100.00, ERP Score=-0.0388

Selected best strategy: Run 2, Batch 3, Strategy: Augmented (100%) with a validation accuracy of 100.00%
This strategy will now be evaluated on the unseen test set.


--- Step 8: Final Evaluation of Best Strategies on Test Set ---
BEST SYNTHETIC-ONLY (Val Acc: 66.67%) -> REAL test accuracy: 66.67%
Retraining best model on combined Train+Validation data for final evaluation.
BEST OVERALL STRATEGY (Augmented (100%), Val Acc: 100.00%) -> REAL test accuracy: 81.82%

--- Step 9: Final Plotting and Summary ---
Saved target class of best synthetic batch to H10_results/Subject_1-2_results/target_synthetic_data_S1-2.mat
Saved non-target class of best synthetic batch to H10_results/Subject_1-2_results/nontarget_synthetic_data_S1-2.mat
Saved target class of training data to H10_results/Subject_1-2_results/target_training_data_S1-2.mat
Saved non-target class of training data to H10_results/Subject_1-2_results/nontarget_training_data_S1-2.mat

Saved accuracy comparison plot to: H10_results/Subject_1-2_results/accuracy_comparison_S1-2.png

--- Plotting Combined Grand Average ERP Comparison for Channel Cz (Session 1-2) ---
Data will be rescaled to original amplitude (Î¼V) for plotting.
Saved combined grand average plot to: H10_results/Subject_1-2_results/GA_ERP_Combined_S1-2_ChCz.png

--- Subject 1-2 processing finished successfully. ---
